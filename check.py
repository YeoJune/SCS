# data_leakage_checker.py
"""
SCS í•™ìŠµ ë°ì´í„° ëˆ„ì¶œ ê²€ì‚¬ ìŠ¤í¬ë¦½íŠ¸

í•™ìŠµ ë°ì´í„°ì— ì •ë‹µì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸:
1. ì…ë ¥ í…ìŠ¤íŠ¸ì— ì •ë‹µ ë¬¸ì(A, B, C, D)ê°€ ì§ì ‘ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€
2. LogiQA ë°ì´í„°ì…‹ì˜ êµ¬ì¡°ì  ë¬¸ì œ í™•ì¸
3. Teacher Forcing ì¤‘ íƒ€ê²Ÿ í† í°ì´ ì…ë ¥ì— ë…¸ì¶œë˜ëŠ”ì§€ í™•ì¸
"""

import torch
from transformers import AutoTokenizer
import json
import re
from typing import Dict, List, Any, Tuple
from datasets import load_dataset


class DataLeakageChecker:
    """ë°ì´í„° ëˆ„ì¶œ ê²€ì‚¬ê¸°"""
    
    def __init__(self, dataset_name: str = "datatune/LogiQA2.0"):
        self.dataset_name = dataset_name
        self.tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
        
    def check_full_dataset(self, split: str = "train", max_samples: int = 100) -> Dict[str, Any]:
        """ì „ì²´ ë°ì´í„°ì…‹ ëˆ„ì¶œ ê²€ì‚¬"""
        print(f"ğŸ” {self.dataset_name} ({split}) ë°ì´í„° ëˆ„ì¶œ ê²€ì‚¬ ì‹œì‘...")
        
        # ë°ì´í„°ì…‹ ë¡œë“œ
        try:
            raw_dataset = load_dataset(self.dataset_name, split=split)
            if max_samples and len(raw_dataset) > max_samples:
                raw_dataset = raw_dataset.select(range(max_samples))
        except Exception as e:
            return {"error": f"ë°ì´í„°ì…‹ ë¡œë“œ ì‹¤íŒ¨: {e}"}
        
        results = {
            "total_samples": len(raw_dataset),
            "leakage_cases": [],
            "answer_in_input_count": 0,
            "options_in_context_count": 0,
            "direct_answer_count": 0,
            "tokenization_leakage_count": 0
        }
        
        for idx, item in enumerate(raw_dataset):
            if idx % 50 == 0:
                print(f"  ê²€ì‚¬ ì§„í–‰: {idx}/{len(raw_dataset)}")
                
            leakage_info = self._check_single_item(item, idx)
            if leakage_info["has_leakage"]:
                results["leakage_cases"].append(leakage_info)
                
                if leakage_info["answer_in_input"]:
                    results["answer_in_input_count"] += 1
                if leakage_info["options_in_context"]:
                    results["options_in_context_count"] += 1
                if leakage_info["direct_answer"]:
                    results["direct_answer_count"] += 1
                if leakage_info["tokenization_leakage"]:
                    results["tokenization_leakage_count"] += 1
        
        # ìš”ì•½ í†µê³„
        results["leakage_rate"] = len(results["leakage_cases"]) / results["total_samples"]
        results["most_common_leakage"] = self._analyze_leakage_patterns(results["leakage_cases"])
        
        return results
    
    def _check_single_item(self, item: Dict[str, Any], idx: int) -> Dict[str, Any]:
        """ë‹¨ì¼ ì•„ì´í…œ ëˆ„ì¶œ ê²€ì‚¬"""
        try:
            # LogiQA ë°ì´í„° íŒŒì‹±
            raw_text = item.get('text', '').strip()
            if not raw_text:
                return {"has_leakage": False, "error": "ë¹ˆ í…ìŠ¤íŠ¸"}
            
            data = json.loads(raw_text)
            context = data.get('text', '').strip()
            question = data.get('question', '').strip()
            options = data.get('options', [])
            answer = data.get('answer', 0)
            
            # ì •ë‹µ ë¬¸ì ê³„ì‚°
            if isinstance(answer, int) and 0 <= answer < len(options):
                correct_answer_char = chr(65 + answer)  # 0->A, 1->B, etc.
                correct_answer_text = options[answer] if options else ""
            else:
                return {"has_leakage": False, "error": f"ì˜ëª»ëœ ì •ë‹µ ì¸ë±ìŠ¤: {answer}"}
            
            # ì…ë ¥ í…ìŠ¤íŠ¸ êµ¬ì„± (ì‹¤ì œ í•™ìŠµì—ì„œ ì‚¬ìš©ë˜ëŠ” í˜•íƒœ)
            input_parts = []
            if context:
                input_parts.append(f"Context: {context}")
            input_parts.append(f"Question: {question}")
            
            options_text = " ".join([f"{chr(65+i)}) {opt.strip()}" 
                                   for i, opt in enumerate(options)])
            input_parts.append(f"Options: {options_text}")
            
            full_input_text = " ".join(input_parts)
            
            # ëˆ„ì¶œ ê²€ì‚¬
            leakage_info = {
                "index": idx,
                "has_leakage": False,
                "answer_in_input": False,
                "options_in_context": False,
                "direct_answer": False,
                "tokenization_leakage": False,
                "details": [],
                "correct_answer": correct_answer_char,
                "input_text": full_input_text[:200] + "..." if len(full_input_text) > 200 else full_input_text
            }
            
            # ê²€ì‚¬ 1: ì…ë ¥ì— ì •ë‹µ ë¬¸ìê°€ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€
            if self._check_answer_in_input(full_input_text, correct_answer_char, correct_answer_text):
                leakage_info["answer_in_input"] = True
                leakage_info["has_leakage"] = True
                leakage_info["details"].append("ì…ë ¥ í…ìŠ¤íŠ¸ì— ì •ë‹µ ë¬¸ì/í…ìŠ¤íŠ¸ í¬í•¨")
            
            # ê²€ì‚¬ 2: ì»¨í…ìŠ¤íŠ¸ì— ì„ íƒì§€ í…ìŠ¤íŠ¸ê°€ ì§ì ‘ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€
            if self._check_options_in_context(context, options):
                leakage_info["options_in_context"] = True
                leakage_info["has_leakage"] = True
                leakage_info["details"].append("ì»¨í…ìŠ¤íŠ¸ì— ì„ íƒì§€ í…ìŠ¤íŠ¸ í¬í•¨")
            
            # ê²€ì‚¬ 3: ì»¨í…ìŠ¤íŠ¸ë‚˜ ì§ˆë¬¸ì— ì§ì ‘ì ì¸ ë‹µì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€
            if self._check_direct_answer_hints(context + " " + question, correct_answer_text):
                leakage_info["direct_answer"] = True
                leakage_info["has_leakage"] = True
                leakage_info["details"].append("ì»¨í…ìŠ¤íŠ¸/ì§ˆë¬¸ì— ì§ì ‘ì ì¸ ë‹µ íŒíŠ¸ í¬í•¨")
            
            # ê²€ì‚¬ 4: í† í°í™” ê³¼ì •ì—ì„œì˜ ëˆ„ì¶œ
            if self._check_tokenization_leakage(full_input_text, correct_answer_char):
                leakage_info["tokenization_leakage"] = True
                leakage_info["has_leakage"] = True
                leakage_info["details"].append("í† í°í™” ê³¼ì •ì—ì„œ ì •ë‹µ ì •ë³´ ëˆ„ì¶œ")
            
            return leakage_info
            
        except Exception as e:
            return {"has_leakage": False, "error": f"ì²˜ë¦¬ ì‹¤íŒ¨: {e}"}
    
    def _check_answer_in_input(self, input_text: str, answer_char: str, answer_text: str) -> bool:
        """ì…ë ¥ì— ì •ë‹µì´ ì§ì ‘ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        input_lower = input_text.lower()
        
        # ì •ë‹µ ë¬¸ìê°€ Options ì„¹ì…˜ ì™¸ì˜ ë‹¤ë¥¸ ê³³ì— ë‚˜íƒ€ë‚˜ëŠ”ì§€ í™•ì¸
        options_start = input_text.find("Options:")
        if options_start != -1:
            pre_options_text = input_text[:options_start].lower()
            # Options ì´ì „ í…ìŠ¤íŠ¸ì— ì •ë‹µ ë¬¸ìê°€ ë‚˜íƒ€ë‚˜ë©´ ëˆ„ì¶œ
            if f" {answer_char.lower()}" in pre_options_text or f"{answer_char.lower()})" in pre_options_text:
                return True
        
        # ì •ë‹µ í…ìŠ¤íŠ¸ê°€ ì»¨í…ìŠ¤íŠ¸ë‚˜ ì§ˆë¬¸ì— ê·¸ëŒ€ë¡œ ë‚˜íƒ€ë‚˜ëŠ”ì§€ í™•ì¸
        if answer_text and len(answer_text) > 10:  # ì¶©ë¶„íˆ ê¸´ í…ìŠ¤íŠ¸ë§Œ ì²´í¬
            if answer_text.lower() in input_lower:
                # Options ì„¹ì…˜ì—ì„œì˜ ì¶œí˜„ì€ ì •ìƒì´ë¯€ë¡œ ì œì™¸
                if options_start != -1:
                    pre_options_text = input_text[:options_start].lower()
                    if answer_text.lower() in pre_options_text:
                        return True
        
        return False
    
    def _check_options_in_context(self, context: str, options: List[str]) -> bool:
        """ì»¨í…ìŠ¤íŠ¸ì— ì„ íƒì§€ í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        if not context or not options:
            return False
            
        context_lower = context.lower()
        
        for option in options:
            if len(option) > 15:  # ì¶©ë¶„íˆ ê¸´ ì„ íƒì§€ë§Œ ì²´í¬
                if option.lower() in context_lower:
                    return True
        
        return False
    
    def _check_direct_answer_hints(self, context_question: str, answer_text: str) -> bool:
        """ì»¨í…ìŠ¤íŠ¸/ì§ˆë¬¸ì— ì§ì ‘ì ì¸ ë‹µ íŒíŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸"""
        if not context_question or not answer_text:
            return False
        
        # ê°•í•œ íŒíŠ¸ í‚¤ì›Œë“œë“¤
        hint_patterns = [
            r"ë‹µì€?\s*[A-D]",
            r"ì •ë‹µì€?\s*[A-D]", 
            r"answer is\s*[A-D]",
            r"correct.*[A-D]",
            r"ë”°ë¼ì„œ\s*[A-D]"
        ]
        
        text_lower = context_question.lower()
        
        for pattern in hint_patterns:
            if re.search(pattern, text_lower, re.IGNORECASE):
                return True
        
        return False
    
    def _check_tokenization_leakage(self, input_text: str, answer_char: str) -> bool:
        """í† í°í™” ê³¼ì •ì—ì„œ ì •ë‹µ ì •ë³´ê°€ ëˆ„ì¶œë˜ëŠ”ì§€ í™•ì¸"""
        try:
            # ì…ë ¥ í…ìŠ¤íŠ¸ í† í°í™”
            tokens = self.tokenizer.tokenize(input_text)
            
            # ì •ë‹µ ë¬¸ì í† í°í™”
            answer_tokens = self.tokenizer.tokenize(answer_char)
            
            # í† í° ë ˆë²¨ì—ì„œ íŒ¨í„´ í™•ì¸
            token_string = " ".join(tokens)
            answer_token_string = " ".join(answer_tokens)
            
            # ë¹„ì •ìƒì ì¸ í† í° íŒ¨í„´ ê²€ì‚¬
            suspicious_patterns = [
                f"answer {answer_char.lower()}",
                f"correct {answer_char.lower()}",
                f"choose {answer_char.lower()}"
            ]
            
            for pattern in suspicious_patterns:
                if pattern in token_string.lower():
                    return True
                    
            return False
            
        except Exception:
            return False
    
    def _analyze_leakage_patterns(self, leakage_cases: List[Dict]) -> Dict[str, int]:
        """ëˆ„ì¶œ íŒ¨í„´ ë¶„ì„"""
        patterns = {
            "answer_in_input": 0,
            "options_in_context": 0, 
            "direct_answer": 0,
            "tokenization_leakage": 0
        }
        
        for case in leakage_cases:
            for pattern in patterns.keys():
                if case.get(pattern, False):
                    patterns[pattern] += 1
        
        return patterns
    
    def generate_report(self, results: Dict[str, Any]) -> str:
        """ê²€ì‚¬ ê²°ê³¼ ë³´ê³ ì„œ ìƒì„±"""
        if "error" in results:
            return f"âŒ ê²€ì‚¬ ì‹¤íŒ¨: {results['error']}"
        
        report = f"""
ğŸ” SCS ë°ì´í„° ëˆ„ì¶œ ê²€ì‚¬ ë³´ê³ ì„œ
==========================================

ğŸ“Š ì „ì²´ í†µê³„:
- ê²€ì‚¬í•œ ìƒ˜í”Œ ìˆ˜: {results['total_samples']:,}
- ëˆ„ì¶œ ì˜ì‹¬ ì‚¬ë¡€: {len(results['leakage_cases']):,}
- ëˆ„ì¶œë¥ : {results['leakage_rate']:.2%}

ğŸš¨ ëˆ„ì¶œ ìœ í˜•ë³„ í†µê³„:
- ì…ë ¥ì— ì •ë‹µ í¬í•¨: {results['answer_in_input_count']:,}
- ì»¨í…ìŠ¤íŠ¸ì— ì„ íƒì§€ í¬í•¨: {results['options_in_context_count']:,}
- ì§ì ‘ì ì¸ ë‹µ íŒíŠ¸: {results['direct_answer_count']:,}
- í† í°í™” ê³¼ì • ëˆ„ì¶œ: {results['tokenization_leakage_count']:,}

ğŸ“‹ ì£¼ìš” íŒ¨í„´:
{self._format_patterns(results['most_common_leakage'])}

âš ï¸ ì‹¬ê°í•œ ëˆ„ì¶œ ì‚¬ë¡€ (ìƒìœ„ 5ê°œ):
{self._format_top_leakage_cases(results['leakage_cases'][:5])}

ğŸ’¡ ê¶Œì¥ ì‚¬í•­:
{self._generate_recommendations(results)}
"""
        return report
    
    def _format_patterns(self, patterns: Dict[str, int]) -> str:
        """íŒ¨í„´ í¬ë§·íŒ…"""
        lines = []
        for pattern, count in patterns.items():
            lines.append(f"- {pattern}: {count}ê±´")
        return "\n".join(lines) if lines else "- ëˆ„ì¶œ íŒ¨í„´ ì—†ìŒ"
    
    def _format_top_leakage_cases(self, cases: List[Dict]) -> str:
        """ìƒìœ„ ëˆ„ì¶œ ì‚¬ë¡€ í¬ë§·íŒ…"""
        if not cases:
            return "- ëˆ„ì¶œ ì‚¬ë¡€ ì—†ìŒ"
        
        lines = []
        for i, case in enumerate(cases):
            lines.append(f"{i+1}. ìƒ˜í”Œ #{case['index']}")
            lines.append(f"   ì •ë‹µ: {case['correct_answer']}")
            lines.append(f"   ë¬¸ì œ: {', '.join(case['details'])}")
            lines.append(f"   ì…ë ¥: {case['input_text']}")
            lines.append("")
        
        return "\n".join(lines)
    
    def _generate_recommendations(self, results: Dict[str, Any]) -> str:
        """ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        recommendations = []
        
        if results['leakage_rate'] > 0.1:
            recommendations.append("- ğŸš¨ ì‹¬ê°í•œ ë°ì´í„° ëˆ„ì¶œ detected! ì¦‰ì‹œ ìˆ˜ì • í•„ìš”")
        elif results['leakage_rate'] > 0.05:
            recommendations.append("- âš ï¸ ì¤‘ê°„ ìˆ˜ì¤€ì˜ ë°ì´í„° ëˆ„ì¶œ. ê°œì„  ê¶Œì¥")
        else:
            recommendations.append("- âœ… ë°ì´í„° ëˆ„ì¶œ ìˆ˜ì¤€ ì–‘í˜¸")
        
        if results['answer_in_input_count'] > 0:
            recommendations.append("- ì…ë ¥ ì „ì²˜ë¦¬ì—ì„œ ì •ë‹µ ë¬¸ì ì œê±° ë¡œì§ ì¶”ê°€")
        
        if results['options_in_context_count'] > 0:
            recommendations.append("- ì»¨í…ìŠ¤íŠ¸ì™€ ì„ íƒì§€ ë¶„ë¦¬ ê°œì„ ")
        
        if results['direct_answer_count'] > 0:
            recommendations.append("- ì§ì ‘ì ì¸ ë‹µ íŒíŠ¸ê°€ í¬í•¨ëœ ë°ì´í„° í•„í„°ë§")
        
        return "\n".join(recommendations) if recommendations else "- ì¶”ê°€ ê°œì„ ì‚¬í•­ ì—†ìŒ"


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    checker = DataLeakageChecker("datatune/LogiQA2.0")
    
    # í•™ìŠµ ë°ì´í„° ê²€ì‚¬
    print("ğŸ” í•™ìŠµ ë°ì´í„° ëˆ„ì¶œ ê²€ì‚¬ ì‹œì‘...")
    train_results = checker.check_full_dataset("train", max_samples=200)
    
    # ê²€ì¦ ë°ì´í„° ê²€ì‚¬
    print("\nğŸ” ê²€ì¦ ë°ì´í„° ëˆ„ì¶œ ê²€ì‚¬ ì‹œì‘...")
    val_results = checker.check_full_dataset("validation", max_samples=100)
    
    # ë³´ê³ ì„œ ìƒì„±
    print("\n" + "="*50)
    print("ğŸ“‹ í•™ìŠµ ë°ì´í„° ê²€ì‚¬ ê²°ê³¼")
    print("="*50)
    print(checker.generate_report(train_results))
    
    print("\n" + "="*50)
    print("ğŸ“‹ ê²€ì¦ ë°ì´í„° ê²€ì‚¬ ê²°ê³¼")
    print("="*50)
    print(checker.generate_report(val_results))
    
    # Teacher Forcing ëˆ„ì¶œ ê°€ëŠ¥ì„± ê²½ê³ 
    print("\n" + "="*50)
    print("ğŸ¯ Teacher Forcing ëˆ„ì¶œ ê°€ëŠ¥ì„± ê²€ì‚¬")
    print("="*50)
    print("""
âš ï¸ ì¶”ê°€ í™•ì¸ í•„ìš” ì‚¬í•­:

1. í•™ìŠµ ì¤‘ Teacher Forcing ì‹œì :
   - íƒ€ê²Ÿ í† í°ì´ ì…ë ¥ ì‹œí€€ìŠ¤ì— í¬í•¨ë˜ì–´ forward passì—ì„œ ë³´ì´ëŠ”ê°€?
   - SCSTrainer._train_batch()ì—ì„œ target_tokensê°€ model() í˜¸ì¶œ ì‹œ ì „ë‹¬ë˜ëŠ”ê°€?

2. í† í° ì‹œí€€ìŠ¤ êµ¬ì„±:
   - ì…ë ¥: "Context: ... Question: ... Options: A) ... B) ..."
   - íƒ€ê²Ÿ: "A" (ì •ë‹µ)
   - ëª¨ë¸ì´ Options ë¶€ë¶„ì„ ë³´ê³  ë‹µì„ ì¶”ë¡ í•˜ëŠ” ê²ƒì´ ì •ìƒì¸ê°€?

3. ê¶Œì¥ í•´ê²°ì±…:
   - ì…ë ¥ì—ì„œ Options ì œê±°í•˜ê±°ë‚˜
   - Mask ê¸°ë°˜ í•™ìŠµìœ¼ë¡œ ì „í™˜í•˜ê±°ë‚˜  
   - Contrastive Learning ì ìš©
    """)


if __name__ == "__main__":
    main()