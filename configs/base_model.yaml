# configs/base_model.yaml
# SCS 기본 모델 설정 - 표준화된 구조

# === 시스템 역할 정의 ===
system_roles:
  input_node: "IN"
  output_node: "OUT"
  acc_node: "ACC"

# === 뇌 영역 구성 (단순한 IN→OUT 구조) ===
brain_regions:
  IN:
    grid_size: [16, 16]
    decay_rate: 0.9
    distance_tau: 3.0
  OUT:
    grid_size: [16, 16]
    decay_rate: 0.9
    distance_tau: 3.0
  ACC:
    grid_size: [16, 16]
    decay_rate: 0.9
    distance_tau: 3.0

# === 스파이크 역학 ===
spike_dynamics:
  threshold: 5.0
  refractory_base: 1
  refractory_adaptive_factor: 1.0
  surrogate_beta: 3.0
  ema_alpha: 0.1

# === 연결성 설정 ===
connectivity:
  local:
    max_distance: 5

# === 축삭 연결 (IN→OUT 단일 연결) ===
axonal_connections:
  connections:
    - source: "IN"
      target: "OUT"
      kernel_size: 3
      stride: 1
      padding: 1
      dilation: 1
      weight_scale: 0.8

# === IO 시스템 ===
io_system:
  input_interface:
    embedding_dim: 512
    window_size: 64
    num_heads: 8
    use_positional_encoding: false
    t5_model_name: "t5-small"
  output_interface:
    embedding_dim: 512
    window_size: 64
    num_heads: 8
    num_decoder_layers: 1
    dim_feedforward: 2048
    dropout: 0.1
    use_positional_encoding: false
    t5_model_name: "t5-small"
    spike_gain: 10.0 # 스파이크 증폭 계수

timing_manager:
  sync_ema_alpha: 0.1 # EMA 필터링 강도
  sync_threshold_start: 0.4 # 시작 임계값
  sync_threshold_end: 0.2 # 종료 임계값
  min_processing_clk: 0 # 최소 처리 시간
  max_processing_clk: 500 # 최대 처리 시간
  min_output_length: 5 # 최소 출력 길이
  fixed_len: -1 # -1: 적응 모드, >0: 고정 길이
  fixed_delay: -1 # -1: 적응 모드, ≥0: 고정 지연

# === 학습 설정 ===
learning:
  epochs: 15
  learning_rate: 1e-4
  eta_min: 1e-5
  weight_decay: 1e-4
  gradient_clip_norm: 1.0
  eval_every: 3
  save_every: 10
  early_stopping_patience: 20
  max_clk_training: 250
  optimizer: "adamw"

  # Scheduled Sampling
  use_scheduled_sampling: false
  ss_start_prob: 1.0
  ss_end_prob: 0.05
  ss_decay_epochs: 30

  spike_reg_weight: 0.5 # 스파이크 정규화 가중치
  target_spike_rate: 0.2 # 목표 스파이크율
  timing_weight: 0.0 # 타이밍 손실 가중치
  sync_target_start: 1.0 # 시작 시점 동기화 목표
  sync_target_end: 0.0 # 종료 시점 동기화 목표

  use_temporal_weighting: true
  initial_temporal_weight: 10.0 # 초기 CLK에 높은 중요도
  final_temporal_weight: 1.0 # 나중 CLK에 기본 중요도

  gradual_unfreezing:
    enabled: true
    initial_frozen_patterns: # 시작할 때 동결할 파라미터들
      - "input_interface.token_embedding"
      - "output_interface.token_embedding"
      - "output_interface.final_projection"
      - "output_interface.transformer_decoder.layers.0.self_attn"
      - "output_interface.transformer_decoder.layers.0.linear"
    unfreeze_schedule: # 에포크별 해제 스케줄
      100: # 에포크 100에 T5 임베딩 해제
        - "input_interface.token_embedding"
        - "output_interface.token_embedding"
        - "output_interface.final_projection"

data:
  train_samples: -1 # -1은 전체 데이터, 양수는 해당 개수만
  val_samples: -1 # -1은 전체 데이터
  test_samples: -1 # -1은 전체 데이터

# === 데이터 로딩 ===
data_loading:
  batch_size: 4
  num_workers: 0
  tokenizer:
    name: "t5-small"
    max_length: 128
    pad_token_id: 0
    eos_token_id: 1
    bos_token_id: 0
    unk_token_id: 2

# === 작업 설정 ===
task:
  dataset_name: "datatune/LogiQA2.0"
  task_type: "auto"

# === 평가 설정 ===
evaluation:
  save_examples: 10
