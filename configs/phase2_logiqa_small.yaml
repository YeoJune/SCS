# configs/phase2_logiqa_small.yaml

# 기본 설정 상속
defaults:
  - base_model

# 실험 메타정보
experiment:
  name: "Phase2_LogiQA_Large"
  description: "LogiQA 데이터셋을 통한 추론 능력 검증 (큰 규모)"
  phase: 2
  expected_runtime: "90-180분"

# 시스템 역할 정의
system_roles:
  input_node: "IN"
  output_node: "OUT"

# 태스크 설정
task:
  name: "LogiQA"
  type: "reasoning"
  dataset_name: "datatune/LogiQA2.0"
  max_samples:
    train: 50
    validation: 10
    test: 10

# 모델 설정
brain_regions:
  IN:
    grid_size: [64, 64]
    decay_rate: 0.95
    distance_tau: 1.5
  ACC:
    grid_size: [64, 64]
    decay_rate: 0.88
    distance_tau: 2.0
  ADJ:
    grid_size: [64, 64]
    decay_rate: 0.92
    distance_tau: 2.5
  OUT:
    grid_size: [64, 64]
    decay_rate: 0.97
    distance_tau: 3.0

# 축삭 연결 설정
axonal_connections:
  excitatory_ratio: 0.8
  connections:
    # --- 1. 기본 정보 처리 경로 ---
    # 입력(IN)에서 처리(ADJ)로, 처리(ADJ)에서 출력(OUT)으로 가는 핵심 경로
    - source: "IN"
      target: "ADJ"
      kernel_size: 5
      stride: 1
      padding: 2 # (5-1)/2 = 2
      weight_scale: 0.7

    - source: "ADJ"
      target: "OUT"
      kernel_size: 3
      stride: 1
      padding: 1 # (3-1)/2 = 1
      weight_scale: 0.9

    # --- 2. 모니터링 및 조절 경로 (피드백 루프) ---
    # 처리(ADJ) 노드의 상태를 모니터링(ACC)하고, 그 결과를 다시 처리(ADJ) 노드에 반영
    - source: "ADJ"
      target: "ACC"
      kernel_size: 3
      stride: 1
      padding: 1
      weight_scale: 0.6

    - source: "ACC"
      target: "ADJ"
      kernel_size: 7 # 넓은 범위의 조절 신호를 위한 큰 커널
      stride: 1
      padding: 3 # (7-1)/2 = 3
      weight_scale: 0.4

    # --- 3. 보조 경로 (컨텍스트 유지) ---
    # 원본 입력(IN) 정보를 모니터링(ACC) 및 출력(OUT) 노드에 직접 전달하여 컨텍스트 유지
    - source: "IN"
      target: "ACC"
      kernel_size: 1
      stride: 1
      padding: 0
      weight_scale: 0.3

    - source: "IN"
      target: "OUT"
      kernel_size: 1
      stride: 1
      padding: 0
      weight_scale: 0.3

# I/O 인터페이스 설정
io_system:
  input_interface:
    max_seq_len: 256
  output_interface:
    max_output_len: 256

# 학습 설정
training:
  epochs: 20
  learning_rate: 5e-4
  batch_size: 1
  max_clk_training: 150
  optimizer: "adamw"
  weight_decay: 0.01
  warmup_steps: 100
  eval_every_n_epochs: 5
  save_every_n_epochs: 10
  early_stopping_patience: 5

# 데이터 설정
data:
  tokenizer:
    name: "bert-base-uncased"
    max_length: 256
    padding: true
    truncation: true

# 데이터 전처리 설정
preprocessing:
  lowercase: true
  remove_punctuation: false
  max_context_length: 200
  max_question_length: 50

# 평가 메트릭
metrics:
  primary: "accuracy"
  additional: ["f1", "precision", "recall"]

# 실험 추적 설정
tracking:
  use_wandb: true
  wandb_project: "SCS_LogiQA"
  wandb_tags: ["phase2", "logiqa", "large", "reasoning"]

# 저장할 메트릭
log_metrics: ["loss", "accuracy", "f1"]
log_frequency: 10

# 분석 설정
analysis:
  dynamics_analysis:
    enabled: true
    save_spike_patterns: true
    analyze_connectivity: true
  representation_analysis:
    enabled: false
  ablation_study:
    enabled: false
