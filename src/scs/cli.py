# src/scs/cli.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
SCS (Spike-Based Cognitive System) ê³µì‹ CLI ì‹¤í–‰ ì§„ì…ì  (ê°„ì†Œí™”ëœ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°)
"""

import argparse
import sys
from pathlib import Path
import logging
from datetime import datetime
from typing import Dict, Any
import torch

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ Import (ë¦¬íŒ©í† ë§ëœ ê²½ë¡œ)
try:
    from scs.config import load_and_validate_config, ModelBuilder, AppConfig, LearningConfig
    from scs.training import SCSTrainer, MultiObjectiveLoss, TimingLoss, OptimizerFactory
    from scs.evaluation import SCSVisualizer, analyze_io_pipeline
    from scs.data import create_dataloader, SCSTokenizer
    from scs.utils import (
        setup_logging, save_config, set_random_seed, get_device
    )
except ImportError as e:
    print(f"âš  ëª¨ë“ˆ import ì˜¤ë¥˜: {e}. íŒ¨í‚¤ì§€ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”. ('pip install -e .')")
    sys.exit(1)

def setup_args() -> argparse.ArgumentParser:
    """CLI ì¸ì ì„¤ì •"""
    parser = argparse.ArgumentParser(
        description="SCS ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (ë¦¬íŒ©í† ë§ëœ êµ¬ì¡°)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # í•™ìŠµ ëª¨ë“œ
  scs --mode train --config configs/phase2_logiqa_small.yaml
  
  # TensorBoardì™€ í•¨ê»˜ í•™ìŠµ
  scs --mode train --config configs/phase2_logiqa_small.yaml --tensorboard --tb-launch
  
  # í‰ê°€ ëª¨ë“œ  
  scs --mode evaluate --experiment_dir experiments/phase2_20241201_1430
  
  # ì„¤ì • íŒŒì¼ ê²€ì¦
  scs --mode validate --config configs/my_experiment.yaml
        """
    )
    parser.add_argument("--mode", type=str, required=True, 
                       choices=["train", "evaluate", "validate"], 
                       help="ì‹¤í–‰ ëª¨ë“œ")
    parser.add_argument("--config", type=str, 
                       help="ì„¤ì • íŒŒì¼ ê²½ë¡œ (train/validate ëª¨ë“œ í•„ìˆ˜)")
    parser.add_argument("--experiment_dir", type=str, 
                       help="ì‹¤í—˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ (evaluate ëª¨ë“œ í•„ìˆ˜)")
    parser.add_argument("--device", type=str, default="auto", 
                       help="ì—°ì‚° ì¥ì¹˜ ì„ íƒ (cuda, cpu, mps)")
    parser.add_argument("--seed", type=int, default=42, 
                       help="ì¬í˜„ì„±ì„ ìœ„í•œ ëœë¤ ì‹œë“œ")
    parser.add_argument("--debug", action="store_true", 
                       help="ë””ë²„ê·¸ ëª¨ë“œ (ìƒì„¸ ë¡œê¹…)")
    parser.add_argument("--tensorboard", action="store_true", 
                       help="TensorBoard ë¡œê¹… í™œì„±í™”")
    parser.add_argument("--tb-port", type=int, default=6006, 
                       help="TensorBoard ì„œë²„ í¬íŠ¸")
    parser.add_argument("--tb-launch", action="store_true", 
                       help="TensorBoard ì„œë²„ ìë™ ì‹œì‘ ë° ë¸Œë¼ìš°ì € ì—´ê¸°")
    
    return parser

def validate_args(args: argparse.Namespace):
    """CLI ì¸ì ìœ íš¨ì„± ê²€ì‚¬"""
    if args.mode in ["train", "validate"] and not args.config:
        raise ValueError(f"{args.mode} ëª¨ë“œì—ì„œëŠ” --config ì¸ìê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
    if args.mode == "evaluate" and not args.experiment_dir:
        raise ValueError("evaluate ëª¨ë“œì—ì„œëŠ” --experiment_dir ì¸ìê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
    if args.config and not Path(args.config).exists():
        raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.config}")
    if args.experiment_dir and not Path(args.experiment_dir).exists():
        raise FileNotFoundError(f"ì‹¤í—˜ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.experiment_dir}")


def validate_mode(args: argparse.Namespace):
    """ì„¤ì • íŒŒì¼ êµ¬ì¡° ê²€ì¦ ëª¨ë“œ (config íŒ¨í‚¤ì§€ ì‚¬ìš©)"""
    print("ğŸ” ì„¤ì • íŒŒì¼ êµ¬ì¡° ê²€ì¦ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    
    try:
        config_path = Path(args.config)
        if not config_path.is_absolute():
            config_path = Path.cwd() / config_path
        
        # config íŒ¨í‚¤ì§€ì˜ ê²€ì¦ ê¸°ëŠ¥ ì‚¬ìš©
        app_config = load_and_validate_config(config_path)
        
        print("âœ… ì„¤ì • íŒŒì¼ êµ¬ì¡°ê°€ ì˜¬ë°”ë¦…ë‹ˆë‹¤!")
        
        # ê°„ë‹¨í•œ ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸
        try:
            model = ModelBuilder.build_model(app_config, device="cpu")
            total_params = sum(p.numel() for p in model.parameters())
            print(f"ğŸ“Š ëª¨ë¸ ì •ë³´:")
            print(f"   - ì´ ë§¤ê°œë³€ìˆ˜: {total_params:,}")
            print(f"   - ë‡Œ ì˜ì—­ ìˆ˜: {len(app_config.brain_regions)}")
            print(f"   - ì¶•ì‚­ ì—°ê²° ìˆ˜: {len(app_config.axonal_connections.connections)}")
            print(f"   - ì…ë ¥â†’ì¶œë ¥: {app_config.system_roles.input_node} â†’ {app_config.system_roles.output_node}")
            print("âœ… ëª¨ë¸ ìƒì„± ë° ì°¨ì› ê²€ì¦ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        except Exception as model_error:
            print(f"âš ï¸ ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {model_error}")
            return False
            
        return True
        
    except Exception as e:
        print(f"âš  ì„¤ì • íŒŒì¼ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False


def train_mode(args: argparse.Namespace):
    """í•™ìŠµ ëª¨ë“œ ì‹¤í–‰ (ê°„ì†Œí™”ëœ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°)"""
    # 1. ê¸°ë³¸ ì„¤ì •
    experiment_name = f"{Path(args.config).stem}_{datetime.now().strftime('%Y%m%d_%H%M')}"
    experiment_dir = Path("experiments") / experiment_name
    experiment_dir.mkdir(parents=True, exist_ok=True)
    
    setup_logging(log_dir=experiment_dir / "logs", level=logging.DEBUG if args.debug else logging.INFO)
    logger = logging.getLogger(__name__)
    set_random_seed(args.seed)
    device = get_device(args.device)
    
    logger.info(f"ğŸš€ ì‹¤í—˜ '{experiment_name}' ì‹œì‘ | ë””ë°”ì´ìŠ¤: {device}")

    try:
        # 2. ì„¤ì • ë¡œë”© ë° ê²€ì¦ (config íŒ¨í‚¤ì§€ ì‚¬ìš©)
        config_path = Path(args.config)
        if not config_path.is_absolute():
            config_path = Path.cwd() / config_path
        
        app_config = load_and_validate_config(config_path)
        
        # TensorBoard ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ (ìƒˆë¡œ ì¶”ê°€)
        if args.tensorboard:
            app_config.logging.tensorboard.enabled = True
            app_config.logging.tensorboard.port = args.tb_port
            app_config.logging.tensorboard.auto_launch = args.tb_launch
            logger.info(f"ğŸ“Š TensorBoard í™œì„±í™”: í¬íŠ¸ {args.tb_port}, ìë™ ì‹œì‘: {args.tb_launch}")

        save_config(app_config.model_dump(), experiment_dir / "config.yaml")
        logger.info("âœ… ì„¤ì • íŒŒì¼ ë¡œë”© ë° ê²€ì¦ ì™„ë£Œ")

        # 3. ë°ì´í„° ë¡œë” ìƒì„±
        logger.info("ğŸ“Š ë°ì´í„° ë¡œë” ìƒì„± ì¤‘...")
        tokenizer = SCSTokenizer(app_config.data_loading.tokenizer.name)
        
        # í† í¬ë‚˜ì´ì € ì„¤ì • ì—…ë°ì´íŠ¸
        app_config.data_loading.tokenizer.pad_token_id = getattr(tokenizer.tokenizer, 'pad_token_id', 0)
        app_config.data_loading.tokenizer.eos_token_id = getattr(tokenizer.tokenizer, 'eos_token_id', 1)
        
        dataset_name = app_config.task.dataset_name
        learning_style = app_config.task.learning_style
        bert_config = app_config.task.bert_config
        
        train_loader = create_dataloader(
            dataset_name=dataset_name, 
            split="train", 
            batch_size=app_config.data_loading.batch_size,
            max_length=app_config.data_loading.tokenizer.max_length,
            tokenizer=tokenizer,
            num_samples=app_config.data.train_samples,
            task_id=app_config.task.task_id,
            learning_style=learning_style,
            bert_config=bert_config
        )

        val_loader = create_dataloader(
            dataset_name=dataset_name, 
            split="validation", 
            batch_size=app_config.data_loading.batch_size,
            max_length=app_config.data_loading.tokenizer.max_length,
            tokenizer=tokenizer,
            num_samples=app_config.data.val_samples,
            task_id=app_config.task.task_id,
            learning_style=learning_style,
            bert_config=bert_config
        )
        
        logger.info(f"âœ… ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ (ë°ì´í„°ì…‹: {dataset_name}, ìŠ¤íƒ€ì¼: {learning_style})")

        # 4. ëª¨ë¸ ìƒì„± (config íŒ¨í‚¤ì§€ ì‚¬ìš©)
        logger.info("ğŸ§  SCS ëª¨ë¸ ìƒì„± ì¤‘...")
        app_config.io_system.input_interface.vocab_size = tokenizer.vocab_size
        app_config.io_system.output_interface.vocab_size = tokenizer.vocab_size

        model = ModelBuilder.build_model(app_config, device=device)
        
        total_params = sum(p.numel() for p in model.parameters())
        logger.info(f"âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        logger.info(f"   - ì´ ë§¤ê°œë³€ìˆ˜: {total_params:,}")
        logger.info(f"   - ë‡Œ ì˜ì—­: {list(app_config.brain_regions.keys())}")

        # 5. í•™ìŠµ ì‹œìŠ¤í…œ êµ¬ì„±
        logger.info("âš™ï¸ í•™ìŠµ ì‹œìŠ¤í…œ êµ¬ì„± ì¤‘...")
        
        # í•™ìŠµ ì„¤ì • ì¤€ë¹„
        learning_config = app_config.learning
        learning_config.device = device
        learning_config.pad_token_id = app_config.data_loading.tokenizer.pad_token_id

        # ì†ì‹¤ í•¨ìˆ˜ ìƒì„±
        loss_fn = TimingLoss(
            pad_token_id=app_config.data_loading.tokenizer.pad_token_id,
            guide_sep_token_id=learning_config.guide_sep_token_id,
            max_clk=learning_config.max_clk_training,
            guide_weight=learning_config.guide_weight,
            length_penalty_weight=learning_config.length_penalty_weight,
            orthogonal_reg_weight=learning_config.orthogonal_reg_weight,
            spike_reg_weight=learning_config.spike_reg_weight,
            target_spike_rate=learning_config.target_spike_rate,
            use_temporal_weighting=learning_config.use_temporal_weighting,
            initial_temporal_weight=learning_config.initial_temporal_weight,
            final_temporal_weight=learning_config.final_temporal_weight,
            timing_weight=learning_config.timing_weight,
            sync_target_start=learning_config.sync_target_start,
            sync_target_end=learning_config.sync_target_end,
            gate_pruning_weight=learning_config.gate_pruning_weight,
            gate_temperature=learning_config.gate_temperature,
            inner_pruning_weight=learning_config.inner_pruning_weight,
            inner_temperature=learning_config.inner_temperature,
            axon_strength_reg_weight=learning_config.axon_strength_reg_weight
        )
        
        # ì˜µí‹°ë§ˆì´ì € ìƒì„±
        optimizer = OptimizerFactory.create(
            optimizer_type=learning_config.optimizer, 
            model=model, 
            config=learning_config
        )
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer, 
            T_max=learning_config.epochs,
            eta_min=learning_config.eta_min
        )
        
        logger.info(f"âœ… í•™ìŠµ ì‹œìŠ¤í…œ êµ¬ì„± ì™„ë£Œ (ì˜µí‹°ë§ˆì´ì €: {learning_config.optimizer})")

        # 6. íŠ¸ë ˆì´ë„ˆ ìƒì„± ë° í•™ìŠµ
        logger.info("ğŸ¯ í•™ìŠµ ì‹œì‘...")
        
        # ì ì§„ì  í•´ì œ ì„¤ì •
        unfreezing_config = learning_config.gradual_unfreezing.model_dump() if learning_config.gradual_unfreezing else None
        
        trainer = SCSTrainer(
            model=model, 
            config=learning_config, 
            loss_fn=loss_fn, 
            optimizer=optimizer, 
            scheduler=scheduler, 
            tokenizer=tokenizer,
            unfreezing_config=unfreezing_config,
            tensorboard_config=app_config.logging.tensorboard.model_dump(),
            experiment_dir=experiment_dir
        )
        trainer.train(train_loader, val_loader, save_path=str(experiment_dir / "checkpoints"))

        # 7. ìµœì¢… í‰ê°€
        logger.info("ğŸ“ˆ ìµœì¢… í‰ê°€ ì‹œì‘...")
        test_loader = create_dataloader(
            dataset_name=dataset_name, 
            split="test", 
            batch_size=app_config.data_loading.batch_size,
            max_length=app_config.data_loading.tokenizer.max_length,
            tokenizer=tokenizer,
            num_samples=app_config.data.test_samples,
            task_id=app_config.task.task_id,
            learning_style=learning_style,
            bert_config=bert_config
        )
        
        test_results = trainer.evaluate(test_loader, save_examples=app_config.evaluation.save_examples)
        
        # ê²°ê³¼ ì €ì¥
        results_path = experiment_dir / f"final_results_{datetime.now().strftime('%Y%m%d_%H%M')}.yaml"
        save_config(test_results, results_path)
        
        logger.info("ğŸ‰ í•™ìŠµ ë° í‰ê°€ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        logger.info("ğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼:")
        for key, value in test_results.items():
            if key not in ['examples']:
                if isinstance(value, float):
                    logger.info(f"   - {key}: {value:.4f}")
                else:
                    logger.info(f"   - {key}: {value}")
        
        logger.info(f"ğŸ“‚ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {experiment_dir}")

        # 8. ì‹œê°í™” ë° ë¶„ì„ (evaluation íŒ¨í‚¤ì§€ ì‚¬ìš©)
        logger.info("ğŸ¨ ì‹œê°í™” ìƒì„± ì¤‘...")
        visualizer = SCSVisualizer()
        visualizer.generate_all_visualizations(model, test_loader, experiment_dir)

        logger.info("ğŸ”¬ IO íŒŒì´í”„ë¼ì¸ ë¶„ì„ ì¤‘...")
        analyze_io_pipeline(model, test_loader, experiment_dir, device)

    except Exception as e:
        logger.error(f"âš  í•™ìŠµ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise


def evaluate_mode(args: argparse.Namespace):
    """í‰ê°€ ëª¨ë“œ ì‹¤í–‰ (ê°„ì†Œí™”ëœ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°)"""
    # 1. ê¸°ë³¸ ì„¤ì •
    experiment_dir = Path(args.experiment_dir)
    config_path = experiment_dir / "config.yaml"

    if not config_path.exists():
        raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")

    setup_logging(log_dir=experiment_dir / "logs" / "eval", level=logging.DEBUG if args.debug else logging.INFO)
    logger = logging.getLogger(__name__)
    device = get_device(args.device)
    logger.info(f"ğŸ“Š í‰ê°€ ëª¨ë“œ ì‹œì‘ | ë””ë°”ì´ìŠ¤: {device}")
    
    try:
        # 2. ì„¤ì • ë¡œë”© (config íŒ¨í‚¤ì§€ ì‚¬ìš©)
        app_config = load_and_validate_config(config_path)
        
        # TensorBoard ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ (í‰ê°€ ëª¨ë“œì—ì„œë„ ë¡œê¹… ê°€ëŠ¥)
        if args.tensorboard:
            app_config.logging.tensorboard.enabled = True
            app_config.logging.tensorboard.port = args.tb_port
            app_config.logging.tensorboard.auto_launch = args.tb_launch
            logger.info(f"ğŸ“Š í‰ê°€ ëª¨ë“œ TensorBoard í™œì„±í™”: í¬íŠ¸ {args.tb_port}")
        
        logger.info("âœ… ì €ì¥ëœ ì„¤ì • íŒŒì¼ ë¡œë”© ì™„ë£Œ")
        
        # 3. ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
        checkpoint_dir = experiment_dir / "checkpoints"
        best_model_path = checkpoint_dir / "best_model.pt"
        if not best_model_path.exists():
            checkpoint_files = list(checkpoint_dir.glob("checkpoint_epoch_*.pt"))
            if not checkpoint_files:
                raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_dir}")
            best_model_path = max(checkpoint_files, key=lambda p: int(p.stem.split('_')[-1]))
        
        logger.info(f"ì‚¬ìš©í•  ì²´í¬í¬ì¸íŠ¸: {best_model_path}")

        # 4. ë°ì´í„° ë¡œë” ìƒì„±
        tokenizer = SCSTokenizer(app_config.data_loading.tokenizer.name)
        app_config.io_system.input_interface.vocab_size = tokenizer.vocab_size
        app_config.io_system.output_interface.vocab_size = tokenizer.vocab_size
        
        test_loader = create_dataloader(
            dataset_name=app_config.task.dataset_name,
            split="test",
            batch_size=app_config.data_loading.batch_size,
            max_length=app_config.data_loading.tokenizer.max_length,
            tokenizer=tokenizer,
            num_samples=app_config.data.test_samples,
            task_id=app_config.task.task_id,
            learning_style=app_config.task.learning_style,
            bert_config=app_config.task.bert_config
        )

        # 5. ëª¨ë¸ ë¡œë“œ (config íŒ¨í‚¤ì§€ ì‚¬ìš©)
        logger.info("ğŸ§  ëª¨ë¸ ë³µì› ì¤‘...")
        model = ModelBuilder.build_model(app_config, device=device)
        
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        checkpoint = torch.load(best_model_path, map_location=device, weights_only=False)
        model.load_state_dict(checkpoint['model_state_dict'], strict=False)
        logger.info("âœ… ëª¨ë¸ ë³µì› ì™„ë£Œ")

        # 6. í‰ê°€ ì‹¤í–‰
        logger.info("ğŸ“ˆ í‰ê°€ ì‹¤í–‰ ì¤‘...")
        learning_config = app_config.learning
        learning_config.device = device
        learning_config.pad_token_id = app_config.data_loading.tokenizer.pad_token_id
        
        trainer = SCSTrainer(
            model=model, 
            config=learning_config, 
            tokenizer=tokenizer,
            tensorboard_config=app_config.logging.tensorboard.model_dump(),
            experiment_dir=experiment_dir
        )
        results = trainer.evaluate(test_loader, save_examples=app_config.evaluation.save_examples)
        
        # ê²°ê³¼ ì €ì¥
        results_path = experiment_dir / f"eval_results_{datetime.now().strftime('%Y%m%d_%H%M')}.yaml"
        save_config(results, results_path)
        
        logger.info("ğŸ‰ í‰ê°€ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        logger.info("ğŸ“Š í‰ê°€ ê²°ê³¼:")
        for key, value in results.items():
            if key not in ['examples']:
                if isinstance(value, float):
                    logger.info(f"   - {key}: {value:.4f}")
                else:
                    logger.info(f"   - {key}: {value}")
        
        logger.info(f"ğŸ“‚ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {results_path}")
        
        # 7. ì‹œê°í™” ë° ë¶„ì„ (evaluation íŒ¨í‚¤ì§€ ì‚¬ìš©)
        logger.info("ğŸ¨ ì‹œê°í™” ìƒì„± ì¤‘...")
        visualizer = SCSVisualizer()
        visualizer.generate_visualizations(model, test_loader, experiment_dir)

        logger.info("ğŸ”¬ IO íŒŒì´í”„ë¼ì¸ ë¶„ì„ ì¤‘...")
        analyze_io_pipeline(model, test_loader, experiment_dir, device)

    except Exception as e:
        logger.error(f"âš  í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise


def main():
    """ë©”ì¸ CLI í•¨ìˆ˜ (ê°„ì†Œí™”ëœ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°)"""
    parser = setup_args()
    args = parser.parse_args()
    
    try:
        validate_args(args)
        
        if args.mode == "validate":
            success = validate_mode(args)
            sys.exit(0 if success else 1)
            
        elif args.mode == "train":
            train_mode(args)
            
        elif args.mode == "evaluate":
            evaluate_mode(args)
            
    except (ValueError, FileNotFoundError) as e:
        print(f"âš  ì…ë ¥ ì˜¤ë¥˜: {e}")
        sys.exit(1)
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(0)
    except Exception as e:
        logging.getLogger(__name__).critical(f"âš  ì‹¤í–‰ ì‹¤íŒ¨: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    pass