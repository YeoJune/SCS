#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
SCS (Spike-Based Cognitive System) ê³µì‹ CLI ì‹¤í–‰ ì§„ì…ì 

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” íŒ¨í‚¤ì§€ ì„¤ì¹˜ í›„ `scs` ëª…ë ¹ì–´ë¥¼ í†µí•´ í˜¸ì¶œë˜ë©°,
ì‹¤í—˜ì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ê´€ì¥í•˜ëŠ” ì¤‘ì•™ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°ì…ë‹ˆë‹¤.
"""

import argparse
import sys
from pathlib import Path
import logging
from datetime import datetime
from typing import Dict, Any
import torch

# --- í”„ë¡œì íŠ¸ ëª¨ë“ˆ Import ---
# ì´ íŒŒì¼ì€ íŒ¨í‚¤ì§€ ë‚´ë¶€ì— ìˆìœ¼ë¯€ë¡œ, ìƒëŒ€/ì ˆëŒ€ ê²½ë¡œë¡œ ëª¨ë“ˆì„ import í•©ë‹ˆë‹¤.
try:
    from scs.architecture import SCSSystem
    from scs.training import SCSTrainer, TrainingConfig, MultiObjectiveLoss, OptimizerFactory
    from scs.data import create_dataloader, SCSTokenizer
    from scs.utils import (
        setup_logging, load_config, save_config, set_random_seed,
        get_device, ModelBuilder
    )
except ImportError as e:
    print(f"âŒ ëª¨ë“ˆ import ì˜¤ë¥˜: {e}. íŒ¨í‚¤ì§€ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”. ('pip install -e .')")
    sys.exit(1)


# --- ëª…ë ¹í–‰ ì¸ì ë° ìœ íš¨ì„± ê²€ì‚¬ ---
def setup_args() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(description="SCS ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸")
    parser.add_argument("--mode", type=str, required=True, choices=["train", "evaluate"], help="ì‹¤í–‰ ëª¨ë“œ")
    parser.add_argument("--config", type=str, help="ì„¤ì • íŒŒì¼ ê²½ë¡œ (train ëª¨ë“œ í•„ìˆ˜)")
    parser.add_argument("--experiment_dir", type=str, help="ì‹¤í—˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ (evaluate ëª¨ë“œ í•„ìˆ˜)")
    parser.add_argument("--device", type=str, default="auto", help="ì—°ì‚° ì¥ì¹˜ ì„ íƒ (cuda, cpu, mps)")
    parser.add_argument("--seed", type=int, default=42, help="ì¬í˜„ì„±ì„ ìœ„í•œ ëœë¤ ì‹œë“œ")
    parser.add_argument("--debug", action="store_true", help="ë””ë²„ê·¸ ëª¨ë“œ (ìƒì„¸ ë¡œê¹…)")
    return parser

def validate_args(args: argparse.Namespace):
    if args.mode == "train" and not args.config:
        raise ValueError("train ëª¨ë“œì—ì„œëŠ” --config ì¸ìê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
    if args.mode == "evaluate" and not args.experiment_dir:
        raise ValueError("evaluate ëª¨ë“œì—ì„œëŠ” --experiment_dir ì¸ìê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
    if args.config and not Path(args.config).exists():
        raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.config}")
    if args.experiment_dir and not Path(args.experiment_dir).exists():
        raise FileNotFoundError(f"ì‹¤í—˜ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.experiment_dir}")


# --- ëª¨ë“œë³„ ì‹¤í–‰ í•¨ìˆ˜ ---
def train_mode(args: argparse.Namespace, config: Dict[str, Any]):
    """í•™ìŠµ ëª¨ë“œ ì‹¤í–‰"""
    # 1. ì‹¤í—˜ í™˜ê²½ ì„¤ì •
    experiment_name = f"{Path(args.config).stem}_{datetime.now().strftime('%Y%m%d_%H%M')}"
    experiment_dir = Path("experiments") / experiment_name
    experiment_dir.mkdir(parents=True, exist_ok=True)
    save_config(config, experiment_dir / "config.yaml")
    setup_logging(log_dir=experiment_dir / "logs", level=logging.DEBUG if args.debug else logging.INFO)
    logger = logging.getLogger(__name__)
    set_random_seed(args.seed)
    device = get_device(args.device)
    logger.info(f"ì‹¤í—˜ '{experiment_name}' ì‹œì‘ | ë””ë°”ì´ìŠ¤: {device}")

    try:
        # 2. ë°ì´í„° ë¡œë” ìƒì„±
        tokenizer = SCSTokenizer(config["data_loading"]["tokenizer"]["name"])
        train_loader = create_dataloader(dataset_name=config["task"]["dataset_name"], task_type=config["task"]["type"], split="train", batch_size=config["data_loading"]["batch_size"], max_length=config["data_loading"]["tokenizer"]["max_length"])
        val_loader = create_dataloader(dataset_name=config["task"]["dataset_name"], task_type=config["task"]["type"], split="validation", batch_size=1, max_length=config["data_loading"]["tokenizer"]["max_length"])

        # 3. ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤í™”
        config["io_system"]["input_interface"]["vocab_size"] = tokenizer.vocab_size
        config["io_system"]["output_interface"]["vocab_size"] = tokenizer.vocab_size
        model = ModelBuilder.build_scs_from_config(config, device=device)
        logger.info(f"ëª¨ë¸ ë§¤ê°œë³€ìˆ˜: {sum(p.numel() for p in model.parameters()):,}")

        # 4. í•™ìŠµ ì‹œìŠ¤í…œ êµ¬ì„±
        pad_token_id = tokenizer.tokenizer.pad_token_id
        training_config = TrainingConfig(pad_token_id=pad_token_id, device=device, **config["learning"])
        loss_fn = MultiObjectiveLoss(pad_token_id=pad_token_id)
        optimizer = OptimizerFactory.create(optimizer_type=config["learning"].get("optimizer", "adamw").lower(), model=model, config=training_config)
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=training_config.epochs)
        
        # 5. íŠ¸ë ˆì´ë„ˆ ìƒì„± ë° í•™ìŠµ
        trainer = SCSTrainer(model=model, config=training_config, loss_fn=loss_fn, optimizer=optimizer, scheduler=scheduler, tokenizer=tokenizer)
        trainer.train(train_loader, val_loader, save_path=str(experiment_dir / "checkpoints"))

        # 6. ìµœì¢… í‰ê°€
        logger.info("ìµœì¢… í‰ê°€ ì‹œì‘...")
        test_loader = create_dataloader(dataset_name=config["task"]["dataset_name"], task_type=config["task"]["type"], split="test", batch_size=1, max_length=config["data"]["tokenizer"]["max_length"])
        test_results = trainer.evaluate(test_loader)
        save_config(test_results, experiment_dir / "results.yaml")

    except Exception as e:
        logger.error(f"í•™ìŠµ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise

def evaluate_mode(args: argparse.Namespace):
    """í‰ê°€ ëª¨ë“œ ì‹¤í–‰"""
    # 1. í™˜ê²½ ì„¤ì •
    experiment_dir = Path(args.experiment_dir)
    config_path = experiment_dir / "config.yaml"
    checkpoint_path = experiment_dir / "checkpoints" / "best_model.pt"

    config = load_config(config_path)
    setup_logging(log_dir=experiment_dir / "logs" / "eval")
    logger = logging.getLogger(__name__)
    device = get_device(args.device)
    
    try:
        # 2. ë°ì´í„° ë° ëª¨ë¸ ë¡œë“œ
        tokenizer = SCSTokenizer(config["data_loading"]["tokenizer"]["name"])
        test_loader = create_dataloader(dataset_name=config["task"]["dataset_name"], task_type=config["task"]["type"], split="test", batch_size=1, max_length=config["data_loading"]["tokenizer"]["max_length"])
        
        config["io_system"]["input_interface"]["vocab_size"] = tokenizer.vocab_size
        config["io_system"]["output_interface"]["vocab_size"] = tokenizer.vocab_size
        model = ModelBuilder.build_scs_from_config(config, device=device)
        
        checkpoint = torch.load(checkpoint_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        
        # 3. íŠ¸ë ˆì´ë„ˆ ìƒì„± ë° í‰ê°€
        pad_token_id = tokenizer.tokenizer.pad_token_id
        training_config = TrainingConfig(pad_token_id=pad_token_id, device=device, **config["learning"])
        trainer = SCSTrainer(model=model, config=training_config, tokenizer=tokenizer)
        results = trainer.evaluate(test_loader)
        
        logger.info("ğŸ‰ í‰ê°€ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

    except Exception as e:
        logger.error(f"í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise


def main():
    """ë©”ì¸ CLI í•¨ìˆ˜"""
    parser = setup_args()
    args = parser.parse_args()
    try:
        validate_args(args)
        if args.mode == "train":
            config_path = Path(args.config)
            if not config_path.is_absolute():
                 config_path = Path.cwd() / config_path
            config = load_config(config_path)
            train_mode(args, config)
        elif args.mode == "evaluate":
            evaluate_mode(args)
    except (ValueError, FileNotFoundError) as e:
        print(f"âŒ ì…ë ¥ ì˜¤ë¥˜: {e}")
        sys.exit(1)
    except Exception as e:
        logging.getLogger(__name__).critical(f"ì‹¤í–‰ ì‹¤íŒ¨: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    # ì´ íŒŒì¼ì´ ì§ì ‘ ì‹¤í–‰ë  ë•ŒëŠ” ì•„ë¬´ ì¼ë„ ì¼ì–´ë‚˜ì§€ ì•ŠìŒ.
    # scs ëª…ë ¹ì–´ ë˜ëŠ” run.pyë¥¼ í†µí•´ main()ì´ í˜¸ì¶œë˜ì–´ì•¼ í•¨.
    pass