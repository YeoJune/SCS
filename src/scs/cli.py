# src/scs/cli.py
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
SCS (Spike-Based Cognitive System) ê³µì‹ CLI ì‹¤í–‰ ì§„ì…ì 
"""

import argparse
import sys
from pathlib import Path
import logging
from datetime import datetime
from typing import Dict, Any, List, Tuple
import torch

import matplotlib.pyplot as plt
import matplotlib.animation as animation
import numpy as np

# --- í”„ë¡œì íŠ¸ ëª¨ë“ˆ Import ---
# ì´ íŒŒì¼ì€ íŒ¨í‚¤ì§€ ë‚´ë¶€ì— ìˆìœ¼ë¯€ë¡œ, ìƒëŒ€/ì ˆëŒ€ ê²½ë¡œë¡œ ëª¨ë“ˆì„ import í•©ë‹ˆë‹¤.
try:
    from scs.architecture import SCSSystem
    from scs.training import SCSTrainer, TrainingConfig, MultiObjectiveLoss, TimingLoss, OptimizerFactory
    from scs.data import create_dataloader, SCSTokenizer
    from scs.utils import (
        setup_logging, load_config, save_config, set_random_seed,
        get_device, ModelBuilder
    )
except ImportError as e:
    print(f"âŒ ëª¨ë“ˆ import ì˜¤ë¥˜: {e}. íŒ¨í‚¤ì§€ê°€ ì˜¬ë°”ë¥´ê²Œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”. ('pip install -e .')")
    sys.exit(1)


# --- ëª…ë ¹í–‰ ì¸ì ë° ìœ íš¨ì„± ê²€ì‚¬ ---
def setup_args() -> argparse.ArgumentParser:
    """CLI ì¸ì ì„¤ì •"""
    parser = argparse.ArgumentParser(
        description="SCS ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ (ì„ ì–¸ì  ì¡°ë¦½ êµ¬ì¡° ì§€ì›)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # í•™ìŠµ ëª¨ë“œ
  scs --mode train --config configs/phase2_logiqa_small.yaml
  
  # í‰ê°€ ëª¨ë“œ  
  scs --mode evaluate --experiment_dir experiments/phase2_20241201_1430
  
  # ì„¤ì • íŒŒì¼ ê²€ì¦
  scs --mode validate --config configs/my_experiment.yaml
        """
    )
    parser.add_argument("--mode", type=str, required=True, 
                       choices=["train", "evaluate", "validate"], 
                       help="ì‹¤í–‰ ëª¨ë“œ")
    parser.add_argument("--config", type=str, 
                       help="ì„¤ì • íŒŒì¼ ê²½ë¡œ (train/validate ëª¨ë“œ í•„ìˆ˜)")
    parser.add_argument("--experiment_dir", type=str, 
                       help="ì‹¤í—˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ (evaluate ëª¨ë“œ í•„ìˆ˜)")
    parser.add_argument("--device", type=str, default="auto", 
                       help="ì—°ì‚° ì¥ì¹˜ ì„ íƒ (cuda, cpu, mps)")
    parser.add_argument("--seed", type=int, default=42, 
                       help="ì¬í˜„ì„±ì„ ìœ„í•œ ëœë¤ ì‹œë“œ")
    parser.add_argument("--debug", action="store_true", 
                       help="ë””ë²„ê·¸ ëª¨ë“œ (ìƒì„¸ ë¡œê¹…)")
    return parser

def validate_args(args: argparse.Namespace):
    """CLI ì¸ì ìœ íš¨ì„± ê²€ì‚¬"""
    if args.mode in ["train", "validate"] and not args.config:
        raise ValueError(f"{args.mode} ëª¨ë“œì—ì„œëŠ” --config ì¸ìê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
    if args.mode == "evaluate" and not args.experiment_dir:
        raise ValueError("evaluate ëª¨ë“œì—ì„œëŠ” --experiment_dir ì¸ìê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.")
    if args.config and not Path(args.config).exists():
        raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.config}")
    if args.experiment_dir and not Path(args.experiment_dir).exists():
        raise FileNotFoundError(f"ì‹¤í—˜ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.experiment_dir}")

# --- ì„¤ì • íŒŒì¼ ê²€ì¦ ëª¨ë“œ ---
def validate_mode(args: argparse.Namespace):
   """ì„¤ì • íŒŒì¼ êµ¬ì¡° ê²€ì¦ ëª¨ë“œ"""
   print("ğŸ” ì„¤ì • íŒŒì¼ êµ¬ì¡° ê²€ì¦ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
   
   try:
       # ì„¤ì • íŒŒì¼ ë¡œë“œ
       config_path = Path(args.config)
       if not config_path.is_absolute():
           config_path = Path.cwd() / config_path
       config = load_config(config_path)
       
       # ModelBuilderë¥¼ í†µí•œ ê¸°ë³¸ êµ¬ì¡° ê²€ì¦
       validation_errors = ModelBuilder.validate_config_structure(config)
       
       all_errors = validation_errors
       
       if not all_errors:
           print("âœ… ì„¤ì • íŒŒì¼ êµ¬ì¡°ê°€ ì˜¬ë°”ë¦…ë‹ˆë‹¤!")
           
           # ê°„ë‹¨í•œ ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸ (ì‹¤ì œ ë””ë°”ì´ìŠ¤ ì‚¬ìš© ì•ˆí•¨)
           try:
               model = ModelBuilder.build_scs_from_config(config, device="cpu")
               total_params = sum(p.numel() for p in model.parameters())
               print(f"ğŸ“Š ëª¨ë¸ ì •ë³´:")
               print(f"   - ì´ ë§¤ê°œë³€ìˆ˜: {total_params:,}")
               print(f"   - ë‡Œ ì˜ì—­ ìˆ˜: {len(config['brain_regions'])}")
               print(f"   - ì¶•ì‚­ ì—°ê²° ìˆ˜: {len(config['axonal_connections']['connections'])}")
               print(f"   - ì…ë ¥ ë…¸ë“œ: {config['system_roles']['input_node']}")
               print(f"   - ì¶œë ¥ ë…¸ë“œ: {config['system_roles']['output_node']}")
               
               # ì¶•ì‚­ ì—°ê²° ì°¨ì› ì •ë³´ ì¶œë ¥ (íŒ¨ì¹˜ ê¸°ë°˜)
               print(f"ğŸ“ ì¶•ì‚­ ì—°ê²° ì°¨ì› ê²€ì¦:")
               for conn in config['axonal_connections']['connections']:
                   source = conn['source']
                   target = conn['target']
                   source_size = config['brain_regions'][source]['grid_size']
                   target_size = config['brain_regions'][target]['grid_size']
                   
                   patch_size = conn.get('patch_size', 4)  # íŒ¨ì¹˜ í¬ê¸°
                   
                   # ì†ŒìŠ¤ ê¸°ì¤€ íŒ¨ì¹˜ ìˆ˜ ê³„ì‚°
                   source_patches_h = source_size[0] // patch_size
                   source_patches_w = source_size[1] // patch_size
                   num_patches = source_patches_h * source_patches_w
                   
                   # íƒ€ê²Ÿ íŒ¨ì¹˜ í¬ê¸° (ë™ì¼í•œ íŒ¨ì¹˜ ìˆ˜ ë§ì¶”ê¸°)
                   target_patch_h = target_size[0] // source_patches_h if source_patches_h > 0 else target_size[0]
                   target_patch_w = target_size[1] // source_patches_w if source_patches_w > 0 else target_size[1]
                   
                   # íŒ¨ì¹˜ë³„ íŒŒë¼ë¯¸í„° ìˆ˜
                   source_patch_size = patch_size * patch_size
                   target_patch_size = target_patch_h * target_patch_w
                   gate_params = num_patches
                   inner_params = num_patches * target_patch_size * source_patch_size
                   total_conn_params = gate_params + inner_params
                   
                   print(f"   - {source}â†’{target}: {source_size} (patch:{patch_size}Ã—{patch_size}) â†’ {num_patches}ê°œ íŒ¨ì¹˜ â†’ {target_size}")
                   print(f"     íŒ¨ì¹˜ ë°°ì¹˜: {source_patches_h}Ã—{source_patches_w} â†’ {target_patch_h}Ã—{target_patch_w}, íŒŒë¼ë¯¸í„°: {total_conn_params:,}ê°œ")
               
               print("âœ… ëª¨ë¸ ìƒì„± ë° ì°¨ì› ê²€ì¦ í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
           except Exception as model_error:
               print(f"âš ï¸  ëª¨ë¸ ìƒì„± í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {model_error}")
               return False
               
       else:
           print("âŒ ì„¤ì • íŒŒì¼ì—ì„œ ë‹¤ìŒ ì˜¤ë¥˜ë“¤ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:")
           for i, error in enumerate(all_errors, 1):
               print(f"   {i}. {error}")
           
           return False
           
       return True
       
   except Exception as e:
       print(f"âŒ ì„¤ì • íŒŒì¼ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
       return False
   
# --- ë°ì´í„°ì…‹ ì´ë¦„ ì¶”ì¶œ í—¬í¼ ---
def get_dataset_name_from_config(config: Dict[str, Any], logger) -> str:
    """ì„¤ì • íŒŒì¼ì—ì„œ ë°ì´í„°ì…‹ ì´ë¦„ ì¶”ì¶œ (ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)"""
    dataset_name = None
    
    # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ë°ì´í„°ì…‹ ì´ë¦„ íƒìƒ‰ (ìˆœì„œ ì¤‘ìš”)
    if "task" in config and "dataset_name" in config["task"]:
        dataset_name = config["task"]["dataset_name"]
    elif "data_loading" in config and "dataset_name" in config["data_loading"]:
        dataset_name = config["data_loading"]["dataset_name"]
    elif "data" in config and "dataset_name" in config["data"]:
        dataset_name = config["data"]["dataset_name"]  
    elif "dataset_name" in config:
        dataset_name = config["dataset_name"]
    else:
        # ê¸°ë³¸ê°’ ì‚¬ìš©
        dataset_name = "datatune/LogiQA2.0"
        logger.warning(f"dataset_name not found in config, using default: {dataset_name}")
    
    return dataset_name


# --- í•™ìŠµ ì„¤ì • ì¶”ì¶œ ë° ì •ê·œí™” í—¬í¼ ---
def extract_and_normalize_training_config(config: Dict[str, Any]) -> Tuple[Dict[str, Any], Dict[str, Any], Dict[str, Any]]:
    """ì„¤ì •ì—ì„œ í•™ìŠµ íŒŒë¼ë¯¸í„° ì¶”ì¶œ ë° ì •ê·œí™”"""
    raw_config = config.get("learning", config.get("training", {})).copy()
    
    # gradual_unfreezing ë³„ë„ ì¶”ì¶œ
    unfreezing_config = raw_config.pop("gradual_unfreezing", {})
    
    # íŒŒë¼ë¯¸í„° ì´ë¦„ ì •ê·œí™”
    param_mapping = {
        "base_learning_rate": "learning_rate",
        "max_grad_norm": "gradient_clip_norm", 
        "eval_every_n_epochs": "eval_every",
        "save_every_n_epochs": "save_every",
        "use_schedule_sampling": "use_scheduled_sampling",
        "scheduled_sampling_start": "ss_start_prob",
        "scheduled_sampling_end": "ss_end_prob",
        "scheduled_sampling_decay": "ss_decay_epochs",
    }
    
    for old_name, new_name in param_mapping.items():
        if old_name in raw_config:
            raw_config[new_name] = raw_config.pop(old_name)
    
    # TrainingConfigê°€ í—ˆìš©í•˜ëŠ” íŒŒë¼ë¯¸í„°
    valid_params = {
        "epochs", "learning_rate", "weight_decay", "gradient_clip_norm",
        "eval_every", "save_every", "early_stopping_patience", "max_clk_training",
        "use_scheduled_sampling", "ss_start_prob", "ss_end_prob", "ss_decay_epochs",
        "eta_min", "use_curriculum_learning", "curriculum_schedule"
    }
    filtered_config = {k: v for k, v in raw_config.items() if k in valid_params}
    
    # íƒ€ì… ë³€í™˜
    float_params = ["learning_rate", "weight_decay", "gradient_clip_norm", "ss_start_prob", "ss_end_prob", "eta_min"]
    int_params = ["epochs", "eval_every", "save_every", "early_stopping_patience", "max_clk_training", "ss_decay_epochs"]
    bool_params = ["use_scheduled_sampling", "use_curriculum_learning"]
    
    for param in float_params:
        if param in filtered_config:
            filtered_config[param] = float(filtered_config[param])
    
    for param in int_params:
        if param in filtered_config:
            filtered_config[param] = int(filtered_config[param])
    
    for param in bool_params:
        if param in filtered_config:
            filtered_config[param] = bool(filtered_config[param])
    
    return filtered_config, raw_config, unfreezing_config

# ìƒˆë¡œ ì¶”ê°€í•  í•¨ìˆ˜ (train_mode í•¨ìˆ˜ ë’¤ì— ì¶”ê°€)
def _save_spike_visualizations(model, experiment_dir, test_loader, logger):
   """ì„ì‹œ: ìŠ¤íŒŒì´í¬ íŒ¨í„´ê³¼ ê°€ì¤‘ì¹˜ íˆíŠ¸ë§µ ì‹œê°í™”"""
   try:
       vis_dir = experiment_dir / "visualizations"
       vis_dir.mkdir(exist_ok=True)
       
       # ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ ì‚¬ìš©
       first_batch = next(iter(test_loader))
       input_tokens = first_batch['input_tokens'][:1].to(model.device)  # ì²« ë²ˆì§¸ ìƒ˜í”Œë§Œ
       attention_mask = first_batch.get('attention_mask')
       if attention_mask is not None:
           attention_mask = attention_mask[:1].to(model.device)
       
       # ìŠ¤íŒŒì´í¬ íŒ¨í„´ ìˆ˜ì§‘ì„ ìœ„í•œ ëª¨ë¸ ì‹¤í–‰
       model.eval()
       with torch.no_grad():
           # ëª¨ë¸ ìƒíƒœ ì´ˆê¸°í™”
           model.reset_state(batch_size=1)
           
           all_spike_patterns = []  # CLKë³„ ìŠ¤íŒŒì´í¬ íŒ¨í„´ ì €ì¥
           
           max_clk = min(500, model.timing_manager.max_processing_clk)  # ì‹œê°í™”ìš©ìœ¼ë¡œ ì œí•œ
           
           for clk in range(max_clk):
               model.current_clk = clk
               
               # í˜„ì¬ CLKì˜ ìŠ¤íŒŒì´í¬ ê³„ì‚°
               current_spikes = model._phase1_compute_spikes()
               
               # ì™¸ë¶€ ì…ë ¥ ì ìš© (ìˆ˜ì •ëœ ë¶€ë¶„)
               external_input = model._get_external_input_at_clk(
                   input_tokens, clk, attention_mask
               )
               
               # ìƒíƒœ ì—…ë°ì´íŠ¸
               model._phase2_update_states(external_input, current_spikes)
               model._phase3_post_spike_processing(current_spikes)
               
               # ìŠ¤íŒŒì´í¬ íŒ¨í„´ ì €ì¥ (CPUë¡œ ì´ë™)
               spike_pattern = {}
               for node_name, spikes in current_spikes.items():
                   spike_pattern[node_name] = spikes[0].cpu().numpy()  # [H, W]
               all_spike_patterns.append(spike_pattern)
       
       # 1. CLKë³„ ìŠ¤íŒŒì´í¬ íŒ¨í„´ ì´ë¯¸ì§€ ìƒì„±
       node_names = list(all_spike_patterns[0].keys())
       num_nodes = len(node_names)
       
       spike_dir = vis_dir / "spike_patterns"
       spike_dir.mkdir(exist_ok=True)
       
       for clk, spike_pattern in enumerate(all_spike_patterns):
           fig, axes = plt.subplots(1, num_nodes, figsize=(4*num_nodes, 4))
           if num_nodes == 1:
               axes = [axes]
           
           for i, node_name in enumerate(node_names):
               spikes = spike_pattern[node_name]
               im = axes[i].imshow(spikes, cmap='hot', vmin=0, vmax=1)
               axes[i].set_title(f'{node_name}\nCLK {clk}')
               axes[i].set_xlabel('Width')
               axes[i].set_ylabel('Height')
               plt.colorbar(im, ax=axes[i])
           
           plt.tight_layout()
           plt.savefig(spike_dir / f"clk_{clk:03d}.png", dpi=100, bbox_inches='tight')
           plt.close()
       
       logger.info(f"âœ… ìŠ¤íŒŒì´í¬ íŒ¨í„´ ì´ë¯¸ì§€ {len(all_spike_patterns)}ê°œ ì €ì¥: {spike_dir}")
       
       # 2. ìŠ¤íŒŒì´í¬ íŒ¨í„´ GIF ì• ë‹ˆë©”ì´ì…˜ ìƒì„±
       try:
           fig, axes = plt.subplots(1, num_nodes, figsize=(4*num_nodes, 4))
           if num_nodes == 1:
               axes = [axes]
           
           # ì´ˆê¸° í”Œë¡¯ ì„¤ì •
           ims = []
           for i, node_name in enumerate(node_names):
               im = axes[i].imshow(all_spike_patterns[0][node_name], 
                                  cmap='hot', vmin=0, vmax=1)
               axes[i].set_title(f'{node_name}\nCLK 0')
               axes[i].set_xlabel('Width')
               axes[i].set_ylabel('Height')
               plt.colorbar(im, ax=axes[i])
               ims.append(im)
           
           def animate(frame):
               spike_pattern = all_spike_patterns[frame]
               for i, (node_name, im) in enumerate(zip(node_names, ims)):
                   im.set_array(spike_pattern[node_name])
                   axes[i].set_title(f'{node_name}\nCLK {frame}')
               return ims
           
           # ì• ë‹ˆë©”ì´ì…˜ ìƒì„±
           anim = animation.FuncAnimation(
               fig, animate, frames=len(all_spike_patterns),
               interval=200, blit=True, repeat=True
           )
           
           # GIF ì €ì¥
           gif_path = vis_dir / "spike_animation.gif"
           anim.save(gif_path, writer='pillow', fps=5)
           plt.close()
           
           logger.info(f"ğŸ¬ ìŠ¤íŒŒì´í¬ íŒ¨í„´ GIF ìƒì„±: {gif_path}")
           
       except Exception as gif_error:
           logger.warning(f"âš ï¸ GIF ìƒì„± ì¤‘ ì˜¤ë¥˜ (ê°œë³„ ì´ë¯¸ì§€ëŠ” ì •ìƒ ì €ì¥ë¨): {gif_error}")
       
       # 3. Influence ê°€ì¤‘ì¹˜ íˆíŠ¸ë§µ ìƒì„±
       weight_dir = vis_dir / "weight_heatmaps"
       weight_dir.mkdir(exist_ok=True)
       
       # ë…¸ë“œë³„ influence ê°€ì¤‘ì¹˜
       fig, axes = plt.subplots(1, num_nodes, figsize=(4*num_nodes, 4))
       if num_nodes == 1:
           axes = [axes]
       
       for i, node_name in enumerate(node_names):
           node = model.nodes[node_name]
           influence = node.influence_strength.detach().cpu().numpy()
           
           im = axes[i].imshow(influence, cmap='RdBu_r', vmin=-5, vmax=5)
           axes[i].set_title(f'{node_name}\nInfluence Strength')
           axes[i].set_xlabel('Width')
           axes[i].set_ylabel('Height')
           plt.colorbar(im, ax=axes[i])
       
       plt.tight_layout()
       plt.savefig(weight_dir / "node_influence_weights.png", dpi=100, bbox_inches='tight')
       plt.close()
       
       # ì¶•ì‚­ ì—°ê²° ê°€ì¤‘ì¹˜ (ì¼ë¶€ë§Œ)
       if hasattr(model.axonal_connections, 'adjacency_matrices'):
           adj_matrices = model.axonal_connections.adjacency_matrices
           num_connections = min(6, len(adj_matrices))  # ìµœëŒ€ 6ê°œë§Œ ì‹œê°í™”
           
           if num_connections > 0:
               cols = min(3, num_connections)
               rows = (num_connections + cols - 1) // cols
               
               fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))
               if rows == 1 and cols == 1:
                   axes = [axes]
               elif rows == 1 or cols == 1:
                   axes = axes.flatten()
               else:
                   axes = axes.flatten()
               
               for i, (conn_name, weight_matrix) in enumerate(list(adj_matrices.items())[:num_connections]):
                   weights = weight_matrix.detach().cpu().numpy()
                   
                   # í° í–‰ë ¬ì€ ìƒ˜í”Œë§
                   if weights.shape[0] > 100 or weights.shape[1] > 100:
                       step_i = max(1, weights.shape[0] // 50)
                       step_j = max(1, weights.shape[1] // 50)
                       weights = weights[::step_i, ::step_j]
                   
                   im = axes[i].imshow(weights, cmap='RdBu_r', aspect='auto')
                   axes[i].set_title(f'{conn_name}\nAxonal Weights')
                   axes[i].set_xlabel('Source')
                   axes[i].set_ylabel('Target')
                   plt.colorbar(im, ax=axes[i])
               
               # ë¹ˆ subplot ìˆ¨ê¸°ê¸°
               for j in range(i+1, len(axes)):
                   axes[j].set_visible(False)
               
               plt.tight_layout()
               plt.savefig(weight_dir / "axonal_connection_weights.png", dpi=100, bbox_inches='tight')
               plt.close()
       
       logger.info(f"âœ… ê°€ì¤‘ì¹˜ íˆíŠ¸ë§µ ì €ì¥: {weight_dir}")
       logger.info(f"ğŸ“ ëª¨ë“  ì‹œê°í™” íŒŒì¼ ì €ì¥ ì™„ë£Œ: {vis_dir}")
       
   except Exception as e:
       logger.warning(f"âš ï¸ ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ê³„ì†): {e}")
       
def _generate_io_example_metric(model, test_loader, experiment_dir, logger, device):
    """
    IO íŒŒì´í”„ë¼ì¸ ì¤‘ê°„ê°’ ì¶”ì  ë° í•™ìŠµ ì „í›„ ë¹„êµ (v5.0 ë§ì¶¤)
    
    ì£¼ìš” ë³€ê²½ì‚¬í•­:
    - InputInterface: ì‚¬ì „ ì •ê·œí™” ì œê±°, dropout ì¶”ê°€ ë°˜ì˜
    - OutputInterface: compressor_power ë³€ê²½, ë©”ëª¨ë¦¬ ìŠ¤ì¼€ì¼ ì¶”ì 
    """
    try:
        # ì²« ë²ˆì§¸ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ì¶”ì¶œ
        first_batch = next(iter(test_loader))
        sample_input = first_batch['input_tokens'][0:1].to(device)  # [1, seq_len]
        sample_target = first_batch['target_tokens'][0:1].to(device)
        sample_mask = first_batch.get('attention_mask')
        if sample_mask is not None:
            sample_mask = sample_mask[0:1].to(device)
        
        logger.info(f"ğŸ” ë¶„ì„ ëŒ€ìƒ ìƒ˜í”Œ:")
        logger.info(f"   ì…ë ¥ ê¸¸ì´: {sample_input.shape[1]}")
        logger.info(f"   íƒ€ê²Ÿ ê¸¸ì´: {sample_target.shape[1]}")
        
        def trace_pipeline(model, input_tokens, target_tokens, attention_mask, phase_name):
            """íŒŒì´í”„ë¼ì¸ ì¤‘ê°„ê°’ ì¶”ì  (v5.0 ë°˜ì˜)"""
            model.eval()
            traced_data = {"phase": phase_name, "steps": []}
            
            with torch.no_grad():
                # ============ InputInterface ì¶”ì  ============
                if hasattr(model, 'input_interface'):
                    window_size = model.input_interface.window_size
                    if input_tokens.shape[1] >= window_size:
                        test_window = input_tokens[:, :window_size]
                    else:
                        pad_size = window_size - input_tokens.shape[1]
                        padding = torch.zeros(1, pad_size, dtype=torch.long, device=input_tokens.device)
                        test_window = torch.cat([padding, input_tokens], dim=1)
                    
                    # Step 1: í† í° ì„ë² ë”© (T5 ê°€ì¤‘ì¹˜)
                    token_embeds = model.input_interface.token_embedding(test_window)
                    traced_data["steps"].append({
                        "name": "input_token_embedding",
                        "shape": list(token_embeds.shape),
                        "mean": token_embeds.mean().item(),
                        "std": token_embeds.std().item(),
                        "min": token_embeds.min().item(),
                        "max": token_embeds.max().item(),
                        "description": "T5 í† í° ì„ë² ë”© (stdâ‰ˆ23 ì˜ˆìƒ)"
                    })
                    
                    # Step 2: ìœ„ì¹˜ ì„ë² ë”© ì¶”ê°€ (CLS í† í° ì œê±°ë¨)
                    windowed_input = token_embeds
                    if model.input_interface.use_positional_encoding:
                        seq_len = test_window.shape[1]
                        positions = torch.arange(seq_len, device=device).unsqueeze(0)
                        position_embeds = model.input_interface.position_embedding(positions)
                        windowed_input = windowed_input + position_embeds
                    
                    traced_data["steps"].append({
                        "name": "input_with_pos",
                        "shape": list(windowed_input.shape),
                        "mean": windowed_input.mean().item(),
                        "std": windowed_input.std().item(),
                        "description": "ìœ„ì¹˜ ì„ë² ë”© ì¶”ê°€ (CLS í† í° ì œê±°ë¨, ì—¬ì „íˆ stdâ‰ˆ23)"
                    })
                    
                    # Step 3: Dropout ì ìš© (v5.0 ìƒˆë¡œ ì¶”ê°€)
                    if hasattr(model.input_interface, 'dropout'):
                        dropped_input = model.input_interface.dropout(windowed_input)
                        traced_data["steps"].append({
                            "name": "input_after_dropout",
                            "shape": list(dropped_input.shape),
                            "mean": dropped_input.mean().item(),
                            "std": dropped_input.std().item(),
                            "description": "T5 ìŠ¤íƒ€ì¼ dropout ì ìš©"
                        })
                        windowed_input = dropped_input
                    
                    # Step 4: Transformer Encoder (v5.0: CLS í† í° ì œê±°, ë§ˆì§€ë§‰ í† í° ì‚¬ìš©)
                    # norm_first=Trueì´ë¯€ë¡œ ë‚´ë¶€ì—ì„œ ì •ê·œí™” ìˆ˜í–‰
                    encoder_output = model.input_interface.transformer_encoder(windowed_input)
                    context_vector = encoder_output[:, -1, :]  # ë§ˆì§€ë§‰ í† í°
                    traced_data["steps"].append({
                        "name": "encoder_output",
                        "shape": list(encoder_output.shape),
                        "full_mean": encoder_output.mean().item(),
                        "full_std": encoder_output.std().item(),
                        "last_token_mean": context_vector.mean().item(),
                        "last_token_std": context_vector.std().item(),
                        "description": "T5 encoder ì¶œë ¥, ë§ˆì§€ë§‰ í† í°ì„ contextë¡œ ì‚¬ìš©"
                    })
                    
                    # Step 5: Pattern Mapper
                    membrane_logits = model.input_interface.pattern_mapper(context_vector)
                    traced_data["steps"].append({
                        "name": "membrane_logits",
                        "shape": list(membrane_logits.shape),
                        "mean": membrane_logits.mean().item(),
                        "std": membrane_logits.std().item(),
                        "min": membrane_logits.min().item(),
                        "max": membrane_logits.max().item(),
                        "description": "ì§êµ ì´ˆê¸°í™”ëœ linear ë§¤í•‘ (stdâ‰ˆ1.0 ì˜ˆìƒ)"
                    })
                    
                    # Step 6: ìµœì¢… ë§‰ì „ìœ„ íŒ¨í„´
                    pattern_probs = torch.softmax(membrane_logits / model.input_interface.softmax_temperature, dim=-1)
                    total_energy = model.input_interface.grid_height * model.input_interface.grid_width * model.input_interface.input_power
                    final_pattern = pattern_probs * total_energy
                    final_pattern_2d = final_pattern.view(1, model.input_interface.grid_height, model.input_interface.grid_width)
                    
                    # íŒ¨í„´ ë¶„ì„
                    active_neurons = (final_pattern > 0.1).sum().item()  # ì„ê³„ê°’ ì´ìƒ í™œì„±í™”
                    max_activation = final_pattern.max().item()
                    sparsity = (final_pattern < 0.01).sum().item() / final_pattern.numel()
                    
                    traced_data["steps"].append({
                        "name": "final_membrane_pattern",
                        "shape": list(final_pattern_2d.shape),
                        "mean": final_pattern_2d.mean().item(),
                        "std": final_pattern_2d.std().item(),
                        "total_energy": total_energy,
                        "active_neurons": active_neurons,
                        "max_activation": max_activation,
                        "sparsity_ratio": sparsity,
                        "softmax_temperature": model.input_interface.softmax_temperature,
                        "input_power": model.input_interface.input_power,
                        "description": "Softmax + ì—ë„ˆì§€ ìŠ¤ì¼€ì¼ë§ëœ ìµœì¢… íŒ¨í„´"
                    })
                
                # ============ OutputInterface ì¶”ì  ============
                if hasattr(model, 'output_interface'):
                    # v6.0: OutputInterface ìƒíƒœ ì´ˆê¸°í™” (íˆë“  ìœˆë„ìš° ë‚´ë¶€ ê´€ë¦¬)
                    grid_h, grid_w = model.output_interface.grid_height, model.output_interface.grid_width
                    batch_size = 1
                    model.output_interface.reset_state(batch_size)
                    
                    # ì¼€ì´ìŠ¤ 1: ì™„ì „ ë¹„í™œì„±í™” ìŠ¤íŒŒì´í¬ë¡œ ìœˆë„ìš° ì—…ë°ì´íŠ¸
                    zero_spikes = torch.zeros(batch_size, grid_h, grid_w, device=device)
                    model.output_interface.update_hidden_window(zero_spikes)
                    
                    # ì¼€ì´ìŠ¤ 2: ìŠ¤íŒŒìŠ¤ í™œì„±í™” (10ê°œ ë‰´ëŸ°)ë¡œ ìœˆë„ìš° ì—…ë°ì´íŠ¸
                    sparse_spikes = torch.zeros(batch_size, grid_h, grid_w, device=device)
                    flat_sparse = sparse_spikes.view(batch_size, -1)
                    indices = torch.randperm(grid_h * grid_w)[:10]
                    flat_sparse[:, indices] = 1.0
                    sparse_spikes = flat_sparse.view(batch_size, grid_h, grid_w)
                    model.output_interface.update_hidden_window(sparse_spikes)
                    
                    # í˜„ì¬ íˆë“  ìœˆë„ìš° ìƒíƒœ ë¶„ì„
                    current_hidden_window = model.output_interface.hidden_window  # [B, window_size, embedding_dim]
                    compressor_power = model.output_interface.compressor_power.item()
                    
                    # ìœˆë„ìš°ì˜ ë§ˆì§€ë§‰ ë²¡í„° (ê°€ì¥ ìµœê·¼ ì—…ë°ì´íŠ¸ëœ ê²ƒ) ë¶„ì„
                    latest_hidden = current_hidden_window[:, -1, :]  # [B, embedding_dim]
                    
                    traced_data["steps"].append({
                        "name": "output_hidden_window_analysis",
                        "compressor_power": compressor_power,
                        "hidden_window_shape": list(current_hidden_window.shape),
                        "latest_hidden_vector": {
                            "shape": list(latest_hidden.shape),
                            "mean": latest_hidden.mean().item(),
                            "std": latest_hidden.std().item(),
                            "l2_norm": torch.norm(latest_hidden).item()
                        },
                        "window_stats": {
                            "window_mean": current_hidden_window.mean().item(),
                            "window_std": current_hidden_window.std().item(),
                            "window_l2_norm": torch.norm(current_hidden_window).item()
                        },
                        "description": f"v6.0: íˆë“  ìœˆë„ìš° ë‚´ë¶€ ê´€ë¦¬, compressor_power={compressor_power:.3f}, ìŠ¤íŒŒìŠ¤ ìŠ¤íŒŒì´í¬ ì—…ë°ì´íŠ¸ í›„ ìƒíƒœ"
                    })
                    
                    # ë””ì½”ë” ì…ë ¥ ì„ë² ë”© ì¶”ì 
                    if target_tokens.shape[1] > 0:
                        window_size = model.output_interface.window_size
                        if target_tokens.shape[1] >= window_size:
                            decoder_window = target_tokens[:, :window_size]
                        else:
                            decoder_window = target_tokens
                        
                        target_embeds = model.output_interface._prepare_target_embeddings(decoder_window)
                        traced_data["steps"].append({
                            "name": "output_target_embeddings",
                            "shape": list(target_embeds.shape),
                            "mean": target_embeds.mean().item(),
                            "std": target_embeds.std().item(),
                            "description": "T5 ë””ì½”ë” ì…ë ¥ ì„ë² ë”© (RMSNorm ì •ê·œí™”ë¨)"
                        })
            
            return traced_data
        
        # ë¶„ì„ ì‹¤í–‰
        logger.info("ğŸ“Š í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ì¶”ì  ì¤‘...")
        trained_trace = trace_pipeline(model, sample_input, sample_target, sample_mask, "trained_model")
        
        # ê²°ê³¼ ì €ì¥
        metric_dir = experiment_dir / "io_example_metrics"
        metric_dir.mkdir(exist_ok=True)
        
        import json
        with open(metric_dir / "pipeline_trace_trained_v5.json", 'w') as f:
            json.dump(trained_trace, f, indent=2)
        
        # ìš”ì•½ ë¡œê¹…
        logger.info(f"âœ… IO íŒŒì´í”„ë¼ì¸ ë¶„ì„ ì™„ë£Œ (v5.0): {metric_dir}")
        logger.info(f"   ğŸ“Š ì¶”ì ëœ ë‹¨ê³„ ìˆ˜: {len(trained_trace['steps'])}")
        
        # í•µì‹¬ ì§€í‘œ ìš”ì•½
        key_metrics = {}
        for step in trained_trace['steps']:
            if step['name'] == 'input_token_embedding':
                key_metrics['token_embed_std'] = step['std']
            elif step['name'] == 'encoder_output':
                key_metrics['last_token_std'] = step['last_token_std']
            elif step['name'] == 'membrane_logits':
                key_metrics['membrane_logits_std'] = step['std']
            elif step['name'] == 'output_hidden_vector_analysis':
                key_metrics['compressor_power'] = step['compressor_power']
                key_metrics['sparse_hidden_std'] = step['sparse_spikes']['std']
        
        logger.info("ğŸ¯ í•µì‹¬ ì§€í‘œ ìš”ì•½:")
        logger.info(f"   í† í° ì„ë² ë”© std: {key_metrics.get('token_embed_std', 'N/A'):.3f} (ëª©í‘œ: ~23)")
        logger.info(f"   ë§ˆì§€ë§‰ í† í° std: {key_metrics.get('last_token_std', 'N/A'):.3f} (T5 encoder ì¶œë ¥)")
        logger.info(f"   ë§‰ì „ìœ„ ë¡œì§“ std: {key_metrics.get('membrane_logits_std', 'N/A'):.3f} (ì§êµ ë³€í™˜)")
        logger.info(f"   ì••ì¶• íŒŒì›Œ: {key_metrics.get('compressor_power', 'N/A'):.3f} (ëª©í‘œ: ~0.1)")
        logger.info(f"   ìŠ¤íŒŒìŠ¤ íˆë“  std: {key_metrics.get('sparse_hidden_std', 'N/A'):.3f} (ëª©í‘œ: ~0.1)")
        
    except Exception as e:
        logger.warning(f"âš ï¸ IO íŒŒì´í”„ë¼ì¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        logger.debug(traceback.format_exc())

# --- ëª¨ë“œë³„ ì‹¤í–‰ í•¨ìˆ˜ ---
def train_mode(args: argparse.Namespace, config: Dict[str, Any]):
    """í•™ìŠµ ëª¨ë“œ ì‹¤í–‰ (ìƒˆë¡œìš´ ì„ ì–¸ì  ì¡°ë¦½ êµ¬ì¡° ì§€ì›)"""
    # 1. ì‹¤í—˜ í™˜ê²½ ì„¤ì •
    experiment_name = f"{Path(args.config).stem}_{datetime.now().strftime('%Y%m%d_%H%M')}"
    experiment_dir = Path("experiments") / experiment_name
    experiment_dir.mkdir(parents=True, exist_ok=True)
    save_config(config, experiment_dir / "config.yaml")
    setup_logging(log_dir=experiment_dir / "logs", level=logging.DEBUG if args.debug else logging.INFO)
    logger = logging.getLogger(__name__)
    set_random_seed(args.seed)
    device = get_device(args.device)
    logger.info(f"ğŸš€ ì‹¤í—˜ '{experiment_name}' ì‹œì‘ | ë””ë°”ì´ìŠ¤: {device}")

    try:
        # 2. ì„¤ì • íŒŒì¼ ì‚¬ì „ ê²€ì¦ (ì°¨ì› ê²€ì¦ í¬í•¨)
        logger.info("ğŸ“‹ ì„¤ì • íŒŒì¼ êµ¬ì¡° ë° ì°¨ì› ê²€ì¦ ì¤‘...")
        validation_errors = ModelBuilder.validate_config_structure(config)
        all_errors = validation_errors
        
        if all_errors:
            logger.error("âŒ ì„¤ì • íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨:")
            for error in all_errors:
                logger.error(f"   - {error}")
            raise ValueError("ì„¤ì • íŒŒì¼ì— ì˜¤ë¥˜ê°€ ìˆìŠµë‹ˆë‹¤. ìœ„ ë©”ì‹œì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        logger.info("âœ… ì„¤ì • íŒŒì¼ êµ¬ì¡° ë° ì°¨ì› ê²€ì¦ ì™„ë£Œ")

        # 3. ë°ì´í„° ë¡œë” ìƒì„±
        logger.info("ğŸ“Š ë°ì´í„° ë¡œë” ìƒì„± ì¤‘...")
        tokenizer = SCSTokenizer(config["data_loading"]["tokenizer"]["name"])

        # í† í¬ë‚˜ì´ì € ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
        tokenizer_config = config["data_loading"]["tokenizer"]
        tokenizer_config["pad_token_id"] = getattr(tokenizer.tokenizer, 'pad_token_id', 0)
        tokenizer_config["eos_token_id"] = getattr(tokenizer.tokenizer, 'eos_token_id', 1)
        tokenizer_config["bos_token_id"] = getattr(tokenizer.tokenizer, 'bos_token_id', 2)
        tokenizer_config["unk_token_id"] = getattr(tokenizer.tokenizer, 'unk_token_id', 3)
        pad_token_id = tokenizer_config["pad_token_id"]

        dataset_name = get_dataset_name_from_config(config, logger)
        
        # ìƒˆë¡œ ì¶”ê°€: learning_styleê³¼ BERT ì„¤ì • ì¶”ì¶œ
        task_config = config.get("task", {})
        learning_style = task_config.get("learning_style", "generative")
        bert_config = task_config.get("bert_config", None)
        
        # ë¡œê¹…
        if learning_style == "bert":
            logger.info(f"ğŸ­ BERT ìŠ¤íƒ€ì¼ í•™ìŠµ ëª¨ë“œ í™œì„±í™”")
            if bert_config:
                logger.info(f"ğŸ“ BERT ì„¤ì •: {bert_config}")
        else:
            logger.info(f"ğŸ¯ ê¸°ì¡´ ìƒì„±í˜•(Generative) í•™ìŠµ ëª¨ë“œ")

        # ë°ì´í„° ì„¤ì • ì¶”ì¶œ (ê¸°ì¡´ê³¼ ë™ì¼)
        data_config = config.get("data", {})
        
        train_samples = data_config.get("train_samples", -1)
        val_samples = data_config.get("val_samples", -1)
        test_samples = data_config.get("test_samples", -1)
        task_id = task_config.get("task_id", 1)
        
        # í›ˆë ¨ ë°ì´í„° ë¡œë” ìƒì„± (ìƒˆ íŒŒë¼ë¯¸í„° ì „ë‹¬)
        train_loader = create_dataloader(
            dataset_name=dataset_name, 
            split="train", 
            batch_size=config["data_loading"]["batch_size"], 
            max_length=config["data_loading"]["tokenizer"]["max_length"], 
            tokenizer=tokenizer,
            num_samples=train_samples,
            task_id=task_id,
            learning_style=learning_style,  # ìƒˆë¡œ ì¶”ê°€ëœ íŒŒë¼ë¯¸í„°
            bert_config=bert_config  # ìƒˆë¡œ ì¶”ê°€ëœ íŒŒë¼ë¯¸í„°
        )

        # ê²€ì¦ ë°ì´í„° ë¡œë” ìƒì„± (ìƒˆ íŒŒë¼ë¯¸í„° ì „ë‹¬)
        val_loader = create_dataloader(
            dataset_name=dataset_name, 
            split="validation", 
            batch_size=config["data_loading"]["batch_size"],  # ğŸ”§ 1 ëŒ€ì‹  ë™ì¼í•œ ë°°ì¹˜ í¬ê¸°
            max_length=config["data_loading"]["tokenizer"]["max_length"], 
            tokenizer=tokenizer,
            num_samples=val_samples,
            task_id=task_id,
            learning_style=learning_style,  # ìƒˆë¡œ ì¶”ê°€ëœ íŒŒë¼ë¯¸í„°
            bert_config=bert_config  # ìƒˆë¡œ ì¶”ê°€ëœ íŒŒë¼ë¯¸í„°
        )
        
        logger.info(f"âœ… ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ (ë°ì´í„°ì…‹: {dataset_name}, ìŠ¤íƒ€ì¼: {learning_style})")

        # 4. ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤í™” (ìƒˆë¡œìš´ ì„ ì–¸ì  ì¡°ë¦½ ë°©ì‹)
        logger.info("ğŸ§  SCS ëª¨ë¸ ìƒì„± ì¤‘...")
        config["io_system"]["input_interface"]["vocab_size"] = tokenizer.vocab_size
        config["io_system"]["output_interface"]["vocab_size"] = tokenizer.vocab_size

        model = ModelBuilder.build_scs_from_config(config, device=device)
        
        total_params = sum(p.numel() for p in model.parameters())
        logger.info(f"âœ… ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        logger.info(f"   - ì´ ë§¤ê°œë³€ìˆ˜: {total_params:,}")
        logger.info(f"   - ë‡Œ ì˜ì—­: {list(config['brain_regions'].keys())}")
        logger.info(f"   - ì…ë ¥â†’ì¶œë ¥: {config['system_roles']['input_node']} â†’ {config['system_roles']['output_node']}")

        # 5. í•™ìŠµ ì‹œìŠ¤í…œ êµ¬ì„±
        logger.info("âš™ï¸ í•™ìŠµ ì‹œìŠ¤í…œ êµ¬ì„± ì¤‘...")
        
        filtered_config, raw_config, unfreezing_config = extract_and_normalize_training_config(config)
        
        training_config = TrainingConfig(pad_token_id=pad_token_id, device=device, **filtered_config)
        
        # TimingLoss ì‚¬ìš© (ìƒˆë¡œìš´ íŒŒë¼ë¯¸í„° êµ¬ì¡°)
        loss_fn = TimingLoss(
            pad_token_id=pad_token_id,
            # SCSLoss ê¸°ë³¸ íŒŒë¼ë¯¸í„°ë“¤
            spike_reg_weight=raw_config.get("spike_reg_weight", 0.0),
            max_clk=raw_config.get("max_clk_training", 512),
            length_penalty_weight=raw_config.get("length_penalty_weight", 0.0),
            target_spike_rate=raw_config.get("target_spike_rate", 0.1),
            # === v2.0 ì¶”ê°€: ì‹œê°„ì  ê°€ì¤‘ì¹˜ íŒŒë¼ë¯¸í„°ë“¤ ===
            use_temporal_weighting=raw_config.get("use_temporal_weighting", False),
            initial_temporal_weight=raw_config.get("initial_temporal_weight", 2.0),
            final_temporal_weight=raw_config.get("final_temporal_weight", 1.0),
            # TimingLoss ì „ìš© íŒŒë¼ë¯¸í„°ë“¤
            timing_weight=raw_config.get("timing_weight", 1.0),
            sync_target_start=raw_config.get("sync_target_start", 1.0),
            sync_target_end=raw_config.get("sync_target_end", 0.0)
        )
        
        # ì˜µí‹°ë§ˆì´ì € ìƒì„±
        optimizer_type = raw_config.get("optimizer", "adamw").lower()
        optimizer = OptimizerFactory.create(optimizer_type=optimizer_type, model=model, config=training_config)
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer, 
            T_max=training_config.epochs,
            eta_min=training_config.eta_min
        )
        
        logger.info(f"âœ… í•™ìŠµ ì‹œìŠ¤í…œ êµ¬ì„± ì™„ë£Œ (ì˜µí‹°ë§ˆì´ì €: {optimizer_type})")

        # 6. íŠ¸ë ˆì´ë„ˆ ìƒì„± ë° í•™ìŠµ
        logger.info("ğŸ¯ í•™ìŠµ ì‹œì‘...")
        
        trainer = SCSTrainer(
            model=model, 
            config=training_config, 
            loss_fn=loss_fn, 
            optimizer=optimizer, 
            scheduler=scheduler, 
            tokenizer=tokenizer,
            unfreezing_config=unfreezing_config
        )
        trainer.train(train_loader, val_loader, save_path=str(experiment_dir / "checkpoints"))

        # 7. ìµœì¢… í‰ê°€
        logger.info("ğŸ“ˆ ìµœì¢… í‰ê°€ ì‹œì‘...")
        test_loader = create_dataloader(
            dataset_name=dataset_name, 
            split="test", 
            batch_size=config["data_loading"]["batch_size"],  # ğŸ”§ 1 ëŒ€ì‹  ë™ì¼í•œ ë°°ì¹˜ í¬ê¸°
            max_length=config["data_loading"]["tokenizer"]["max_length"], 
            tokenizer=tokenizer,
            num_samples=test_samples,
            task_id=task_id,
            learning_style=learning_style,
            bert_config=bert_config
        )
        
        # ì˜ˆì‹œ ì €ì¥ ê°œìˆ˜ ì„¤ì • (configì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ê¸°ë³¸ê°’ 10)
        save_examples = config.get('evaluation', {}).get('save_examples', 10)
        
        test_results = trainer.evaluate(test_loader, save_examples=save_examples)
        
        # ê²°ê³¼ ì €ì¥ (evaluate_modeì™€ ë™ì¼í•œ í˜•ì‹)
        results_path = experiment_dir / f"final_results_{datetime.now().strftime('%Y%m%d_%H%M')}.yaml"
        save_config(test_results, results_path)
        
        logger.info("ğŸ‰ í•™ìŠµ ë° í‰ê°€ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        logger.info("ğŸ“Š ìµœì¢… í‰ê°€ ê²°ê³¼:")
        for key, value in test_results.items():
            if key not in ['examples']:  # ì˜ˆì‹œëŠ” ë„ˆë¬´ ê¸¸ì–´ì„œ ì œì™¸
                if isinstance(value, float):
                    logger.info(f"   - {key}: {value:.4f}")
                else:
                    logger.info(f"   - {key}: {value}")
        
        logger.info(f"ğŸ’¾ ì €ì¥ëœ ì˜ˆì‹œ ê°œìˆ˜: {test_results['num_examples_saved']}")
        logger.info(f"ğŸ“‚ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {experiment_dir}")
        logger.info(f"ğŸ“Š ìµœì¢… ê²°ê³¼ íŒŒì¼: {results_path}")

        # ê¸°ì¡´ results.yamlë„ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€ (ê°„ë‹¨í•œ ë²„ì „)
        simple_results = {k: v for k, v in test_results.items() if k not in ['examples']}
        save_config(simple_results, experiment_dir / "results.yaml")
        
        logger.info("ğŸ¨ ìŠ¤íŒŒì´í¬ íŒ¨í„´ ì‹œê°í™” ìƒì„± ì¤‘...")
        _save_spike_visualizations(model, experiment_dir, test_loader, logger)
        
        _generate_io_example_metric(model, test_loader, experiment_dir, logger, device)


    except Exception as e:
        logger.error(f"âŒ í•™ìŠµ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise

def find_best_checkpoint(experiment_dir: Path) -> Path:
    """ê°€ì¥ ì í•©í•œ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°"""
    checkpoint_dir = experiment_dir / "checkpoints"
    
    # 1ìˆœìœ„: best_model.pt
    best_model_path = checkpoint_dir / "best_model.pt"
    if best_model_path.exists():
        return best_model_path
    
    # 2ìˆœìœ„: ê°€ì¥ ìµœê·¼ ì—í¬í¬ ì²´í¬í¬ì¸íŠ¸
    checkpoint_files = list(checkpoint_dir.glob("checkpoint_epoch_*.pt"))
    if checkpoint_files:
        # ì—í¬í¬ ë²ˆí˜¸ë¡œ ì •ë ¬í•´ì„œ ê°€ì¥ ìµœê·¼ ê²ƒ ì„ íƒ
        def extract_epoch(path):
            try:
                return int(path.stem.split('_')[-1])
            except (ValueError, IndexError):
                return -1
        
        latest_checkpoint = max(checkpoint_files, key=extract_epoch)
        return latest_checkpoint
    
    raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. {checkpoint_dir}ì—ì„œ 'best_model.pt' ë˜ëŠ” 'checkpoint_epoch_*.pt' íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

def load_model_with_checkpoint(config: Dict[str, Any], checkpoint_path: Path, device: str, logger) -> torch.nn.Module:
    """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ (ì„¤ì • í˜¸í™˜ì„± ê²€ì¦ í¬í•¨)"""
    try:
        # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ (PyTorch 2.6+ í˜¸í™˜ì„±)
        logger.info(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì¤‘: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
        
        # ì²´í¬í¬ì¸íŠ¸ ì •ë³´ ë¡œê¹…
        epoch = checkpoint.get('epoch', 'unknown')
        best_loss = checkpoint.get('best_loss', 'unknown')
        save_timestamp = checkpoint.get('save_timestamp', 'unknown')
        logger.info(f"ë¡œë“œëœ ì²´í¬í¬ì¸íŠ¸ ì •ë³´: ì—í¬í¬={epoch}, ìµœê³  ì†ì‹¤={best_loss}, ì €ì¥ ì‹œê°„={save_timestamp}")
        
        # ì„¤ì • í˜¸í™˜ì„± ê²€ì¦
        saved_training_config = checkpoint.get('training_config_dict', {})
        saved_model_config = checkpoint.get('model_config', {})
        saved_vocab_size = checkpoint.get('tokenizer_vocab_size')
        
        # ì–´íœ˜ í¬ê¸° í˜¸í™˜ì„± ê²€ì¦
        current_vocab_size = config.get("io_system", {}).get("input_interface", {}).get("vocab_size")
        if saved_vocab_size and current_vocab_size and saved_vocab_size != current_vocab_size:
            logger.warning(f"ì–´íœ˜ í¬ê¸° ë¶ˆì¼ì¹˜: ì €ì¥ëœ={saved_vocab_size}, í˜„ì¬={current_vocab_size}")
            logger.warning("ëª¨ë¸ êµ¬ì¡°ê°€ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ìƒˆ í† í¬ë‚˜ì´ì €ë¡œ ì¬í•™ìŠµì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        # í•™ìŠµ ì„¤ì • ë¹„êµ (ê²½ê³ ë§Œ)
        if saved_training_config:
            current_max_clk = config.get("learning", {}).get("max_clk_training") or config.get("training", {}).get("max_clk_training")
            saved_max_clk = saved_training_config.get('max_clk_training')
            if current_max_clk and saved_max_clk and current_max_clk != saved_max_clk:
                logger.warning(f"max_clk_training ë¶ˆì¼ì¹˜: ì €ì¥ëœ={saved_max_clk}, í˜„ì¬={current_max_clk}")
        
        # ëª¨ë¸ ìƒì„± (í˜„ì¬ ì„¤ì • ì‚¬ìš©)
        logger.info("ëª¨ë¸ êµ¬ì¡° ìƒì„± ì¤‘...")
        model = ModelBuilder.build_scs_from_config(config, device=device)
        
        # ìƒíƒœ ë”•ì…”ë„ˆë¦¬ ë¡œë“œ
        model_state_dict = checkpoint['model_state_dict']
        missing, unexpected = model.load_state_dict(model_state_dict, strict=False)
        
        if missing or unexpected:
            logger.warning("ì¼ë¶€ íŒŒë¼ë¯¸í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ì§€ë§Œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            if missing:
                logger.warning(f"ëˆ„ë½ëœ í‚¤ë“¤: {list(missing)[:5]}...")
            if unexpected:
                logger.warning(f"ì˜ˆìƒì¹˜ ëª»í•œ í‚¤ë“¤: {list(unexpected)[:5]}...")
        else:
            logger.info("âœ… ëª¨ë¸ ìƒíƒœ ì™„ì „íˆ ë¡œë“œë¨")
        
        return model
        
    except Exception as e:
        logger.error(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        logger.info("ìƒˆë¡œìš´ ëª¨ë¸ì„ ìƒì„±í•˜ì—¬ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤...")
        return ModelBuilder.build_scs_from_config(config, device=device)
    
def evaluate_mode(args: argparse.Namespace):
    """í‰ê°€ ëª¨ë“œ ì‹¤í–‰ (BERT ìŠ¤íƒ€ì¼ ì§€ì› ì¶”ê°€)"""
    # 1. í™˜ê²½ ì„¤ì •
    experiment_dir = Path(args.experiment_dir)
    config_path = experiment_dir / "config.yaml"

    if not config_path.exists():
        raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_path}")

    config = load_config(config_path)
    setup_logging(log_dir=experiment_dir / "logs" / "eval", level=logging.DEBUG if args.debug else logging.INFO)
    logger = logging.getLogger(__name__)
    device = get_device(args.device)
    logger.info(f"ğŸ“Š í‰ê°€ ëª¨ë“œ ì‹œì‘ | ë””ë°”ì´ìŠ¤: {device}")
    
    try:
        # 2. ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì°¾ê¸°
        checkpoint_path = find_best_checkpoint(experiment_dir)
        logger.info(f"ì‚¬ìš©í•  ì²´í¬í¬ì¸íŠ¸: {checkpoint_path}")
        
        # 3. ì„¤ì • íŒŒì¼ ê²€ì¦ (ê²½ê³ ë§Œ, í‰ê°€ëŠ” ê³„ì†)
        logger.info("ğŸ“‹ ì €ì¥ëœ ì„¤ì • íŒŒì¼ ê²€ì¦ ì¤‘...")
        validation_errors = ModelBuilder.validate_config_structure(config)
        all_errors = validation_errors
        
        if all_errors:
            logger.warning("âš ï¸ ì €ì¥ëœ ì„¤ì • íŒŒì¼ì— ì¼ë¶€ ë¬¸ì œê°€ ìˆì§€ë§Œ í‰ê°€ë¥¼ ê³„ì†í•©ë‹ˆë‹¤:")
            for error in all_errors[:3]:  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ
                logger.warning(f"   - {error}")

        # 4. ë°ì´í„° ë¡œë” ìƒì„± (BERT ìŠ¤íƒ€ì¼ ì§€ì› ì¶”ê°€)
        logger.info("ğŸ“Š ë°ì´í„° ë¡œë” ìƒì„± ì¤‘...")
        tokenizer = SCSTokenizer(config["data_loading"]["tokenizer"]["name"])

        # í† í¬ë‚˜ì´ì € ì„¤ì • (ê¸°ì¡´ê³¼ ë™ì¼)
        tokenizer_config = config["data_loading"]["tokenizer"]
        tokenizer_config["pad_token_id"] = getattr(tokenizer.tokenizer, 'pad_token_id', 0)
        tokenizer_config["eos_token_id"] = getattr(tokenizer.tokenizer, 'eos_token_id', 1)
        tokenizer_config["bos_token_id"] = getattr(tokenizer.tokenizer, 'bos_token_id', 2)
        tokenizer_config["unk_token_id"] = getattr(tokenizer.tokenizer, 'unk_token_id', 3)
        pad_token_id = tokenizer_config["pad_token_id"]
        dataset_name = get_dataset_name_from_config(config, logger)

        # ìƒˆë¡œ ì¶”ê°€: learning_styleê³¼ BERT ì„¤ì • ì¶”ì¶œ
        task_config = config.get("task", {})
        learning_style = task_config.get("learning_style", "generative")
        bert_config = task_config.get("bert_config", None)
        
        # ë¡œê¹…
        if learning_style == "bert":
            logger.info(f"ğŸ­ BERT ìŠ¤íƒ€ì¼ í‰ê°€ ëª¨ë“œ")
            if bert_config:
                logger.info(f"ğŸ“ BERT ì„¤ì •: {bert_config}")
        else:
            logger.info(f"ğŸ¯ ê¸°ì¡´ ìƒì„±í˜•(Generative) í‰ê°€ ëª¨ë“œ")

        # ë°ì´í„° ì„¤ì • ì¶”ì¶œ (ê¸°ì¡´ê³¼ ë™ì¼)
        data_config = config.get("data", {})
        
        test_samples = data_config.get("test_samples", -1)
        task_id = task_config.get("task_id", 1)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„± (ìƒˆ íŒŒë¼ë¯¸í„° ì „ë‹¬)
        test_loader = create_dataloader(
            dataset_name=dataset_name, 
            split="test", 
            batch_size=config["data_loading"]["batch_size"],  # ğŸ”§ 1 ëŒ€ì‹  ì„¤ì •ê°’ ì‚¬ìš©
            max_length=config["data_loading"]["tokenizer"]["max_length"], 
            tokenizer=tokenizer,
            num_samples=test_samples,
            task_id=task_id,
            learning_style=learning_style,  # ìƒˆë¡œ ì¶”ê°€ëœ íŒŒë¼ë¯¸í„°
            bert_config=bert_config  # ìƒˆë¡œ ì¶”ê°€ëœ íŒŒë¼ë¯¸í„°
        )
        
        logger.info(f"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë” ìƒì„± ì™„ë£Œ (ìŠ¤íƒ€ì¼: {learning_style})")
        
        # 5. ëª¨ë¸ ë¡œë“œ (ê¸°ì¡´ ì½”ë“œ)
        logger.info("ğŸ§  ëª¨ë¸ ë³µì› ì¤‘...")
        config["io_system"]["input_interface"]["vocab_size"] = tokenizer.vocab_size
        config["io_system"]["output_interface"]["vocab_size"] = tokenizer.vocab_size
        
        model = load_model_with_checkpoint(config, checkpoint_path, device, logger)
        logger.info("âœ… ëª¨ë¸ ë³µì› ì™„ë£Œ")

        # 6. íŠ¸ë ˆì´ë„ˆ ìƒì„± ë° í‰ê°€ (ê¸°ì¡´ ì½”ë“œ)
        logger.info("ğŸ“ˆ í‰ê°€ ì‹¤í–‰ ì¤‘...")
        
        filtered_config, _, _ = extract_and_normalize_training_config(config)
        
        training_config = TrainingConfig(pad_token_id=pad_token_id, device=device, **filtered_config)
        trainer = SCSTrainer(model=model, config=training_config, tokenizer=tokenizer)
        
        # ì˜ˆì‹œ ì €ì¥ ê°œìˆ˜ ì„¤ì • (configì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ê¸°ë³¸ê°’ 10)
        save_examples = config.get('evaluation', {}).get('save_examples', 10)
        
        results = trainer.evaluate(test_loader, save_examples=save_examples)
        
        # ê²°ê³¼ ì €ì¥ ë° ì¶œë ¥ (ê¸°ì¡´ ì½”ë“œ)
        results_path = experiment_dir / f"eval_results_{datetime.now().strftime('%Y%m%d_%H%M')}.yaml"
        save_config(results, results_path)
        
        logger.info("ğŸ‰ í‰ê°€ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        logger.info("ğŸ“Š í‰ê°€ ê²°ê³¼:")
        for key, value in results.items():
            if key not in ['examples']:  # ì˜ˆì‹œëŠ” ë„ˆë¬´ ê¸¸ì–´ì„œ ì œì™¸
                if isinstance(value, float):
                    logger.info(f"   - {key}: {value:.4f}")
                else:
                    logger.info(f"   - {key}: {value}")
        
        logger.info(f"ğŸ’¾ ì €ì¥ëœ ì˜ˆì‹œ ê°œìˆ˜: {results['num_examples_saved']}")
        logger.info(f"ğŸ“‚ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {results_path}")
        
        logger.info("ğŸ¨ ìŠ¤íŒŒì´í¬ íŒ¨í„´ ì‹œê°í™” ìƒì„± ì¤‘...")
        _save_spike_visualizations(model, experiment_dir, test_loader, logger)

    except Exception as e:
        logger.error(f"âŒ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        raise


def main():
    """ë©”ì¸ CLI í•¨ìˆ˜ (ìƒˆë¡œìš´ ì„ ì–¸ì  ì¡°ë¦½ êµ¬ì¡° ì§€ì›)"""
    parser = setup_args()
    args = parser.parse_args()
    
    try:
        validate_args(args)
        
        if args.mode == "validate":
            # ì„¤ì • íŒŒì¼ ê²€ì¦ ëª¨ë“œ
            success = validate_mode(args)
            sys.exit(0 if success else 1)
            
        elif args.mode == "train":
            # í•™ìŠµ ëª¨ë“œ
            config_path = Path(args.config)
            if not config_path.is_absolute():
                config_path = Path.cwd() / config_path
            config = load_config(config_path)
            train_mode(args, config)
            
        elif args.mode == "evaluate":
            # í‰ê°€ ëª¨ë“œ
            evaluate_mode(args)
            
    except (ValueError, FileNotFoundError) as e:
        print(f"âŒ ì…ë ¥ ì˜¤ë¥˜: {e}")
        sys.exit(1)
    except KeyboardInterrupt:
        print("\nâ¹ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(0)
    except Exception as e:
        logging.getLogger(__name__).critical(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    # ì´ íŒŒì¼ì´ ì§ì ‘ ì‹¤í–‰ë  ë•ŒëŠ” ì•„ë¬´ ì¼ë„ ì¼ì–´ë‚˜ì§€ ì•ŠìŒ.
    # scs ëª…ë ¹ì–´ ë˜ëŠ” run.pyë¥¼ í†µí•´ main()ì´ í˜¸ì¶œë˜ì–´ì•¼ í•¨.
    pass