# src/scs/evaluation/analyzer.py
"""
SCS ëª¨ë¸ ë‚´ë¶€ ë™ì‘ ë¶„ì„ ëª¨ë“ˆ

IO íŒŒì´í”„ë¼ì¸ ì¤‘ê°„ê°’ ì¶”ì  ë° í•™ìŠµ ì „í›„ ë¹„êµ ë¶„ì„
"""

import torch
import json
from pathlib import Path
from typing import Any, Dict
import logging

logger = logging.getLogger(__name__)


def analyze_io_pipeline(model, test_loader, output_dir: Path, device: str):
    """
    IO íŒŒì´í”„ë¼ì¸ ì¤‘ê°„ê°’ ì¶”ì  ë° í•™ìŠµ í›„ ìƒíƒœ ë¶„ì„
    
    Args:
        model: í•™ìŠµëœ SCS ëª¨ë¸
        test_loader: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”
        output_dir: ë¶„ì„ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        device: ì—°ì‚° ë””ë°”ì´ìŠ¤
    """
    try:
        # ì²« ë²ˆì§¸ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ì¶”ì¶œ
        first_batch = next(iter(test_loader))
        sample_input = first_batch['input_tokens'][0:1].to(device)  # [1, seq_len]
        sample_target = first_batch['target_tokens'][0:1].to(device)
        sample_mask = first_batch.get('attention_mask')
        if sample_mask is not None:
            sample_mask = sample_mask[0:1].to(device)
        
        logger.info(f"ğŸ” ë¶„ì„ ëŒ€ìƒ ìƒ˜í”Œ:")
        logger.info(f"   ì…ë ¥ ê¸¸ì´: {sample_input.shape[1]}")
        logger.info(f"   íƒ€ê²Ÿ ê¸¸ì´: {sample_target.shape[1]}")
        
        def trace_pipeline(model, input_tokens, target_tokens, attention_mask, phase_name):
            """íŒŒì´í”„ë¼ì¸ ì¤‘ê°„ê°’ ì¶”ì """
            model.eval()
            traced_data = {"phase": phase_name, "steps": []}
            
            with torch.no_grad():
                # InputInterface ì¶”ì 
                if hasattr(model, 'input_interface'):
                    window_size = model.input_interface.window_size
                    if input_tokens.shape[1] >= window_size:
                        test_window = input_tokens[:, :window_size]
                    else:
                        pad_size = window_size - input_tokens.shape[1]
                        padding = torch.zeros(1, pad_size, dtype=torch.long, device=input_tokens.device)
                        test_window = torch.cat([padding, input_tokens], dim=1)
                    
                    # Step 1: í† í° ì„ë² ë”© (T5 ê°€ì¤‘ì¹˜)
                    token_embeds = model.input_interface.token_embedding(test_window)
                    traced_data["steps"].append({
                        "name": "input_token_embedding",
                        "shape": list(token_embeds.shape),
                        "mean": token_embeds.mean().item(),
                        "std": token_embeds.std().item(),
                        "min": token_embeds.min().item(),
                        "max": token_embeds.max().item(),
                        "description": "T5 í† í° ì„ë² ë”© (stdâ‰ˆ23 ì˜ˆìƒ)"
                    })

                    windowed_input = token_embeds
                    
                    # Step 3: Dropout ì ìš©
                    if hasattr(model.input_interface, 'dropout'):
                        dropped_input = model.input_interface.dropout(windowed_input)
                        traced_data["steps"].append({
                            "name": "input_after_dropout",
                            "shape": list(dropped_input.shape),
                            "mean": dropped_input.mean().item(),
                            "std": dropped_input.std().item(),
                            "description": "T5 ìŠ¤íƒ€ì¼ dropout ì ìš©"
                        })
                        windowed_input = dropped_input
                    
                    # Step 4: Transformer Encoder
                    encoder_output = model.input_interface.transformer_encoder(windowed_input)
                    context_vector = encoder_output[:, -1, :]  # ë§ˆì§€ë§‰ í† í°
                    traced_data["steps"].append({
                        "name": "encoder_output",
                        "shape": list(encoder_output.shape),
                        "full_mean": encoder_output.mean().item(),
                        "full_std": encoder_output.std().item(),
                        "last_token_mean": context_vector.mean().item(),
                        "last_token_std": context_vector.std().item(),
                        "description": "T5 encoder ì¶œë ¥, ë§ˆì§€ë§‰ í† í°ì„ contextë¡œ ì‚¬ìš©"
                    })
                    
                    # Step 5: Pattern Mapper
                    membrane_logits = model.input_interface.pattern_mapper(context_vector)
                    traced_data["steps"].append({
                        "name": "membrane_logits",
                        "shape": list(membrane_logits.shape),
                        "mean": membrane_logits.mean().item(),
                        "std": membrane_logits.std().item(),
                        "min": membrane_logits.min().item(),
                        "max": membrane_logits.max().item(),
                        "description": "ì§êµ ì´ˆê¸°í™”ëœ linear ë§¤í•‘"
                    })
                    
                    # Step 6: ìµœì¢… ë§‰ì „ìœ„ íŒ¨í„´
                    pattern_probs = torch.softmax(membrane_logits / model.input_interface.softmax_temperature, dim=-1)
                    total_energy = model.input_interface.grid_height * model.input_interface.grid_width * model.input_interface.input_power
                    final_pattern = pattern_probs * total_energy
                    final_pattern_2d = final_pattern.view(1, model.input_interface.grid_height, model.input_interface.grid_width)
                    
                    # íŒ¨í„´ ë¶„ì„
                    active_neurons = (final_pattern > 0.1).sum().item()  # ì„ê³„ê°’ ì´ìƒ í™œì„±í™”
                    max_activation = final_pattern.max().item()
                    sparsity = (final_pattern < 0.01).sum().item() / final_pattern.numel()
                    
                    traced_data["steps"].append({
                        "name": "final_membrane_pattern",
                        "shape": list(final_pattern_2d.shape),
                        "mean": final_pattern_2d.mean().item(),
                        "std": final_pattern_2d.std().item(),
                        "total_energy": total_energy,
                        "active_neurons": active_neurons,
                        "max_activation": max_activation,
                        "sparsity_ratio": sparsity,
                        "softmax_temperature": model.input_interface.softmax_temperature,
                        "input_power": model.input_interface.input_power,
                        "description": "Softmax + ì—ë„ˆì§€ ìŠ¤ì¼€ì¼ë§ëœ ìµœì¢… íŒ¨í„´"
                    })
                
                # OutputInterface ì¶”ì 
                if hasattr(model, 'output_interface'):
                    grid_h, grid_w = model.output_interface.grid_height, model.output_interface.grid_width
                    batch_size = 1
                    model.output_interface.reset_state(batch_size)
                    
                    # ì¼€ì´ìŠ¤ 1: ì™„ì „ ë¹„í™œì„±í™” ìŠ¤íŒŒì´í¬ë¡œ ìœˆë„ìš° ì—…ë°ì´íŠ¸
                    zero_spikes = torch.zeros(batch_size, grid_h, grid_w, device=device)
                    model.output_interface.update_hidden_window(zero_spikes)
                    
                    # ì¼€ì´ìŠ¤ 2: ìŠ¤íŒŒìŠ¤ í™œì„±í™” (10ê°œ ë‰´ëŸ°)ë¡œ ìœˆë„ìš° ì—…ë°ì´íŠ¸
                    sparse_spikes = torch.zeros(batch_size, grid_h, grid_w, device=device)
                    flat_sparse = sparse_spikes.view(batch_size, -1)
                    indices = torch.randperm(grid_h * grid_w)[:10]
                    flat_sparse[:, indices] = 1.0
                    sparse_spikes = flat_sparse.view(batch_size, grid_h, grid_w)
                    model.output_interface.update_hidden_window(sparse_spikes)
                    
                    # í˜„ì¬ íˆë“  ìœˆë„ìš° ìƒíƒœ ë¶„ì„
                    current_hidden_window = model.output_interface.hidden_window  # [B, window_size, embedding_dim]
                    
                    # ìœˆë„ìš°ì˜ ë§ˆì§€ë§‰ ë²¡í„° (ê°€ì¥ ìµœê·¼ ì—…ë°ì´íŠ¸ëœ ê²ƒ) ë¶„ì„
                    latest_hidden = current_hidden_window[:, -1, :]  # [B, embedding_dim]
                    
                    traced_data["steps"].append({
                        "name": "output_hidden_window_analysis",
                        "hidden_window_shape": list(current_hidden_window.shape),
                        "latest_hidden_vector": {
                            "shape": list(latest_hidden.shape),
                            "mean": latest_hidden.mean().item(),
                            "std": latest_hidden.std().item(),
                            "l2_norm": torch.norm(latest_hidden).item()
                        },
                        "window_stats": {
                            "window_mean": current_hidden_window.mean().item(),
                            "window_std": current_hidden_window.std().item(),
                            "window_l2_norm": torch.norm(current_hidden_window).item()
                        },
                        "description": f"íˆë“  ìœˆë„ìš° ë‚´ë¶€ ê´€ë¦¬, ìŠ¤íŒŒìŠ¤ ìŠ¤íŒŒì´í¬ ì—…ë°ì´íŠ¸ í›„ ìƒíƒœ"
                    })
            
            return traced_data
        
        # ë¶„ì„ ì‹¤í–‰
        logger.info("ğŸ“Š í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ íŒŒì´í”„ë¼ì¸ ì¶”ì  ì¤‘...")
        trained_trace = trace_pipeline(model, sample_input, sample_target, sample_mask, "trained_model")
        
        # ê²°ê³¼ ì €ì¥
        metric_dir = output_dir / "io_example_metrics"
        metric_dir.mkdir(exist_ok=True)
        
        with open(metric_dir / "pipeline_trace_trained.json", 'w') as f:
            json.dump(trained_trace, f, indent=2)
        
        # ìš”ì•½ ë¡œê¹…
        logger.info(f"âœ… IO íŒŒì´í”„ë¼ì¸ ë¶„ì„ ì™„ë£Œ: {metric_dir}")
        logger.info(f"   ğŸ“Š ì¶”ì ëœ ë‹¨ê³„ ìˆ˜: {len(trained_trace['steps'])}")
        
        # í•µì‹¬ ì§€í‘œ ìš”ì•½
        key_metrics = {}
        for step in trained_trace['steps']:
            if step['name'] == 'input_token_embedding':
                key_metrics['token_embed_std'] = step['std']
            elif step['name'] == 'encoder_output':
                key_metrics['last_token_std'] = step['last_token_std']
            elif step['name'] == 'membrane_logits':
                key_metrics['membrane_logits_std'] = step['std']
            elif step['name'] == 'output_hidden_window_analysis':
                key_metrics['latest_hidden_std'] = step['latest_hidden_vector']['std']
        
        logger.info("ğŸ¯ í•µì‹¬ ì§€í‘œ ìš”ì•½:")
        logger.info(f"   í† í° ì„ë² ë”© std: {key_metrics.get('token_embed_std', 'N/A'):.3f} (ëª©í‘œ: ~23)")
        logger.info(f"   ë§ˆì§€ë§‰ í† í° std: {key_metrics.get('last_token_std', 'N/A'):.3f} (T5 encoder ì¶œë ¥)")
        logger.info(f"   ë§‰ì „ìœ„ ë¡œì§“ std: {key_metrics.get('membrane_logits_std', 'N/A'):.3f} (ì§êµ ë³€í™˜)")
        logger.info(f"   ìµœì‹  íˆë“  std: {key_metrics.get('latest_hidden_std', 'N/A'):.3f}")
        
    except Exception as e:
        logger.warning(f"âš ï¸ IO íŒŒì´í”„ë¼ì¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        logger.debug(traceback.format_exc())