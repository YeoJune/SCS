# src/scs/evaluation/visualizer.py
"""
SCS ëª¨ë¸ ì‹œê°í™” ëª¨ë“ˆ (v2.0)

SCSSystemì˜ ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ì— ë§ì¶˜ ìŠ¤íŒŒì´í¬ íŒ¨í„´ ë° ê°€ì¤‘ì¹˜ ì‹œê°í™” ê¸°ëŠ¥ ì œê³µ
"""

import torch
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import numpy as np
from pathlib import Path
from typing import Any, Dict, List, Optional
import logging

logger = logging.getLogger(__name__)


def generate_visualizations(model, test_loader, output_dir: Path):
    """
    SCS ëª¨ë¸ì˜ ìŠ¤íŒŒì´í¬ íŒ¨í„´ê³¼ ê°€ì¤‘ì¹˜ íˆíŠ¸ë§µ ì‹œê°í™” ìƒì„±
    
    Args:
        model: SCSSystem ëª¨ë¸
        test_loader: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”
        output_dir: ì‹œê°í™” íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬
    """
    try:
        vis_dir = output_dir / "visualizations"
        vis_dir.mkdir(exist_ok=True)
        
        # ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ ì‚¬ìš©
        first_batch = next(iter(test_loader))
        input_tokens = first_batch['input_tokens'][:1].to(model.device)  # ì²« ë²ˆì§¸ ìƒ˜í”Œë§Œ
        attention_mask = first_batch.get('attention_mask')
        if attention_mask is not None:
            attention_mask = attention_mask[:1].to(model.device)
        
        # ìŠ¤íŒŒì´í¬ íŒ¨í„´ ìˆ˜ì§‘ì„ ìœ„í•œ ëª¨ë¸ ì‹¤í–‰
        model.eval()
        with torch.no_grad():
            # ìŠ¤íŒŒì´í¬ íŒ¨í„´ ìˆ˜ì§‘
            all_spike_patterns = _collect_spike_patterns(
                model, input_tokens, attention_mask
            )
        
        # ë…¸ë“œ ì´ë¦„ ì¶”ì¶œ
        node_names = list(all_spike_patterns[0].keys()) if all_spike_patterns else []
        
        if not node_names:
            logger.warning("âš ï¸ ìˆ˜ì§‘ëœ ìŠ¤íŒŒì´í¬ íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 1. CLKë³„ ìŠ¤íŒŒì´í¬ íŒ¨í„´ ì´ë¯¸ì§€ ìƒì„±
        _generate_spike_pattern_images(all_spike_patterns, node_names, vis_dir)
        
        # 2. ìŠ¤íŒŒì´í¬ íŒ¨í„´ GIF ì• ë‹ˆë©”ì´ì…˜ ìƒì„±
        _generate_spike_animation(all_spike_patterns, node_names, vis_dir)
        
        # 3. ê°€ì¤‘ì¹˜ íˆíŠ¸ë§µ ìƒì„±
        _generate_weight_heatmaps(model, node_names, vis_dir)
        
        # 4. ì²˜ë¦¬ ì •ë³´ ì‹œê°í™” (ìƒˆë¡œìš´ ê¸°ëŠ¥)
        _generate_processing_info_plots(all_spike_patterns, vis_dir)
        
        logger.info(f"ğŸ“ ëª¨ë“  ì‹œê°í™” íŒŒì¼ ì €ì¥ ì™„ë£Œ: {vis_dir}")
        
    except Exception as e:
        logger.warning(f"âš ï¸ ì‹œê°í™” ìƒì„± ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ê³„ì†): {e}")
        import traceback
        logger.debug(traceback.format_exc())


def _collect_spike_patterns(
    model, 
    input_tokens: torch.Tensor, 
    attention_mask: Optional[torch.Tensor]
) -> List[Dict[str, np.ndarray]]:
    """
    SCSSystem v2.0ì—ì„œ ìŠ¤íŒŒì´í¬ íŒ¨í„´ ìˆ˜ì§‘
    
    Args:
        model: SCSSystem ëª¨ë¸
        input_tokens: [1, seq_len] ì…ë ¥ í† í°
        attention_mask: [1, seq_len] ì–´í…ì…˜ ë§ˆìŠ¤í¬
        
    Returns:
        all_spike_patterns: CLKë³„ ìŠ¤íŒŒì´í¬ íŒ¨í„´ ë¦¬ìŠ¤íŠ¸
    """
    # ëª¨ë¸ ìƒíƒœ ì´ˆê¸°í™”
    model.reset_state(batch_size=1)
    
    all_spike_patterns = []
    max_clk = min(100, model.max_clk)  # ì‹œê°í™”ìš©ìœ¼ë¡œ ì œí•œ
    
    logger.info(f"ğŸ” ìŠ¤íŒŒì´í¬ íŒ¨í„´ ìˆ˜ì§‘ ì‹œì‘ (ìµœëŒ€ {max_clk} CLK)")
    
    for clk in range(max_clk):
        try:
            # Phase 1: ìŠ¤íŒŒì´í¬ ê³„ì‚° ë° ìƒíƒœ ì—…ë°ì´íŠ¸
            current_spikes = model._compute_spikes()
            external_input = model._get_external_input_at_clk(
                input_tokens, clk, attention_mask
            )
            model._update_states(external_input, current_spikes)
            final_acc_spikes = current_spikes.get(model.acc_node)
            
            # í˜„ì¬ ìŠ¤íŒŒì´í¬ íŒ¨í„´ ì €ì¥
            if current_spikes:
                spike_pattern = {}
                for node_name, spikes in current_spikes.items():
                    if spikes is not None:
                        spike_pattern[node_name] = spikes[0].cpu().numpy()  # [H, W]
                all_spike_patterns.append(spike_pattern)
            
            # Phase 2: TimingManager ì—…ë°ì´íŠ¸
            model.timing_manager.step(
                current_clk=clk,
                acc_node_spikes=final_acc_spikes,
                training=False,
                input_seq_len=input_tokens.shape[1],
                target_seq_len=input_tokens.shape[1],  # ì¶”ë¡  ëª¨ë“œ
                last_token_ids=getattr(model, '_last_tokens', None)
            )
            
            # ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´
            if model.timing_manager.all_ended:
                logger.info(f"â¹ï¸ CLK {clk}ì—ì„œ ì²˜ë¦¬ ì™„ë£Œ (ì¡°ê¸° ì¢…ë£Œ)")
                break
                
        except Exception as e:
            logger.warning(f"âš ï¸ CLK {clk} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            break
    
    logger.info(f"âœ… ì´ {len(all_spike_patterns)}ê°œ CLKì˜ ìŠ¤íŒŒì´í¬ íŒ¨í„´ ìˆ˜ì§‘ ì™„ë£Œ")
    return all_spike_patterns


def _generate_spike_pattern_images(
    all_spike_patterns: List[Dict[str, np.ndarray]], 
    node_names: List[str], 
    vis_dir: Path
):
    """CLKë³„ ìŠ¤íŒŒì´í¬ íŒ¨í„´ ì´ë¯¸ì§€ ìƒì„±"""
    spike_dir = vis_dir / "spike_patterns"
    spike_dir.mkdir(exist_ok=True)
    
    num_nodes = len(node_names)
    
    for clk, spike_pattern in enumerate(all_spike_patterns):
        fig, axes = plt.subplots(1, num_nodes, figsize=(4*num_nodes, 4))
        if num_nodes == 1:
            axes = [axes]
        
        for i, node_name in enumerate(node_names):
            if node_name in spike_pattern:
                spikes = spike_pattern[node_name]
                im = axes[i].imshow(spikes, cmap='hot', vmin=0, vmax=1)
                axes[i].set_title(f'{node_name}\nCLK {clk}')
                axes[i].set_xlabel('Width')
                axes[i].set_ylabel('Height')
                plt.colorbar(im, ax=axes[i])
            else:
                axes[i].text(0.5, 0.5, f'{node_name}\nNo Data', 
                           transform=axes[i].transAxes, ha='center', va='center')
                axes[i].set_title(f'{node_name}\nCLK {clk}')
        
        plt.tight_layout()
        plt.savefig(spike_dir / f"clk_{clk:03d}.png", dpi=100, bbox_inches='tight')
        plt.close()
    
    logger.info(f"âœ… ìŠ¤íŒŒì´í¬ íŒ¨í„´ ì´ë¯¸ì§€ {len(all_spike_patterns)}ê°œ ì €ì¥: {spike_dir}")


def _generate_spike_animation(
    all_spike_patterns: List[Dict[str, np.ndarray]], 
    node_names: List[str], 
    vis_dir: Path
):
    """ìŠ¤íŒŒì´í¬ íŒ¨í„´ GIF ì• ë‹ˆë©”ì´ì…˜ ìƒì„±"""
    try:
        if not all_spike_patterns:
            logger.warning("âš ï¸ ì• ë‹ˆë©”ì´ì…˜ ìƒì„±ì„ ìœ„í•œ ìŠ¤íŒŒì´í¬ íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        num_nodes = len(node_names)
        fig, axes = plt.subplots(1, num_nodes, figsize=(4*num_nodes, 4))
        if num_nodes == 1:
            axes = [axes]
        
        # ì´ˆê¸° í”Œë¡¯ ì„¤ì •
        ims = []
        for i, node_name in enumerate(node_names):
            if node_name in all_spike_patterns[0]:
                initial_data = all_spike_patterns[0][node_name]
            else:
                initial_data = np.zeros((64, 64))  # ê¸°ë³¸ í¬ê¸°
            
            im = axes[i].imshow(initial_data, cmap='hot', vmin=0, vmax=1)
            axes[i].set_title(f'{node_name}\nCLK 0')
            axes[i].set_xlabel('Width')
            axes[i].set_ylabel('Height')
            plt.colorbar(im, ax=axes[i])
            ims.append(im)
        
        def animate(frame):
            spike_pattern = all_spike_patterns[frame]
            for i, (node_name, im) in enumerate(zip(node_names, ims)):
                if node_name in spike_pattern:
                    im.set_array(spike_pattern[node_name])
                axes[i].set_title(f'{node_name}\nCLK {frame}')
            return ims
        
        # ì• ë‹ˆë©”ì´ì…˜ ìƒì„±
        anim = animation.FuncAnimation(
            fig, animate, frames=len(all_spike_patterns),
            interval=200, blit=True, repeat=True
        )
        
        # GIF ì €ì¥
        gif_path = vis_dir / "spike_animation.gif"
        anim.save(gif_path, writer='pillow', fps=5)
        plt.close()
        
        logger.info(f"ğŸ¬ ìŠ¤íŒŒì´í¬ íŒ¨í„´ GIF ìƒì„±: {gif_path}")
        
    except Exception as gif_error:
        logger.warning(f"âš ï¸ GIF ìƒì„± ì¤‘ ì˜¤ë¥˜ (ê°œë³„ ì´ë¯¸ì§€ëŠ” ì •ìƒ ì €ì¥ë¨): {gif_error}")


def _generate_weight_heatmaps(model, node_names: List[str], vis_dir: Path):
    """ê°€ì¤‘ì¹˜ íˆíŠ¸ë§µ ìƒì„±"""
    weight_dir = vis_dir / "weight_heatmaps"
    weight_dir.mkdir(exist_ok=True)
    
    num_nodes = len(node_names)
    
    # 1. ë…¸ë“œë³„ influence ê°€ì¤‘ì¹˜
    fig, axes = plt.subplots(1, num_nodes, figsize=(4*num_nodes, 4))
    if num_nodes == 1:
        axes = [axes]
    
    for i, node_name in enumerate(node_names):
        if node_name in model.nodes:
            node = model.nodes[node_name]
            influence = node.influence_strength.detach().cpu().numpy()
            
            im = axes[i].imshow(influence, cmap='RdBu_r', vmin=-2, vmax=2)
            axes[i].set_title(f'{node_name}\nInfluence Strength')
            axes[i].set_xlabel('Width')
            axes[i].set_ylabel('Height')
            plt.colorbar(im, ax=axes[i])
        else:
            axes[i].text(0.5, 0.5, f'{node_name}\nNo Data', 
                       transform=axes[i].transAxes, ha='center', va='center')
            axes[i].set_title(f'{node_name}\nInfluence Strength')
    
    plt.tight_layout()
    plt.savefig(weight_dir / "node_influence_weights.png", dpi=100, bbox_inches='tight')
    plt.close()
    
    # 2. ì¶•ì‚­ ì—°ê²° ê°€ì¤‘ì¹˜ (AxonalConnections)
    _visualize_axonal_connections(model.axonal_connections, weight_dir)
    
    logger.info(f"âœ… ê°€ì¤‘ì¹˜ íˆíŠ¸ë§µ ì €ì¥: {weight_dir}")


def _visualize_axonal_connections(axonal_connections, weight_dir: Path):
    """ì¶•ì‚­ ì—°ê²° ê°€ì¤‘ì¹˜ ì‹œê°í™”"""
    try:
        if not hasattr(axonal_connections, 'patch_gates'):
            logger.warning("âš ï¸ AxonalConnectionsì— patch_gatesê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        patch_gates = axonal_connections.patch_gates
        patch_transforms = axonal_connections.patch_transforms
        
        # Patch Gates ì‹œê°í™”
        num_connections = min(6, len(patch_gates))  # ìµœëŒ€ 6ê°œë§Œ ì‹œê°í™”
        
        if num_connections > 0:
            cols = min(3, num_connections)
            rows = (num_connections + cols - 1) // cols
            
            fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))
            if rows == 1 and cols == 1:
                axes = [axes]
            elif rows == 1 or cols == 1:
                axes = axes.flatten()
            else:
                axes = axes.flatten()
            
            for i, (conn_name, gate_weights) in enumerate(list(patch_gates.items())[:num_connections]):
                weights = gate_weights.detach().cpu().numpy()
                
                # 1D ê°€ì¤‘ì¹˜ë¥¼ ì ì ˆí•œ í˜•íƒœë¡œ ë³€í™˜
                if len(weights.shape) == 1:
                    # 1ì°¨ì› ë°°ì—´ì„ 2ì°¨ì›ìœ¼ë¡œ ë³€í™˜
                    sqrt_size = int(np.sqrt(len(weights)))
                    if sqrt_size * sqrt_size == len(weights):
                        weights = weights.reshape(sqrt_size, sqrt_size)
                    else:
                        # ì ì ˆí•œ í¬ê¸°ë¡œ íŒ¨ë”©
                        pad_size = sqrt_size + 1
                        padded = np.zeros(pad_size * pad_size)
                        padded[:len(weights)] = weights
                        weights = padded.reshape(pad_size, pad_size)
                
                im = axes[i].imshow(weights, cmap='hot', aspect='auto')
                axes[i].set_title(f'{conn_name}\nPatch Gates')
                axes[i].set_xlabel('Patch Index (reshaped)')
                axes[i].set_ylabel('Patch Index (reshaped)')
                plt.colorbar(im, ax=axes[i])
            
            # ë¹ˆ subplot ìˆ¨ê¸°ê¸°
            for j in range(i+1, len(axes)):
                axes[j].set_visible(False)
            
            plt.tight_layout()
            plt.savefig(weight_dir / "axonal_patch_gates.png", dpi=100, bbox_inches='tight')
            plt.close()
        
        # Patch Transforms í†µê³„ ì‹œê°í™”
        if patch_transforms:
            _visualize_patch_transform_stats(patch_transforms, weight_dir)
            
    except Exception as e:
        logger.warning(f"âš ï¸ ì¶•ì‚­ ì—°ê²° ê°€ì¤‘ì¹˜ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜: {e}")


def _visualize_patch_transform_stats(patch_transforms, weight_dir: Path):
    """Patch Transform í–‰ë ¬ì˜ í†µê³„ ì‹œê°í™”"""
    try:
        # ê° ì—°ê²°ë³„ transform í–‰ë ¬ì˜ í†µê³„ ê³„ì‚°
        conn_stats = {}
        
        for conn_name, transforms in patch_transforms.items():
            transforms_np = transforms.detach().cpu().numpy()
            
            # í†µê³„ ê³„ì‚°
            stats = {
                'mean': np.mean(transforms_np),
                'std': np.std(transforms_np),
                'min': np.min(transforms_np),
                'max': np.max(transforms_np),
                'shape': transforms_np.shape
            }
            conn_stats[conn_name] = stats
        
        # í†µê³„ ì‹œê°í™”
        if conn_stats:
            conn_names = list(conn_stats.keys())
            metrics = ['mean', 'std', 'min', 'max']
            
            fig, axes = plt.subplots(2, 2, figsize=(12, 8))
            axes = axes.flatten()
            
            for i, metric in enumerate(metrics):
                values = [conn_stats[conn][metric] for conn in conn_names]
                bars = axes[i].bar(range(len(conn_names)), values)
                axes[i].set_title(f'Patch Transform {metric.capitalize()}')
                axes[i].set_xlabel('Connection')
                axes[i].set_ylabel(metric.capitalize())
                axes[i].set_xticks(range(len(conn_names)))
                axes[i].set_xticklabels([name.split('_to_')[0][:8] + 'â†’' + name.split('_to_')[1][:8] 
                                       for name in conn_names], rotation=45)
                
                # ê°’ í‘œì‹œ
                for bar, value in zip(bars, values):
                    axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height(),
                               f'{value:.3f}', ha='center', va='bottom', fontsize=8)
            
            plt.tight_layout()
            plt.savefig(weight_dir / "patch_transform_stats.png", dpi=100, bbox_inches='tight')
            plt.close()
            
            logger.info("âœ… Patch Transform í†µê³„ ì‹œê°í™” ì™„ë£Œ")
            
    except Exception as e:
        logger.warning(f"âš ï¸ Patch Transform í†µê³„ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜: {e}")


def _generate_processing_info_plots(all_spike_patterns: List[Dict[str, np.ndarray]], vis_dir: Path):
    """ì²˜ë¦¬ ì •ë³´ ì‹œê°í™” (ìƒˆë¡œìš´ ê¸°ëŠ¥)"""
    try:
        if not all_spike_patterns:
            return
        
        info_dir = vis_dir / "processing_info"
        info_dir.mkdir(exist_ok=True)
        
        node_names = list(all_spike_patterns[0].keys())
        num_clks = len(all_spike_patterns)
        
        # 1. CLKë³„ ë…¸ë“œ í™œì„±ë„ ë³€í™”
        node_activities = {node: [] for node in node_names}
        
        for spike_pattern in all_spike_patterns:
            for node_name in node_names:
                if node_name in spike_pattern:
                    activity = np.mean(spike_pattern[node_name])
                    node_activities[node_name].append(activity)
                else:
                    node_activities[node_name].append(0.0)
        
        # í™œì„±ë„ í”Œë¡¯
        plt.figure(figsize=(12, 6))
        for node_name, activities in node_activities.items():
            plt.plot(activities, label=node_name, linewidth=2)
        
        plt.xlabel('CLK')
        plt.ylabel('Average Spike Rate')
        plt.title('Node Activity Over Time')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(info_dir / "node_activity_timeline.png", dpi=100, bbox_inches='tight')
        plt.close()
        
        # 2. ì´ ìŠ¤íŒŒì´í¬ ìˆ˜ ë³€í™”
        total_spikes = []
        for spike_pattern in all_spike_patterns:
            total = sum(np.sum(spikes) for spikes in spike_pattern.values())
            total_spikes.append(total)
        
        plt.figure(figsize=(10, 5))
        plt.plot(total_spikes, linewidth=2, color='red')
        plt.xlabel('CLK')
        plt.ylabel('Total Spikes')
        plt.title('Total Spike Count Over Time')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(info_dir / "total_spikes_timeline.png", dpi=100, bbox_inches='tight')
        plt.close()
        
        logger.info(f"âœ… ì²˜ë¦¬ ì •ë³´ ì‹œê°í™” ì €ì¥: {info_dir}")
        
    except Exception as e:
        logger.warning(f"âš ï¸ ì²˜ë¦¬ ì •ë³´ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜: {e}")


def generate_quick_visualization(
    model, 
    input_tokens: torch.Tensor, 
    attention_mask: Optional[torch.Tensor] = None,
    max_clks: int = 50
) -> Dict[str, Any]:
    """
    ë¹ ë¥¸ ì‹œê°í™”ìš© í•¨ìˆ˜ - íŒŒì¼ ì €ì¥ ì—†ì´ ë°ì´í„°ë§Œ ë°˜í™˜
    
    Args:
        model: SCSSystem ëª¨ë¸
        input_tokens: [B, seq_len] ì…ë ¥ í† í°
        attention_mask: [B, seq_len] ì–´í…ì…˜ ë§ˆìŠ¤í¬
        max_clks: ìµœëŒ€ CLK ìˆ˜
        
    Returns:
        visualization_data: ì‹œê°í™” ë°ì´í„° ë”•ì…”ë„ˆë¦¬
    """
    model.eval()
    
    # ì²« ë²ˆì§¸ ìƒ˜í”Œë§Œ ì‚¬ìš©
    single_input = input_tokens[:1]
    single_mask = attention_mask[:1] if attention_mask is not None else None
    
    with torch.no_grad():
        spike_patterns = _collect_spike_patterns(model, single_input, single_mask)
        
        # í™œì„±ë„ ê³„ì‚°
        if spike_patterns:
            node_names = list(spike_patterns[0].keys())
            activities = {node: [np.mean(pattern.get(node, np.zeros((1,1)))) 
                               for pattern in spike_patterns] 
                         for node in node_names}
        else:
            activities = {}
    
    return {
        'spike_patterns': spike_patterns,
        'node_activities': activities,
        'num_clks_processed': len(spike_patterns)
    }