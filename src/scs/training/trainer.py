# src/scs/training/trainer.py
"""
SCS ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” í•™ìŠµ ì‹œìŠ¤í…œ
"""

import torch
from torch.utils.data import DataLoader
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from tqdm import tqdm
import logging
from pathlib import Path

from .loss import SCSLoss
from .metric import SCSMetrics


@dataclass
class TrainingConfig:
    """í•™ìŠµ ì„¤ì •"""
    epochs: int = 100
    learning_rate: float = 1e-3
    weight_decay: float = 1e-4
    gradient_clip_norm: float = 1.0
    eval_every: int = 5
    save_every: int = 10
    early_stopping_patience: int = 20
    device: str = "cuda"
    max_clk_training: int = 100  # í•™ìŠµ ì‹œ ê³ ì • CLK
    pad_token_id: int = 0  # íŒ¨ë”© í† í° ID


class SCSTrainer:
    """SCS ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(
        self,
        model: torch.nn.Module,
        config: TrainingConfig,
        loss_fn: Optional[SCSLoss] = None,
        optimizer: Optional[torch.optim.Optimizer] = None,
        scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None,
        tokenizer: Optional[Any] = None
    ):
        self.model = model
        self.config = config
        
        # ì†ì‹¤ í•¨ìˆ˜ (pad_token_id í¬í•¨)
        self.loss_fn = loss_fn or SCSLoss(pad_token_id=config.pad_token_id)
        
        # ìµœì í™”ê¸°ì™€ ìŠ¤ì¼€ì¤„ëŸ¬
        self.optimizer = optimizer or torch.optim.Adam(
            model.parameters(), 
            lr=config.learning_rate,
            weight_decay=config.weight_decay
        )
        self.scheduler = scheduler
        self.tokenizer = tokenizer
        
        self.device = config.device
        self.model.to(self.device)
        
        # í•™ìŠµ ìƒíƒœ
        self.current_epoch = 0
        self.best_loss = float('inf')
        self.patience_counter = 0
        self.best_model_path = None  # ìµœê³  ëª¨ë¸ ê²½ë¡œ ì¶”ê°€
        
        # ë¡œê¹…
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def train(
        self,
        train_loader: DataLoader,
        val_loader: Optional[DataLoader] = None,
        save_path: Optional[str] = None
    ) -> Dict[str, List[float]]:
        """í•™ìŠµ ì‹¤í–‰"""
        
        history = {
            'train_loss': [],
            'train_accuracy': [],
            'val_loss': [],
            'val_accuracy': []
        }
        
        self.logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ í•™ìŠµ ì‹œì‘: {self.config.epochs} ì—í¬í¬")
        
        # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        if save_path:
            save_dir = Path(save_path)
            save_dir.mkdir(parents=True, exist_ok=True)
        
        for epoch in range(self.config.epochs):
            self.current_epoch = epoch
            
            # í•™ìŠµ
            train_metrics = self._train_epoch(train_loader)
            history['train_loss'].append(train_metrics['loss'])
            history['train_accuracy'].append(train_metrics['accuracy'])
            
            # ê²€ì¦
            if val_loader and epoch % self.config.eval_every == 0:
                val_metrics = self._validate_epoch(val_loader)
                history['val_loss'].append(val_metrics['loss'])
                history['val_accuracy'].append(val_metrics['accuracy'])
                
                # ìµœê³  ëª¨ë¸ ì €ì¥ (validation loss ê¸°ì¤€)
                if save_path and val_metrics['loss'] < self.best_loss:
                    self.best_loss = val_metrics['loss']
                    self.best_model_path = self._save_best_model(save_path, epoch, val_metrics['loss'])
                    self.patience_counter = 0
                    self.logger.info(f"ğŸ† ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥: {self.best_model_path}")
                else:
                    self.patience_counter += 1
                
                # ì¡°ê¸° ì¢…ë£Œ ì²´í¬
                if self._should_early_stop(val_metrics['loss']):
                    self.logger.info(f"ì¡°ê¸° ì¢…ë£Œ: ì—í¬í¬ {epoch}")
                    break
            
            # ì •ê¸° ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if save_path and epoch % self.config.save_every == 0:
                self._save_checkpoint(save_path, epoch)
            
            # ë¡œê¹…
            self._log_progress(epoch, train_metrics, 
                             val_metrics if val_loader and epoch % self.config.eval_every == 0 else None)
        
        # í•™ìŠµ ì™„ë£Œ í›„ ìµœì¢… ìµœê³  ëª¨ë¸ì´ ì—†ë‹¤ë©´ ë§ˆì§€ë§‰ ëª¨ë¸ì„ ìµœê³  ëª¨ë¸ë¡œ ì €ì¥
        if save_path and self.best_model_path is None:
            self.best_model_path = self._save_best_model(save_path, self.current_epoch, self.best_loss)
            self.logger.info(f"ìµœì¢… ëª¨ë¸ì„ ìµœê³  ëª¨ë¸ë¡œ ì €ì¥: {self.best_model_path}")
        
        return history
    
    def _save_best_model(self, save_path: str, epoch: int, loss: float) -> str:
        """ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥"""
        best_model_path = f"{save_path}/best_model.pt"
        
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'best_loss': loss
        }
        
        if self.scheduler:
            checkpoint['scheduler_state_dict'] = self.scheduler.state_dict()
            
        torch.save(checkpoint, best_model_path)
        return best_model_path
    
    def _save_checkpoint(self, save_path: str, epoch: int):
        """ì •ê¸° ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        save_dir = Path(save_path)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'best_loss': self.best_loss
        }
        if self.scheduler:
            checkpoint['scheduler_state_dict'] = self.scheduler.state_dict()
        torch.save(checkpoint, f"{save_path}/checkpoint_epoch_{epoch}.pt")
    
    def _log_progress(self, epoch: int, train_metrics: Dict[str, float], val_metrics: Optional[Dict[str, float]] = None):
        """ì§„í–‰ ìƒí™© ë¡œê¹…"""
        log_msg = f"ì—í¬í¬ {epoch}: í›ˆë ¨ ì†ì‹¤={train_metrics['loss']:.4f}, í›ˆë ¨ ì •í™•ë„={train_metrics['accuracy']:.4f}"
        
        if val_metrics:
            log_msg += f", ê²€ì¦ ì†ì‹¤={val_metrics['loss']:.4f}, ê²€ì¦ ì •í™•ë„={val_metrics['accuracy']:.4f}"
            if val_metrics['loss'] < self.best_loss:
                log_msg += " â­"
        
        self.logger.info(log_msg)
    
    def _train_epoch(self, train_loader: DataLoader) -> Dict[str, float]:
        """í•œ ì—í¬í¬ ë°°ì¹˜ í•™ìŠµ"""
        self.model.train()
        
        total_loss = 0.0
        total_accuracy = 0.0
        num_batches = 0
        
        progress_bar = tqdm(train_loader, desc=f"Epoch {self.current_epoch}")
        
        for batch in progress_bar:
            # ë°°ì¹˜ ì²˜ë¦¬ (for ë£¨í”„ ì œê±°!)
            batch_loss, batch_metrics = self._train_batch(batch)
            
            total_loss += batch_loss
            total_accuracy += batch_metrics['accuracy']
            num_batches += 1
            
            progress_bar.set_postfix({
                'loss': f"{batch_loss:.4f}",
                'acc': f"{batch_metrics['accuracy']:.4f}"
            })
        
        return {
            'loss': total_loss / num_batches,
            'accuracy': total_accuracy / num_batches
        }
    
    def _train_batch(self, batch: Dict[str, torch.Tensor]) -> tuple:
        """ì§„ì •í•œ ë°°ì¹˜ í•™ìŠµ - GPU ë³‘ë ¬ ì²˜ë¦¬ í™œìš©"""
        # 1. ë°ì´í„° ì¤€ë¹„ ë° ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        input_tokens = batch['input_tokens'].to(self.device)
        target_tokens = batch['target_tokens'].to(self.device) 
        attention_mask = batch['attention_mask'].to(self.device)
        
        # 2. ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”
        self.optimizer.zero_grad()
        
        # 3. Forward Pass (ëª¨ë¸ì— ë°°ì¹˜ ì „ì²´ë¥¼ ì „ë‹¬)
        # ëª¨ë¸ì˜ forwardëŠ” ë‚´ë¶€ì ìœ¼ë¡œ CLK ë£¨í”„ë¥¼ ëŒê³  ìµœì¢… ë¡œì§“ [B, seq_len, vocab_size]ë¥¼ ë°˜í™˜
        output_logits, processing_info = self.model(
            input_schedule=input_tokens,
            max_clk=self.config.max_clk_training,  # YAML ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¨ ê³ ì • CLK
            training=True,
            target_schedule=target_tokens,
            attention_mask=attention_mask
        )
        
        # 4. ì†ì‹¤ ê³„ì‚° (ìˆ˜ì •ëœ loss_fn ì‚¬ìš©)
        loss = self.loss_fn(output_logits, target_tokens, processing_info)
        
        # 5. Backward Pass (ë°°ì¹˜ ì „ì²´ì— ëŒ€í•´ í•œ ë²ˆë§Œ ìˆ˜í–‰)
        loss.backward()
        
        # 6. ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
        if self.config.gradient_clip_norm > 0:
            torch.nn.utils.clip_grad_norm_(
                self.model.parameters(), 
                self.config.gradient_clip_norm
            )
        
        # 7. íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
        self.optimizer.step()
        if self.scheduler:
            self.scheduler.step()
            
        # 8. ë©”íŠ¸ë¦­ ê³„ì‚° (ì •í™•ë„)
        with torch.no_grad():
            accuracy = SCSMetrics.accuracy(
                output_logits, 
                target_tokens, 
                pad_token_id=self.config.pad_token_id
            )
            
        return loss.item(), {'accuracy': accuracy}
    
    
    def _validate_epoch(self, val_loader: DataLoader) -> Dict[str, float]:
        """ê²€ì¦ - ë°°ì¹˜ ì²˜ë¦¬"""
        self.model.eval()
        
        total_loss = 0.0
        total_accuracy = 0.0
        num_batches = 0
        
        with torch.no_grad():
            for batch in val_loader:
                # ğŸ¯ ë°°ì¹˜ ì „ì²´ë¥¼ í•œë²ˆì— ì²˜ë¦¬
                input_tokens = batch['input_tokens'].to(self.device)
                target_tokens = batch['target_tokens'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)
                
                # í•™ìŠµê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ë°°ì¹˜ ì²˜ë¦¬
                output_logits, processing_info = self.model(
                    input_schedule=input_tokens,
                    max_clk=self.config.max_clk_training,
                    training=True,
                    target_schedule=target_tokens,
                    attention_mask=attention_mask
                )
                
                # ë°°ì¹˜ ë‹¨ìœ„ ì†ì‹¤ ë° ë©”íŠ¸ë¦­ ê³„ì‚°
                batch_loss = self.loss_fn(output_logits, target_tokens, processing_info)
                batch_accuracy = SCSMetrics.accuracy(
                    output_logits, 
                    target_tokens, 
                    pad_token_id=self.config.pad_token_id
                )
                
                total_loss += batch_loss.item()
                total_accuracy += batch_accuracy
                num_batches += 1
        
        return {
            'loss': total_loss / num_batches,
            'accuracy': total_accuracy / num_batches
        }
    
    def _should_early_stop(self, val_loss: float) -> bool:
        """ì¡°ê¸° ì¢…ë£Œ íŒë‹¨"""
        if val_loss < self.best_loss:
            self.best_loss = val_loss
            self.patience_counter = 0
            return False
        else:
            self.patience_counter += 1
            return self.patience_counter >= self.config.early_stopping_patience
    
    def evaluate(self, test_loader: DataLoader) -> Dict[str, float]:
        """í…ŒìŠ¤íŠ¸ í‰ê°€ - ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì¼ê´€ì„± ìœ ì§€"""
        self.model.eval()
        
        total_loss = 0.0
        total_accuracy = 0.0
        total_comprehensive = 0.0
        total_convergence = 0.0
        total_efficiency = 0.0
        num_batches = 0
        
        with torch.no_grad():
            for batch in test_loader:
                # ë°°ì¹˜ ì „ì²´ë¥¼ í•œë²ˆì— ì²˜ë¦¬ (í•™ìŠµ/ê²€ì¦ê³¼ ë™ì¼í•œ ë°©ì‹)
                input_tokens = batch['input_tokens'].to(self.device)
                target_tokens = batch['target_tokens'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)
                
                # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ëª¨ë¸ ì‹¤í–‰
                output_logits, processing_info = self.model(
                    input_schedule=input_tokens,
                    max_clk=self.config.max_clk_training,
                    training=False,  # í‰ê°€ ëª¨ë“œ
                    target_schedule=target_tokens,
                    attention_mask=attention_mask
                )
                
                # ë°°ì¹˜ ë‹¨ìœ„ ì†ì‹¤ ë° ë©”íŠ¸ë¦­ ê³„ì‚°
                batch_loss = self.loss_fn(output_logits, target_tokens, processing_info)
                batch_accuracy = SCSMetrics.accuracy(
                    output_logits, 
                    target_tokens, 
                    pad_token_id=self.config.pad_token_id
                )
                
                # ìƒì„¸ ë©”íŠ¸ë¦­ë“¤ë„ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ê³„ì‚°
                batch_comprehensive = SCSMetrics.comprehensive_score(processing_info)
                batch_convergence = SCSMetrics.convergence_rate(processing_info)
                batch_efficiency = SCSMetrics.processing_efficiency(processing_info)
                
                total_loss += batch_loss.item()
                total_accuracy += batch_accuracy
                total_comprehensive += batch_comprehensive
                total_convergence += batch_convergence
                total_efficiency += batch_efficiency
                num_batches += 1
        
        return {
            'test_loss': total_loss / num_batches,
            'test_accuracy': total_accuracy / num_batches,
            'comprehensive_score': total_comprehensive / num_batches,
            'convergence_rate': total_convergence / num_batches,
            'processing_efficiency': total_efficiency / num_batches
        }


class GradualUnfreezingScheduler:
    """ì ì§„ì  ì–¸í”„ë¦¬ì§• ìŠ¤ì¼€ì¤„ëŸ¬"""
    
    def __init__(self, model, unfreezing_schedule: Dict[int, List[str]]):
        self.model = model
        self.schedule = unfreezing_schedule
        
        # ì´ˆê¸°ì—ëŠ” ëª¨ë“  íŒŒë¼ë¯¸í„° ê³ ì •
        for param in self.model.parameters():
            param.requires_grad = False
    
    def step(self, epoch: int):
        """ì—í¬í¬ì— ë”°ë¼ ì ì§„ì ìœ¼ë¡œ ì–¸í”„ë¦¬ì§•"""
        if epoch in self.schedule:
            modules_to_unfreeze = self.schedule[epoch]
            for module_name in modules_to_unfreeze:
                module = getattr(self.model, module_name, None)
                if module:
                    for param in module.parameters():
                        param.requires_grad = True