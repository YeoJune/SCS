# src/scs/training/trainer.py (ê°„ì†Œí™”ëœ ë²„ì „)
"""
SCS ê°„ì†Œí™”ëœ í•™ìŠµ ì‹œìŠ¤í…œ - Systemì˜ ì™„ì „í•œ ì‹œí€€ìŠ¤ ì²˜ë¦¬ í™œìš©
"""

import torch
from torch.utils.data import DataLoader
from typing import Dict, List, Optional, Any
from tqdm import tqdm
import logging
from pathlib import Path
from datetime import datetime

from .loss import SCSLoss
from ..evaluation.metrics import SCSMetrics
from ..config.schemas import LearningConfig
from ..utils import SCSTensorBoardLogger

class SCSTrainer:
    """SCS ê°„ì†Œí™”ëœ í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(
        self,
        model: torch.nn.Module,
        config: LearningConfig,
        loss_fn: Optional[SCSLoss] = None,
        optimizer: Optional[torch.optim.Optimizer] = None,
        scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None,
        tokenizer: Optional[Any] = None,
        unfreezing_config: Optional[Dict] = None,
        tensorboard_config: Optional[Dict] = None,
        experiment_dir: Optional[Path] = None
    ):
        self.model = model
        self.config = config

        # ë¡œê¹…
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # ì†ì‹¤ í•¨ìˆ˜
        self.loss_fn = loss_fn or SCSLoss(pad_token_id=config.pad_token_id)
        
        # ì ì§„ì  í•´ì œ ìŠ¤ì¼€ì¤„ëŸ¬ (ê¸°ì¡´ê³¼ ë™ì¼)
        self.unfreezing_scheduler = None
        if unfreezing_config and unfreezing_config.get('enabled', False):
            frozen_patterns = unfreezing_config.get('initial_frozen_patterns', [])
            unfreeze_schedule = unfreezing_config.get('unfreeze_schedule', {})
            freeze_schedule = unfreezing_config.get('freeze_schedule', {})

            self.unfreezing_scheduler = GradualUnfreezingScheduler(
                model=self.model,
                frozen_patterns=frozen_patterns,
                unfreeze_schedule=unfreeze_schedule,
                freeze_schedule=freeze_schedule,
                logger=self.logger
            )
        
        # ìµœì í™”ê¸°ì™€ ìŠ¤ì¼€ì¤„ëŸ¬
        self.optimizer = optimizer or torch.optim.Adam(
            filter(lambda p: p.requires_grad, model.parameters()) if self.unfreezing_scheduler else model.parameters(),
            lr=config.learning_rate,
            weight_decay=config.weight_decay
        )
        self.scheduler = scheduler
        self.tokenizer = tokenizer
        
        self.device = config.device
        self.model.to(self.device)
        
        # í•™ìŠµ ìƒíƒœ
        self.current_epoch = 0
        self.best_loss = float('inf')
        self.patience_counter = 0
        self.best_model_path = None
        self.current_ss_prob = self.config.ss_start_prob
        
        # í…ì„œë³´ë“œ ë¡œê·¸ ì´ˆê¸°í™”
        self.tb_logger = None
        if tensorboard_config and tensorboard_config.get('enabled', False):
            exp_dir_str = str(experiment_dir)

            log_base_name = tensorboard_config.get('log_dir', 'runs')
            tb_log_dir_str = exp_dir_str.replace('experiments', log_base_name, 1)

            tb_log_dir = Path(tb_log_dir_str)
            self.tb_logger = SCSTensorBoardLogger(tb_log_dir, tensorboard_config)

    
    def _update_scheduled_sampling_prob(self):
        """ìŠ¤ì¼€ì¤„ ìƒ˜í”Œë§ í™•ë¥  ì—…ë°ì´íŠ¸"""
        if not self.config.use_scheduled_sampling:
            self.current_ss_prob = 1.0
            return

        decay_epochs = self.config.ss_decay_epochs
        start_prob = self.config.ss_start_prob
        end_prob = self.config.ss_end_prob
        
        if self.current_epoch >= decay_epochs:
            self.current_ss_prob = end_prob
        else:
            self.current_ss_prob = start_prob - (start_prob - end_prob) * (self.current_epoch / decay_epochs)
        
        if hasattr(self, 'logger'):
            self.logger.info(f"Scheduled Sampling í™•ë¥  ì—…ë°ì´íŠ¸: {self.current_ss_prob:.4f}")

    def _update_curriculum_max_clk(self, epoch: int):
        """ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµ: max_clk ë™ì  ì¡°ì •"""
        schedule = self.config.curriculum_schedule
        sorted_schedule = sorted(schedule.items())
        
        current_max_clk = self.config.max_clk_training
        for start_epoch, max_clk in sorted_schedule:
            if epoch >= start_epoch:
                current_max_clk = max_clk
        
        if current_max_clk != self.config.max_clk_training:
            old_max_clk = self.config.max_clk_training
            self.config.max_clk_training = current_max_clk
            
            # ëª¨ë¸ì˜ max_clk ì—…ë°ì´íŠ¸
            self.model.set_max_clk(current_max_clk)
            
            # loss_fnì˜ max_clkë„ ì—…ë°ì´íŠ¸
            if hasattr(self.loss_fn, 'update_max_clk'):
                self.loss_fn.update_max_clk(current_max_clk)
            
            self.logger.info(f"ğŸ“š ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµ: ì—í¬í¬ {epoch}, max_clk {old_max_clk} â†’ {current_max_clk}")

    def train(
        self,
        train_loader: DataLoader,
        val_loader: Optional[DataLoader] = None,
        save_path: Optional[str] = None
    ) -> Dict[str, List[float]]:
        """í•™ìŠµ ì‹¤í–‰"""
        
        history = {
            'train_loss': [],
            'train_accuracy': [],
            'val_loss': [],
            'val_accuracy': []
        }
        
        self.logger.info(f"ê°„ì†Œí™”ëœ í•™ìŠµ ì‹œì‘: {self.config.epochs} ì—í¬í¬")
        
        if save_path:
            save_dir = Path(save_path)
            save_dir.mkdir(parents=True, exist_ok=True)
        
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹… (í•™ìŠµ ì‹œì‘ ì‹œ í•œ ë²ˆ)
        if self.tb_logger:
            try:
                hparams = self.config.model_dump()
                initial_metrics = {"initial_loss": float('inf'), "initial_accuracy": 0.0}
                self.tb_logger.log_hyperparameters(hparams, initial_metrics)
            except Exception as e:
                self.logger.warning(f"í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹… ì‹¤íŒ¨: {e}")
        
        for epoch in range(self.config.epochs):
            self.current_epoch = epoch
            
            # TensorBoard ì—í¬í¬ ì„¤ì •
            if self.tb_logger:
                self.tb_logger.set_epoch(epoch)
            
            # ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµ
            if self.config.use_curriculum_learning and self.config.curriculum_schedule:
                self._update_curriculum_max_clk(epoch)
            
            # ì ì§„ì  í•´ì œ
            if self.unfreezing_scheduler:
                optimizer_needs_update = self.unfreezing_scheduler.step(epoch)
                if optimizer_needs_update:
                    self.logger.info("ğŸ“ ì˜µí‹°ë§ˆì´ì € ì¬ìƒì„±")
                    self.optimizer = torch.optim.AdamW(
                        filter(lambda p: p.requires_grad, self.model.parameters()),
                        lr=self.config.learning_rate,
                        weight_decay=self.config.weight_decay
                    )
                    if self.scheduler:
                        eta_min = getattr(self.config, 'eta_min', 0.0)
                        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
                            self.optimizer, 
                            T_max=self.config.epochs - epoch,
                            eta_min=eta_min
                        )

            self._update_scheduled_sampling_prob()
            
            # í•™ìŠµ
            train_metrics = self._train_epoch(train_loader)
            history['train_loss'].append(train_metrics['loss'])
            history['train_accuracy'].append(train_metrics['accuracy'])
            
            # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œê¹… (ì£¼ê¸°ì )
            if self.tb_logger and epoch % self.tb_logger.histogram_freq == 0:
                try:
                    self.tb_logger.log_model_weights(self.model)
                except Exception as e:
                    self.logger.warning(f"ê°€ì¤‘ì¹˜ ë¡œê¹… ì‹¤íŒ¨: {e}")
            
            # í•™ìŠµë¥  ë¡œê¹…
            if self.tb_logger and self.scheduler:
                try:
                    current_lr = self.scheduler.get_last_lr()[0] if hasattr(self.scheduler, 'get_last_lr') else self.config.learning_rate
                    self.tb_logger.log_learning_rate(current_lr)
                except Exception as e:
                    self.logger.warning(f"í•™ìŠµë¥  ë¡œê¹… ì‹¤íŒ¨: {e}")
            
            # ìŠ¤ì¼€ì¤„ëŸ¬ ìŠ¤í…
            if self.scheduler:
                self.scheduler.step()
            
            # ê²€ì¦
            if val_loader and epoch % self.config.eval_every == 0:
                val_metrics = self._validate_epoch(val_loader)
                history['val_loss'].append(val_metrics['loss'])
                history['val_accuracy'].append(val_metrics['accuracy'])
                
                # ìµœê³  ëª¨ë¸ ì €ì¥
                if save_path and val_metrics['loss'] < self.best_loss:
                    self.best_loss = val_metrics['loss']
                    self.best_model_path = self._save_best_model(save_path, epoch, val_metrics['loss'])
                    self.patience_counter = 0
                    self.logger.info(f"ğŸ† ìƒˆë¡œìš´ ìµœê³  ëª¨ë¸ ì €ì¥: {self.best_model_path}")
                else:
                    self.patience_counter += 1
                
                # ì¡°ê¸° ì¢…ë£Œ
                if self._should_early_stop(val_metrics['loss']):
                    self.logger.info(f"ì¡°ê¸° ì¢…ë£Œ: ì—í¬í¬ {epoch}")
                    break
            
            # ì •ê¸° ì²´í¬í¬ì¸íŠ¸
            if save_path and epoch % self.config.save_every == 0:
                self._save_checkpoint(save_path, epoch)
            
            # ë¡œê¹…
            self._log_progress(epoch, train_metrics, 
                            val_metrics if val_loader and epoch % self.config.eval_every == 0 else None)
        
        # ìµœì¢… ëª¨ë¸ ì €ì¥
        if save_path and self.best_model_path is None:
            self.best_model_path = self._save_best_model(save_path, self.current_epoch, self.best_loss)
            self.logger.info(f"ìµœì¢… ëª¨ë¸ì„ ìµœê³  ëª¨ë¸ë¡œ ì €ì¥: {self.best_model_path}")
        
        # í•™ìŠµ ì™„ë£Œ ì‹œ TensorBoard ë¡œê±° ì¢…ë£Œ
        if self.tb_logger:
            self.tb_logger.close()
        
        return history
    
    def _train_epoch(self, train_loader: DataLoader) -> Dict[str, float]:
        """í•œ ì—í¬í¬ í•™ìŠµ - ê°„ì†Œí™”ë¨"""
        self.model.train()
        
        total_loss = 0.0
        total_accuracy = 0.0
        num_batches = 0
        num_samples = 0
        
        progress_bar = tqdm(train_loader, desc=f"Epoch {self.current_epoch}")
        
        for batch in progress_bar:
            batch_loss, batch_metrics = self._train_batch(batch)
            
            total_loss += batch_loss
            total_accuracy += batch_metrics['accuracy'] * batch_metrics['batch_size']
            num_batches += 1
            num_samples += batch_metrics['batch_size']

            progress_bar.set_postfix({
                'loss': f"{batch_loss:.4f}",
                'acc': f"{batch_metrics['accuracy']:.4f}"
            })
        
        return {
            'loss': total_loss / num_batches,
            'accuracy': total_accuracy / num_samples
        }
    
    def _train_batch(self, batch: Dict[str, torch.Tensor]) -> tuple:
        """ë°°ì¹˜ í•™ìŠµ - ëŒ€í­ ê°„ì†Œí™”ë¨"""
        # ë°ì´í„° ì¤€ë¹„
        input_tokens = batch['input_tokens'].to(self.device)
        target_tokens = batch['target_tokens'].to(self.device) 
        attention_mask = batch['attention_mask'].to(self.device)
        
        # ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”
        self.optimizer.zero_grad()
        
        # ğŸš€ í•µì‹¬: ì‹œìŠ¤í…œì´ ëª¨ë“  ê²ƒì„ ì²˜ë¦¬!
        result = self.model(
            input_tokens=input_tokens,
            target_tokens=target_tokens,
            attention_mask=attention_mask,
            training=True,
            scheduled_sampling_prob=self.current_ss_prob,
            tensorboard_logger=self.tb_logger  # TensorBoard ë¡œê±° ì „ë‹¬
        )
        
        # ì†ì‹¤ ê³„ì‚°
        output_logits = result['output_logits']
        processing_info = result['processing_info']
        
        if output_logits.shape[1] > 0:
            # ì†ì‹¤ í•¨ìˆ˜ì— tb_logger ì„¤ì •
            if self.tb_logger:
                self.loss_fn._tb_logger = self.tb_logger

            loss = self.loss_fn(output_logits, target_tokens, processing_info)
        else:
            loss = torch.tensor(0.0, device=self.device, requires_grad=True)
        
        # ì—­ì „íŒŒ
        loss.backward()
        if self.config.gradient_clip_norm > 0:
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.gradient_clip_norm)
        self.optimizer.step()
        
        # ì •í™•ë„ ê³„ì‚°
        with torch.no_grad():
            if output_logits.shape[1] > 0:
                accuracy = SCSMetrics.accuracy(output_logits, target_tokens, pad_token_id=self.config.pad_token_id, guide_sep_token_id=self.config.guide_sep_token_id)
            else:
                accuracy = 0.0
        
        # ë°°ì¹˜ ë©”íŠ¸ë¦­ êµ¬ì„±
        batch_metrics = {'accuracy': accuracy, 'batch_size': input_tokens.size(0)}
        
        # TensorBoard ë¡œê¹…
        if self.tb_logger:
            self.tb_logger.log_training_step(batch_metrics, loss.item())

            if (self.tb_logger.should_log("axonal_heatmaps")):
                try:
                    if 'axonal_parameters' in processing_info:
                        self.tb_logger.log_axonal_heatmaps(
                            processing_info['axonal_parameters'], 
                            step=self.tb_logger.global_step
                        )
                except Exception as e:
                    pass
            if (self.tb_logger.should_log("weight_heatmaps")):
                try:
                    self.tb_logger.log_weight_heatmaps(
                        self.model,
                        step=self.tb_logger.global_step
                    )
                except Exception as e:
                    pass

        return loss.item(), batch_metrics

    def _validate_epoch(self, val_loader: DataLoader) -> Dict[str, float]:
        """ê²€ì¦ - ê°„ì†Œí™”ë¨"""
        self.model.eval()
        total_loss = 0.0
        total_accuracy = 0.0
        num_samples = 0
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(val_loader):
                input_tokens = batch['input_tokens'].to(self.device)
                target_tokens = batch['target_tokens'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)

                # ğŸš€ ì‹œìŠ¤í…œì´ ëª¨ë“  ì¶”ë¡  ì²˜ë¦¬!
                result = self.model(
                    input_tokens=input_tokens,
                    target_tokens=target_tokens,  # ê¸¸ì´ ì°¸ì¡°ìš©
                    attention_mask=attention_mask,
                    training=False,
                    scheduled_sampling_prob=0.0,  # ì™„ì „ auto-regressive
                    tensorboard_logger=self.tb_logger  # TensorBoard ë¡œê±° ì „ë‹¬
                )
                
                # ì†ì‹¤ ë° ì •í™•ë„ ê³„ì‚°
                output_logits = result['output_logits']
                processing_info = result['processing_info']
                
                if output_logits.shape[1] > 0:
                    # ì†ì‹¤ í•¨ìˆ˜ì— tb_logger ì„¤ì •
                    if self.tb_logger:
                        self.loss_fn._tb_logger = self.tb_logger

                    batch_loss = self.loss_fn(output_logits, target_tokens, processing_info)
                    batch_accuracy = SCSMetrics.accuracy(output_logits, target_tokens, pad_token_id=self.config.pad_token_id, guide_sep_token_id=self.config.guide_sep_token_id)
                else:
                    batch_loss = torch.tensor(float('inf'))
                    batch_accuracy = 0.0

                # ê²€ì¦ ì¤‘ ë‹¤ì–‘í•œ ì‹œê°í™” ë¡œê¹… (ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ)
                if batch_idx == 0 and self.tb_logger:
                    try:
                        # Axonal íˆíŠ¸ë§µ ì‹œê°í™”
                        if 'axonal_parameters' in processing_info:
                            self.tb_logger.log_axonal_heatmaps(
                                processing_info['axonal_parameters'], 
                                step=self.current_epoch
                            )
                        
                        # ê°€ì¤‘ì¹˜ íˆíŠ¸ë§µ (ë…¸ë“œëª…ì´ ìˆì„ ë•Œë§Œ)
                        if hasattr(self.model, 'nodes'):
                            node_names = list(self.model.nodes.keys())
                            self.tb_logger.log_weight_heatmaps(
                                self.model, node_names, step=self.current_epoch
                            )
                            
                    except Exception as e:
                        pass
                    
                total_loss += batch_loss.item()
                total_accuracy += batch_accuracy * input_tokens.size(0)
                num_samples += input_tokens.size(0)

        # í‰ê·  ë©”íŠ¸ë¦­ ê³„ì‚°
        avg_loss = total_loss / num_samples
        avg_accuracy = total_accuracy / num_samples

        # TensorBoard ë¡œê¹…
        if self.tb_logger:
            self.tb_logger.log_validation_step({'loss': avg_loss, 'accuracy': avg_accuracy})
        
        return {'loss': avg_loss, 'accuracy': avg_accuracy}

    def evaluate(self, test_loader: DataLoader, save_examples: int = 10) -> Dict[str, Any]:
        """í‰ê°€ - ë°°ì¹˜ ë‹¨ìœ„ ê³„ì‚°ìœ¼ë¡œ ìµœì í™”"""
        self.model.eval()
        
        # ì „ì²´ ë°°ì¹˜ ë©”íŠ¸ë¦­ ëˆ„ì ìš©
        total_accuracy = 0.0
        total_samples = 0
        total_convergence_count = 0
        total_processing_clk = 0.0
        total_tokens_generated = 0.0
        
        # ì˜ˆì‹œ ì €ì¥ìš©
        saved_examples = []
        examples_collected = 0
        
        with torch.no_grad():
            for batch_idx, batch in enumerate(test_loader):
                input_tokens = batch['input_tokens'].to(self.device)
                target_tokens = batch['target_tokens'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)
                
                batch_size = input_tokens.shape[0]
                
                # ğŸš€ ì‹œìŠ¤í…œì´ ì™„ì „í•œ ì¶”ë¡  ì²˜ë¦¬!
                result = self.model(
                    input_tokens=input_tokens,
                    target_tokens=target_tokens,
                    attention_mask=attention_mask,
                    training=False,
                    scheduled_sampling_prob=0.0,  # ì™„ì „ auto-regressive
                )
                
                # === ë°°ì¹˜ ë‹¨ìœ„ ë©”íŠ¸ë¦­ ê³„ì‚° ===
                output_logits = result['output_logits']
                processing_info = result['processing_info']
                
                if output_logits.shape[1] > 0:
                    batch_accuracy = SCSMetrics.accuracy(
                        output_logits, target_tokens, 
                        pad_token_id=self.config.pad_token_id, 
                        guide_sep_token_id=self.config.guide_sep_token_id
                    )
                else:
                    batch_accuracy = 0.0
                
                # ë°°ì¹˜ ë©”íŠ¸ë¦­ ëˆ„ì 
                total_accuracy += batch_accuracy * batch_size
                total_samples += batch_size
                total_convergence_count += processing_info['convergence_achieved'] * batch_size
                total_processing_clk += processing_info['processing_clk'] * batch_size
                total_tokens_generated += processing_info['tokens_generated'] * batch_size
                
                # === ì˜ˆì‹œ ìˆ˜ì§‘ (í•„ìš”í•œ ê°œìˆ˜ë§Œí¼ë§Œ) ===
                if examples_collected < save_examples:
                    samples_to_collect = min(save_examples - examples_collected, batch_size)
                    
                    for sample_idx in range(samples_to_collect):
                        global_idx = total_samples - batch_size + sample_idx
                        sample_result = self._extract_sample_from_result(
                            batch, result, sample_idx, global_idx
                        )
                        saved_examples.append(sample_result)
                        examples_collected += 1
        
        # === ì „ì²´ í‰ê·  ë©”íŠ¸ë¦­ ê³„ì‚° ===
        avg_accuracy = total_accuracy / total_samples
        convergence_rate = total_convergence_count / total_samples
        avg_processing_clk = total_processing_clk / total_samples
        avg_tokens_generated = total_tokens_generated / total_samples
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚° (ê¸°ì¡´ê³¼ ë™ì¼)
        processing_efficiency = max(0.0, 1.0 - (avg_processing_clk / self.config.max_clk_training))
        comprehensive_score = (
            0.4 * convergence_rate +
            0.3 * processing_efficiency +
            0.2 * min(1.0, (avg_tokens_generated / 10.0)) +
            0.1 * avg_accuracy
        )
        
        # ê¸°ì¡´ê³¼ ë™ì¼í•œ print ë° return
        print(f"\n=== ì „ì²´ {total_samples}ê°œ ìƒ˜í”Œ ê²°ê³¼ ì§‘ê³„ ===")
        print(f"ìµœì¢… ê²°ê³¼: ì •í™•ë„={avg_accuracy:.4f}, ì¢…í•©ì ìˆ˜={comprehensive_score:.4f}")
        
        return {
            'test_accuracy': avg_accuracy,
            'comprehensive_score': comprehensive_score,
            'convergence_rate': convergence_rate,
            'processing_efficiency': processing_efficiency,
            'examples': saved_examples,
            'num_examples_saved': len(saved_examples),
            'total_samples_evaluated': total_samples
        }
    
    def _should_early_stop(self, val_loss: float) -> bool:
        """ì¡°ê¸° ì¢…ë£Œ íŒë‹¨"""
        if val_loss < self.best_loss:
            self.best_loss = val_loss
            self.patience_counter = 0
            return False
        else:
            self.patience_counter += 1
            return self.patience_counter >= self.config.early_stopping_patience
    
    def _save_best_model(self, save_path: str, epoch: int, loss: float) -> str:
        """ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥"""
        best_model_path = f"{save_path}/best_model.pt"
        
        config_dict = {
            'epochs': self.config.epochs,
            'learning_rate': self.config.learning_rate,
            'weight_decay': self.config.weight_decay,
            'gradient_clip_norm': self.config.gradient_clip_norm,
            'eval_every': self.config.eval_every,
            'save_every': self.config.save_every,
            'early_stopping_patience': self.config.early_stopping_patience,
            'device': self.config.device,
            'max_clk_training': self.config.max_clk_training,
            'pad_token_id': self.config.pad_token_id,
            'use_scheduled_sampling': self.config.use_scheduled_sampling,
            'ss_start_prob': self.config.ss_start_prob,
            'ss_end_prob': self.config.ss_end_prob,
            'ss_decay_epochs': self.config.ss_decay_epochs,
            'eta_min': self.config.eta_min,
        }
        
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'best_loss': loss,
            'config_dict': config_dict,
            'model_config': getattr(self.model, 'config', None),
            'tokenizer_vocab_size': getattr(self.tokenizer, 'vocab_size', None) if self.tokenizer else None,
            'save_timestamp': datetime.now().isoformat(),
            'current_ss_prob': getattr(self, 'current_ss_prob', None)
        }
        
        if self.scheduler:
            checkpoint['scheduler_state_dict'] = self.scheduler.state_dict()
            
        torch.save(checkpoint, best_model_path)
        return best_model_path

    def _extract_sample_from_result(
        self, 
        batch: Dict[str, torch.Tensor], 
        result: Dict[str, Any], 
        sample_idx: int, 
        global_idx: int
    ) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ê²°ê³¼ì—ì„œ ê°œë³„ ìƒ˜í”Œ ê²°ê³¼ ì¶”ì¶œ"""
        try:
            # í…ìŠ¤íŠ¸ ë³µì›
            input_text = self._decode_tokens_to_text(batch['input_tokens'][sample_idx])
            target_text = self._decode_tokens_to_text(batch['target_tokens'][sample_idx])
            
            # ìƒì„± ê²°ê³¼ ì¶”ì¶œ
            generated_tokens = result['generated_tokens'][sample_idx]
            generated_text = self._decode_tokens_to_text(generated_tokens) if generated_tokens.numel() > 0 else "[ë¹ˆ ì¶œë ¥]"
            
            # ì •í™•ë„ ê³„ì‚°
            output_logits = result['output_logits'][sample_idx:sample_idx+1]
            target_tokens = batch['target_tokens'][sample_idx:sample_idx+1].to(output_logits.device)
            
            if output_logits.shape[1] > 0:
                accuracy = SCSMetrics.accuracy(
                    output_logits,
                    target_tokens[:, :output_logits.shape[1]],
                    pad_token_id=self.config.pad_token_id,
                    guide_sep_token_id=self.config.guide_sep_token_id
                )
            else:
                accuracy = 0.0
            
            processing_info = result['processing_info']
            
            return {
                'input_text': input_text,
                'target_text': target_text,
                'generated_text': generated_text,
                'accuracy': accuracy,
                'processing_clk': processing_info['processing_clk'],
                'tokens_generated': processing_info['tokens_generated'],
                'convergence_achieved': processing_info['convergence_achieved'],
                'generation_method': 'system_complete_processing',
                'global_index': global_idx,
            }
            
        except Exception as e:
            return {
                'input_text': "[ì¶”ì¶œ ì‹¤íŒ¨]",
                'target_text': "[ì¶”ì¶œ ì‹¤íŒ¨]",
                'generated_text': "[ì¶”ë¡  ì‹¤íŒ¨]",
                'accuracy': 0.0,
                'processing_clk': self.config.max_clk_training,
                'tokens_generated': 0,
                'convergence_achieved': False,
                'generation_method': 'error',
                'global_index': global_idx,
                'error': str(e)
            }

    def _save_checkpoint(self, save_path: str, epoch: int):
        """ì •ê¸° ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        save_dir = Path(save_path)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        config_dict = {
            'epochs': self.config.epochs,
            'learning_rate': self.config.learning_rate,
            'weight_decay': self.config.weight_decay,
            'gradient_clip_norm': self.config.gradient_clip_norm,
            'eval_every': self.config.eval_every,
            'save_every': self.config.save_every,
            'early_stopping_patience': self.config.early_stopping_patience,
            'device': self.config.device,
            'max_clk_training': self.config.max_clk_training,
            'pad_token_id': self.config.pad_token_id,
            'use_scheduled_sampling': self.config.use_scheduled_sampling,
            'ss_start_prob': self.config.ss_start_prob,
            'ss_end_prob': self.config.ss_end_prob,
            'ss_decay_epochs': self.config.ss_decay_epochs,
            'eta_min': self.config.eta_min,
        }
        
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'best_loss': self.best_loss,
            'config_dict': config_dict,
            'model_config': getattr(self.model, 'config', None),
            'tokenizer_vocab_size': getattr(self.tokenizer, 'vocab_size', None) if self.tokenizer else None,
            'save_timestamp': datetime.now().isoformat(),
            'current_ss_prob': getattr(self, 'current_ss_prob', None)
        }
        
        if self.scheduler:
            checkpoint['scheduler_state_dict'] = self.scheduler.state_dict()
        
        torch.save(checkpoint, f"{save_path}/checkpoint_epoch_{epoch}.pt")
    
    def _log_progress(self, epoch: int, train_metrics: Dict[str, float], val_metrics: Optional[Dict[str, float]] = None):
        """ì§„í–‰ ìƒí™© ë¡œê¹…"""
        log_msg = f"ì—í¬í¬ {epoch}: í›ˆë ¨ ì†ì‹¤={train_metrics['loss']:.4f}, í›ˆë ¨ ì •í™•ë„={train_metrics['accuracy']:.4f}"
        
        if val_metrics:
            log_msg += f", ê²€ì¦ ì†ì‹¤={val_metrics['loss']:.4f}, ê²€ì¦ ì •í™•ë„={val_metrics['accuracy']:.4f}"
            if val_metrics['loss'] < self.best_loss:
                log_msg += " â­"
        
        self.logger.info(log_msg)

    def _decode_tokens_to_text(self, tokens: torch.Tensor) -> str:
        """í† í°ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        if self.tokenizer is None:
            return f"tokens: {tokens.tolist()}"
        
        try:
            # íŒ¨ë”© í† í° ì œê±°
            if hasattr(self.tokenizer, 'tokenizer'):
                pad_token_id = self.tokenizer.tokenizer.pad_token_id
            else:
                pad_token_id = self.config.pad_token_id
                
            # íŒ¨ë”©ì´ ì•„ë‹Œ í† í°ë§Œ ì„ íƒ
            valid_tokens = tokens[tokens != pad_token_id]
            
            # í† í¬ë‚˜ì´ì €ë¡œ ë””ì½”ë”©
            if hasattr(self.tokenizer, 'decode'):
                return self.tokenizer.decode(valid_tokens.tolist())
            elif hasattr(self.tokenizer, 'tokenizer'):
                return self.tokenizer.tokenizer.decode(valid_tokens.tolist(), skip_special_tokens=False)
            else:
                return f"tokens: {valid_tokens.tolist()}"
                
        except Exception as e:
            return f"decode_error: {tokens.tolist()}"


class GradualUnfreezingScheduler:
    """ì ì§„ì  ì–¸í”„ë¦¬ì§•/í”„ë¦¬ì§• ìŠ¤ì¼€ì¤„ëŸ¬ - ë™ê²° íŒ¨í„´ ê¸°ë°˜"""
    
    def __init__(self, model, frozen_patterns: List[str], unfreeze_schedule: Dict[int, List[str]] = None, freeze_schedule: Dict[int, List[str]] = None, logger=None):
        """
        Args:
            model: SCS ëª¨ë¸
            frozen_patterns: ì´ˆê¸°ì— ë™ê²°í•  íŒŒë¼ë¯¸í„° íŒ¨í„´ë“¤
            unfreeze_schedule: {epoch: [patterns]} í˜•íƒœì˜ í•´ì œ ìŠ¤ì¼€ì¤„
            freeze_schedule: {epoch: [patterns]} í˜•íƒœì˜ ë™ê²° ìŠ¤ì¼€ì¤„
            logger: ë¡œê¹… ê°ì²´
        """
        self.model = model
        self.frozen_patterns = frozen_patterns
        self.unfreeze_schedule = unfreeze_schedule or {}
        self.freeze_schedule = freeze_schedule or {}
        self.logger = logger
        self.current_epoch = -1
        self.unfrozen_patterns = set()  # ì´ë¯¸ í•´ì œëœ íŒ¨í„´ë“¤ ì¶”ì 
        
        # ì§€ì •ëœ íŒ¨í„´ë§Œ ë™ê²°
        if self.frozen_patterns:
            self._freeze_by_patterns(self.frozen_patterns)
            
        if self.logger:
            total_params = sum(p.numel() for p in self.model.parameters())
            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
            self.logger.info(f"ğŸ”’ ì´ˆê¸° íŒŒë¼ë¯¸í„° ìƒíƒœ: {trainable_params:,}/{total_params:,} í•™ìŠµ ê°€ëŠ¥")
    
    def _freeze_by_patterns(self, patterns: List[str]):
        """íŒ¨í„´ì— ë§¤ì¹­ë˜ëŠ” íŒŒë¼ë¯¸í„°ë“¤ ë™ê²°"""
        frozen_count = 0
        for name, param in self.model.named_parameters():
            for pattern in patterns:
                if name.startswith(pattern):
                    param.requires_grad = False
                    frozen_count += param.numel()
                    if self.logger:
                        self.logger.info(f"ğŸ”’ ë™ê²°: {name} ({param.numel():,} íŒŒë¼ë¯¸í„°)")
                    break
        
        if self.logger and frozen_count > 0:
            self.logger.info(f"ì´ {frozen_count:,}ê°œ íŒŒë¼ë¯¸í„° ë™ê²° ì™„ë£Œ")
    
    def _unfreeze_by_patterns(self, patterns: List[str]) -> bool:
        """íŒ¨í„´ì— ë§¤ì¹­ë˜ëŠ” íŒŒë¼ë¯¸í„°ë“¤ í•´ì œ"""
        newly_unfrozen = False
        unfrozen_count = 0
        
        for pattern in patterns:
            if pattern in self.unfrozen_patterns:
                continue  # ì´ë¯¸ í•´ì œëœ íŒ¨í„´ì€ ìŠ¤í‚µ
                
            for name, param in self.model.named_parameters():
                if name.startswith(pattern) and not param.requires_grad:
                    param.requires_grad = True
                    unfrozen_count += param.numel()
                    newly_unfrozen = True
                    if self.logger:
                        self.logger.info(f"ğŸ”“ í•´ì œ: {name} ({param.numel():,} íŒŒë¼ë¯¸í„°)")
            
            self.unfrozen_patterns.add(pattern)
        
        if self.logger and unfrozen_count > 0:
            self.logger.info(f"ì´ {unfrozen_count:,}ê°œ íŒŒë¼ë¯¸í„° í•´ì œ ì™„ë£Œ")
        
        return newly_unfrozen
    
    def step(self, epoch: int) -> bool:
        """
        ì—í¬í¬ ì§„í–‰ ì‹œ í˜¸ì¶œ. ìƒˆë¡œìš´ íŒ¨í„´ì´ ë³€ê²½ë˜ë©´ True ë°˜í™˜
        
        Args:
            epoch: í˜„ì¬ ì—í¬í¬
            
        Returns:
            bool: ì˜µí‹°ë§ˆì´ì € ì¬ìƒì„±ì´ í•„ìš”í•œì§€ ì—¬ë¶€
        """
        if epoch == self.current_epoch:
            return False
            
        self.current_epoch = epoch
        optimizer_needs_update = False
        
        # freeze schedule ì²˜ë¦¬ (ì¶”ê°€ëœ ë¶€ë¶„)
        if epoch in self.freeze_schedule:
            if self.logger:
                self.logger.info(f"ğŸ“… ì—í¬í¬ {epoch}: ì ì§„ì  ë™ê²° ì‹¤í–‰")
            
            patterns_to_freeze = self.freeze_schedule[epoch]
            self._freeze_by_patterns(patterns_to_freeze)
            
            # í•´ì œëœ íŒ¨í„´ì—ì„œ ì œê±°
            for pattern in patterns_to_freeze:
                self.unfrozen_patterns.discard(pattern)
            
            optimizer_needs_update = True
        
        # unfreeze schedule ì²˜ë¦¬ (ê¸°ì¡´ ì½”ë“œ)
        if epoch in self.unfreeze_schedule:
            if self.logger:
                self.logger.info(f"ğŸ“… ì—í¬í¬ {epoch}: ì ì§„ì  í•´ì œ ì‹¤í–‰")
            
            patterns_to_unfreeze = self.unfreeze_schedule[epoch]
            newly_unfrozen = self._unfreeze_by_patterns(patterns_to_unfreeze)
            
            if newly_unfrozen:
                optimizer_needs_update = True
        
        # ìƒíƒœ ë³€ê²½ì´ ìˆì—ˆë‹¤ë©´ í†µê³„ ì¶œë ¥
        if optimizer_needs_update:
            total_params = sum(p.numel() for p in self.model.parameters())
            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
            
            if self.logger:
                self.logger.info(f"ğŸ“Š í˜„ì¬ í•™ìŠµ ê°€ëŠ¥ íŒŒë¼ë¯¸í„°: {trainable_params:,}/{total_params:,} "
                               f"({100*trainable_params/total_params:.1f}%)")
        
        return optimizer_needs_update