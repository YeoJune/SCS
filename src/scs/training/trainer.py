# src/scs/training/trainer.py
"""
SCS ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” í•™ìŠµ ì‹œìŠ¤í…œ
"""

import torch
from torch.utils.data import DataLoader
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from tqdm import tqdm
import logging

from .loss import SCSLoss
from .metric import SCSMetrics


@dataclass
class TrainingConfig:
    """í•™ìŠµ ì„¤ì •"""
    epochs: int = 100
    learning_rate: float = 1e-3
    weight_decay: float = 1e-4
    gradient_clip_norm: float = 1.0
    eval_every: int = 5
    save_every: int = 10
    early_stopping_patience: int = 20
    device: str = "cuda"
    max_clk_training: int = 100  # í•™ìŠµ ì‹œ ê³ ì • CLK
    pad_token_id: int = 0  # íŒ¨ë”© í† í° ID


class SCSTrainer:
    """SCS ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(
        self,
        model: torch.nn.Module,
        config: TrainingConfig,
        loss_fn: Optional[SCSLoss] = None,
        optimizer: Optional[torch.optim.Optimizer] = None,
        scheduler: Optional[torch.optim.lr_scheduler._LRScheduler] = None,
        tokenizer: Optional[Any] = None
    ):
        self.model = model
        self.config = config
        
        # ì†ì‹¤ í•¨ìˆ˜ (pad_token_id í¬í•¨)
        self.loss_fn = loss_fn or SCSLoss(pad_token_id=config.pad_token_id)
        
        # ìµœì í™”ê¸°ì™€ ìŠ¤ì¼€ì¤„ëŸ¬
        self.optimizer = optimizer or torch.optim.Adam(
            model.parameters(), 
            lr=config.learning_rate,
            weight_decay=config.weight_decay
        )
        self.scheduler = scheduler
        self.tokenizer = tokenizer
        
        self.device = config.device
        self.model.to(self.device)
        
        # í•™ìŠµ ìƒíƒœ
        self.current_epoch = 0
        self.best_loss = float('inf')
        self.patience_counter = 0
        
        # ë¡œê¹…
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
    
    def train(
        self,
        train_loader: DataLoader,
        val_loader: Optional[DataLoader] = None,
        save_path: Optional[str] = None
    ) -> Dict[str, List[float]]:
        """í•™ìŠµ ì‹¤í–‰"""
        
        history = {
            'train_loss': [],
            'train_accuracy': [],
            'val_loss': [],
            'val_accuracy': []
        }
        
        self.logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ í•™ìŠµ ì‹œì‘: {self.config.epochs} ì—í¬í¬")
        
        for epoch in range(self.config.epochs):
            self.current_epoch = epoch
            
            # í•™ìŠµ
            train_metrics = self._train_epoch(train_loader)
            history['train_loss'].append(train_metrics['loss'])
            history['train_accuracy'].append(train_metrics['accuracy'])
            
            # ê²€ì¦
            if val_loader and epoch % self.config.eval_every == 0:
                val_metrics = self._validate_epoch(val_loader)
                history['val_loss'].append(val_metrics['loss'])
                history['val_accuracy'].append(val_metrics['accuracy'])
                
                # ì¡°ê¸° ì¢…ë£Œ ì²´í¬
                if self._should_early_stop(val_metrics['loss']):
                    self.logger.info(f"ì¡°ê¸° ì¢…ë£Œ: ì—í¬í¬ {epoch}")
                    break
            
            # ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            if save_path and epoch % self.config.save_every == 0:
                self._save_checkpoint(save_path, epoch)
            
            # ë¡œê¹…
            self._log_progress(epoch, train_metrics)
        
        return history
    
    def _train_epoch(self, train_loader: DataLoader) -> Dict[str, float]:
        """í•œ ì—í¬í¬ ë°°ì¹˜ í•™ìŠµ"""
        self.model.train()
        
        total_loss = 0.0
        total_accuracy = 0.0
        num_batches = 0
        
        progress_bar = tqdm(train_loader, desc=f"Epoch {self.current_epoch}")
        
        for batch in progress_bar:
            # ë°°ì¹˜ ì²˜ë¦¬ (for ë£¨í”„ ì œê±°!)
            batch_loss, batch_metrics = self._train_batch(batch)
            
            total_loss += batch_loss
            total_accuracy += batch_metrics['accuracy']
            num_batches += 1
            
            progress_bar.set_postfix({
                'loss': f"{batch_loss:.4f}",
                'acc': f"{batch_metrics['accuracy']:.4f}"
            })
        
        return {
            'loss': total_loss / num_batches,
            'accuracy': total_accuracy / num_batches
        }
    
    def _train_batch(self, batch: Dict[str, torch.Tensor]) -> tuple:
        """ì§„ì •í•œ ë°°ì¹˜ í•™ìŠµ - GPU ë³‘ë ¬ ì²˜ë¦¬ í™œìš©"""
        # 1. ë°ì´í„° ì¤€ë¹„ ë° ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
        input_tokens = batch['input_tokens'].to(self.device)
        target_tokens = batch['target_tokens'].to(self.device) 
        attention_mask = batch['attention_mask'].to(self.device)
        
        # 2. ê·¸ë˜ë””ì–¸íŠ¸ ì´ˆê¸°í™”
        self.optimizer.zero_grad()
        
        # 3. Forward Pass (ëª¨ë¸ì— ë°°ì¹˜ ì „ì²´ë¥¼ ì „ë‹¬)
        # ëª¨ë¸ì˜ forwardëŠ” ë‚´ë¶€ì ìœ¼ë¡œ CLK ë£¨í”„ë¥¼ ëŒê³  ìµœì¢… ë¡œì§“ [B, seq_len, vocab_size]ë¥¼ ë°˜í™˜
        output_logits, processing_info = self.model(
            input_schedule=input_tokens,
            max_clk=self.config.max_clk_training,  # YAML ì„¤ì •ì—ì„œ ê°€ì ¸ì˜¨ ê³ ì • CLK
            training=True,
            target_schedule=target_tokens,
            attention_mask=attention_mask
        )
        
        # 4. ì†ì‹¤ ê³„ì‚° (ìˆ˜ì •ëœ loss_fn ì‚¬ìš©)
        loss = self.loss_fn(output_logits, target_tokens, processing_info)
        
        # 5. Backward Pass (ë°°ì¹˜ ì „ì²´ì— ëŒ€í•´ í•œ ë²ˆë§Œ ìˆ˜í–‰)
        loss.backward()
        
        # 6. ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘
        if self.config.gradient_clip_norm > 0:
            torch.nn.utils.clip_grad_norm_(
                self.model.parameters(), 
                self.config.gradient_clip_norm
            )
        
        # 7. íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸
        self.optimizer.step()
        if self.scheduler:
            self.scheduler.step()
            
        # 8. ë©”íŠ¸ë¦­ ê³„ì‚° (ì •í™•ë„)
        with torch.no_grad():
            accuracy = SCSMetrics.accuracy(
                output_logits, 
                target_tokens, 
                pad_token_id=self.config.pad_token_id
            )
            
        return loss.item(), {'accuracy': accuracy}
    
    
    def _validate_epoch(self, val_loader: DataLoader) -> Dict[str, float]:
        """ê²€ì¦ - ë°°ì¹˜ ì²˜ë¦¬"""
        self.model.eval()
        
        total_loss = 0.0
        total_accuracy = 0.0
        num_batches = 0
        
        with torch.no_grad():
            for batch in val_loader:
                # ğŸ¯ ë°°ì¹˜ ì „ì²´ë¥¼ í•œë²ˆì— ì²˜ë¦¬
                input_tokens = batch['input_tokens'].to(self.device)
                target_tokens = batch['target_tokens'].to(self.device)
                attention_mask = batch['attention_mask'].to(self.device)
                
                # í•™ìŠµê³¼ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ë°°ì¹˜ ì²˜ë¦¬
                output_logits, processing_info = self.model(
                    input_schedule=input_tokens,
                    max_clk=self.config.max_clk_training,
                    training=True,
                    target_schedule=target_tokens,
                    attention_mask=attention_mask
                )
                
                # ë°°ì¹˜ ë‹¨ìœ„ ì†ì‹¤ ë° ë©”íŠ¸ë¦­ ê³„ì‚°
                batch_loss = self.loss_fn(output_logits, target_tokens, processing_info)
                batch_accuracy = SCSMetrics.accuracy(
                    output_logits, 
                    target_tokens, 
                    pad_token_id=self.config.pad_token_id
                )
                
                total_loss += batch_loss.item()
                total_accuracy += batch_accuracy
                num_batches += 1
        
        return {
            'loss': total_loss / num_batches,
            'accuracy': total_accuracy / num_batches
        }
    
    def _should_early_stop(self, val_loss: float) -> bool:
        """ì¡°ê¸° ì¢…ë£Œ íŒë‹¨"""
        if val_loss < self.best_loss:
            self.best_loss = val_loss
            self.patience_counter = 0
            return False
        else:
            self.patience_counter += 1
            return self.patience_counter >= self.config.early_stopping_patience
    
    def _save_checkpoint(self, save_path: str, epoch: int):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'best_loss': self.best_loss,
            'config': self.config
        }
        if self.scheduler:
            checkpoint['scheduler_state_dict'] = self.scheduler.state_dict()
        torch.save(checkpoint, f"{save_path}/checkpoint_epoch_{epoch}.pt")
    
    def _log_progress(self, epoch: int, metrics: Dict[str, float]):
        """ì§„í–‰ ìƒí™© ë¡œê¹…"""
        self.logger.info(
            f"ì—í¬í¬ {epoch}: "
            f"ì†ì‹¤={metrics['loss']:.4f}, "
            f"ì •í™•ë„={metrics['accuracy']:.4f}"
        )
    
    def evaluate(self, test_loader: DataLoader) -> Dict[str, float]:
        """í…ŒìŠ¤íŠ¸ í‰ê°€ - ëª¨ë“  ìƒì„¸ ë©”íŠ¸ë¦­ ë¶„ì„"""
        self.model.eval()
        
        total_loss = 0.0
        total_accuracy = 0.0
        total_comprehensive = 0.0
        total_convergence = 0.0
        total_efficiency = 0.0
        num_samples = 0
        
        with torch.no_grad():
            for batch in test_loader:
                batch_size = batch['input_tokens'].size(0)
                
                for i in range(batch_size):
                    # ë‹¨ì¼ ìƒ˜í”Œë¡œ ìƒì„¸ ë¶„ì„
                    single_input = batch['input_tokens'][i:i+1].to(self.device)
                    single_target = batch['target_tokens'][i:i+1].to(self.device)
                    
                    outputs, processing_info = self.model(
                        input_schedule=single_input.squeeze(0),
                        training=False
                    )
                    
                    loss = self.loss_fn(
                        outputs.unsqueeze(0) if outputs.dim() == 1 else outputs,
                        single_target.squeeze(0) if single_target.dim() == 1 else single_target,
                        processing_info
                    )
                    
                    total_loss += loss.item()
                    total_accuracy += SCSMetrics.accuracy(outputs, single_target.squeeze(0))
                    total_comprehensive += SCSMetrics.comprehensive_score(processing_info)
                    total_convergence += SCSMetrics.convergence_rate(processing_info)
                    total_efficiency += SCSMetrics.processing_efficiency(processing_info)
                    num_samples += 1
        
        return {
            'test_loss': total_loss / num_samples,
            'test_accuracy': total_accuracy / num_samples,
            'comprehensive_score': total_comprehensive / num_samples,
            'convergence_rate': total_convergence / num_samples,
            'processing_efficiency': total_efficiency / num_samples
        }


class GradualUnfreezingScheduler:
    """ì ì§„ì  ì–¸í”„ë¦¬ì§• ìŠ¤ì¼€ì¤„ëŸ¬"""
    
    def __init__(self, model, unfreezing_schedule: Dict[int, List[str]]):
        self.model = model
        self.schedule = unfreezing_schedule
        
        # ì´ˆê¸°ì—ëŠ” ëª¨ë“  íŒŒë¼ë¯¸í„° ê³ ì •
        for param in self.model.parameters():
            param.requires_grad = False
    
    def step(self, epoch: int):
        """ì—í¬í¬ì— ë”°ë¼ ì ì§„ì ìœ¼ë¡œ ì–¸í”„ë¦¬ì§•"""
        if epoch in self.schedule:
            modules_to_unfreeze = self.schedule[epoch]
            for module_name in modules_to_unfreeze:
                module = getattr(self.model, module_name, None)
                if module:
                    for param in module.parameters():
                        param.requires_grad = True