# src/scs/utils/tensorboard_logger.py
"""
SCS TensorBoard ë¡œê±°

SCS ì‹œìŠ¤í…œ ì „ìš© TensorBoard ë¡œê¹… ê¸°ëŠ¥ ì œê³µ
"""

import torch
import torch.nn as nn
from torch.utils.tensorboard import SummaryWriter
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # GUI ì—†ëŠ” í™˜ê²½ì—ì„œë„ ì‘ë™
from typing import Dict, Any, Optional, List
from pathlib import Path
import subprocess
import time
import webbrowser
import warnings

class SCSTensorBoardLogger:
    """SCS ì „ìš© TensorBoard ë¡œê±°"""
    
    def __init__(self, log_dir: Path, config: Optional[Dict[str, Any]] = None):
        """
        TensorBoard ë¡œê±° ì´ˆê¸°í™”
        
        Args:
            log_dir: TensorBoard ë¡œê·¸ ì €ì¥ ë””ë ‰í† ë¦¬
            config: TensorBoard ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # ì„¤ì • ì´ˆê¸°í™”
        self.config = config or {}
        self.log_interval = self.config.get('log_interval', {
            'scalars': 1,
            'histograms': 100,
            'images': 500,
            'spikes': 50
        })
        self.max_images_per_batch = self.config.get('max_images_per_batch', 4)
        self.histogram_freq = self.config.get('histogram_freq', 100)
        
        # TensorBoard Writer ì´ˆê¸°í™” - purge_step=0ìœ¼ë¡œ ì¤‘ë³µ ë””ë ‰í† ë¦¬ ë°©ì§€
        self.writer = SummaryWriter(
            log_dir=self.log_dir,
            purge_step=0  # ê¸°ì¡´ ë¡œê·¸ë¥¼ ë®ì–´ì“°ë©° ìƒˆë¡œìš´ run ë””ë ‰í† ë¦¬ ìƒì„± ë°©ì§€
        )
        
        # ì¹´ìš´í„°ë“¤
        self.global_step = 0
        self.epoch = 0
        self.batch_counter = 0
        self.clk_counter = 0
        
        # TensorBoard ì„œë²„ í”„ë¡œì„¸ìŠ¤
        self.tb_process = None
        
        # ìë™ ì‹¤í–‰
        if self.config.get('auto_launch', False):
            self.launch_tensorboard(self.config.get('port', 6006))
            
    def set_epoch(self, epoch: int):
        """í˜„ì¬ ì—í¬í¬ ì„¤ì •"""
        self.epoch = epoch
    
    def should_log(self, log_type: str) -> bool:
        """ë¡œê¹… ì—¬ë¶€ ê²°ì •"""
        if log_type == "scalars":
            return self.batch_counter % self.log_interval.get("scalars", 1) == 0
        elif log_type == "histograms":
            return self.batch_counter % self.log_interval.get("histograms", 100) == 0
        elif log_type == "images":
            return self.batch_counter % self.log_interval.get("images", 500) == 0
        elif log_type == "spikes":
            return self.clk_counter % self.log_interval.get("spikes", 50) == 0
        elif log_type == "axonal_heatmaps":
            return self.batch_counter % self.log_interval.get("axonal_heatmaps", 200) == 0
        return False
    
    def log_training_step(self, metrics: Dict[str, Any], loss: float):
        """í•™ìŠµ ìŠ¤í… ë¡œê¹…"""
        if self.should_log("scalars"):
            # ê¸°ë³¸ ì†ì‹¤
            self.writer.add_scalar("Training/Loss", loss, self.global_step)
            
            # ê¸°íƒ€ ë©”íŠ¸ë¦­
            for key, value in metrics.items():
                if isinstance(value, (int, float)):
                    self.writer.add_scalar(f"Training/{key}", value, self.global_step)
                elif isinstance(value, torch.Tensor) and value.numel() == 1:
                    self.writer.add_scalar(f"Training/{key}", value.item(), self.global_step)
        
        self.global_step += 1
        self.batch_counter += 1
    
    def log_validation_step(self, metrics: Dict[str, Any]):
        """ê²€ì¦ ìŠ¤í… ë¡œê¹…"""
        for key, value in metrics.items():
            if isinstance(value, (int, float)):
                self.writer.add_scalar(f"Validation/{key}", value, self.epoch)
            elif isinstance(value, torch.Tensor) and value.numel() == 1:
                self.writer.add_scalar(f"Validation/{key}", value.item(), self.epoch)
    
    def log_model_weights(self, model: nn.Module, suffix: str = ""):
        """ëª¨ë¸ ê°€ì¤‘ì¹˜ íˆìŠ¤í† ê·¸ë¨ ë¡œê¹…"""
        if not self.should_log("histograms"):
            return
        
        for name, param in model.named_parameters():
            if param.requires_grad and param.numel() > 0:
                self.writer.add_histogram(f"Weights{suffix}/{name}", param.detach().cpu(), self.epoch)
                
                if param.grad is not None:
                    self.writer.add_histogram(f"Gradients{suffix}/{name}", param.grad.detach().cpu(), self.epoch)
    
    def log_spike_patterns(self, spike_patterns: Dict[str, torch.Tensor], clk: int):
        """ìŠ¤íŒŒì´í¬ íŒ¨í„´ ì´ë¯¸ì§€ ë¡œê¹…"""
        if not self.should_log("spikes"):
            return
        
        # ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜ ì œí•œ
        node_names = list(spike_patterns.keys())[:self.max_images_per_batch]
        
        for node_name in node_names:
            spikes = spike_patterns[node_name]
            if spikes is None or spikes.numel() == 0:
                continue
            
            try:
                # [B, H, W] -> [H, W] (ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ)
                if spikes.dim() == 3:
                    spike_img = spikes[0].detach().cpu().numpy()
                elif spikes.dim() == 2:
                    spike_img = spikes.detach().cpu().numpy()
                else:
                    continue
                
                # ì´ë¯¸ì§€ ì •ê·œí™” (0-1 ë²”ìœ„)
                if spike_img.max() > spike_img.min():
                    spike_img = (spike_img - spike_img.min()) / (spike_img.max() - spike_img.min())
                else:
                    spike_img = np.zeros_like(spike_img)
                
                # TensorBoardì— ì´ë¯¸ì§€ ì¶”ê°€
                self.writer.add_image(
                    f"Spikes/{node_name}",
                    spike_img,
                    global_step=clk,
                    dataformats='HW'
                )
            except Exception as e:
                warnings.warn(f"ìŠ¤íŒŒì´í¬ íŒ¨í„´ ë¡œê¹… ì¤‘ ì˜¤ë¥˜ ({node_name}): {e}")
        
        self.clk_counter += 1
    
    def log_processing_info(self, processing_info: Dict[str, Any]):
        """ì²˜ë¦¬ ì •ë³´ ë¡œê¹…"""
        # ì²˜ë¦¬ CLK ìˆ˜
        if 'processing_clk' in processing_info:
            self.writer.add_scalar("Processing/CLK_Count", processing_info['processing_clk'], self.epoch)
        
        # ìˆ˜ë ´ ì—¬ë¶€
        if 'convergence_achieved' in processing_info:
            convergence = 1.0 if processing_info['convergence_achieved'] else 0.0
            self.writer.add_scalar("Processing/Convergence", convergence, self.epoch)
        
        # ìƒì„±ëœ í† í° ìˆ˜
        if 'tokens_generated' in processing_info:
            self.writer.add_scalar("Processing/Tokens_Generated", processing_info['tokens_generated'], self.epoch)
        
        # ACC í™œë™ë„
        if 'final_acc_activity' in processing_info:
            self.writer.add_scalar("Processing/ACC_Activity", processing_info['final_acc_activity'], self.epoch)
        
        # ë°°ì¹˜ í¬ê¸°
        if 'batch_size' in processing_info:
            self.writer.add_scalar("Processing/Batch_Size", processing_info['batch_size'], self.epoch)
    
    def log_loss_components(self, loss_components: Dict[str, float]):
        """ì†ì‹¤ êµ¬ì„±ìš”ì†Œ ë¡œê¹…"""
        for component, value in loss_components.items():
            if isinstance(value, (int, float)):
                self.writer.add_scalar(f"Loss_Components/{component}", value, self.global_step)
            elif isinstance(value, torch.Tensor) and value.numel() == 1:
                self.writer.add_scalar(f"Loss_Components/{component}", value.item(), self.global_step)
    
    def log_hyperparameters(self, config_dict: Dict[str, Any], metrics: Dict[str, float]):
        """í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…"""
        # í‰ë©´í™”ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬ ìƒì„±
        hparams = self._flatten_config(config_dict)
        
        # ìŠ¤ì¹¼ë¼ ê°’ë§Œ í•„í„°ë§
        filtered_hparams = {}
        for key, value in hparams.items():
            if isinstance(value, (int, float, str, bool)):
                # ë¬¸ìì—´ ê¸¸ì´ ì œí•œ (TensorBoard ì œí•œ)
                if isinstance(value, str) and len(value) > 100:
                    value = value[:97] + "..."
                filtered_hparams[key] = value
        
        # ë©”íŠ¸ë¦­ë„ ìŠ¤ì¹¼ë¼ ê°’ë§Œ í•„í„°ë§
        filtered_metrics = {}
        for key, value in metrics.items():
            if isinstance(value, (int, float)):
                filtered_metrics[key] = value
            elif isinstance(value, torch.Tensor) and value.numel() == 1:
                filtered_metrics[key] = value.item()
        
        if filtered_hparams and filtered_metrics:
            try:
                self.writer.add_hparams(filtered_hparams, filtered_metrics)
            except Exception as e:
                warnings.warn(f"í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹… ì¤‘ ì˜¤ë¥˜: {e}")
    
    def log_learning_rate(self, lr: float):
        """í•™ìŠµë¥  ë¡œê¹…"""
        self.writer.add_scalar("Training/Learning_Rate", lr, self.global_step)
    
    def log_custom_scalar(self, tag: str, value: float, step: Optional[int] = None):
        """ì»¤ìŠ¤í…€ ìŠ¤ì¹¼ë¼ ë¡œê¹…"""
        step = step if step is not None else self.global_step
        self.writer.add_scalar(tag, value, step)
    
    def log_custom_histogram(self, tag: str, values: torch.Tensor, step: Optional[int] = None):
        """ì»¤ìŠ¤í…€ íˆìŠ¤í† ê·¸ë¨ ë¡œê¹…"""
        step = step if step is not None else self.epoch
        if values.numel() > 0:
            self.writer.add_histogram(tag, values.detach().cpu(), step)
    
    def _flatten_config(self, config: Dict[str, Any], prefix: str = "") -> Dict[str, Any]:
        """ì¤‘ì²©ëœ ì„¤ì •ì„ í‰ë©´í™”"""
        flattened = {}
        
        for key, value in config.items():
            full_key = f"{prefix}/{key}" if prefix else key
            
            if isinstance(value, dict):
                flattened.update(self._flatten_config(value, full_key))
            elif isinstance(value, (int, float, str, bool)):
                flattened[full_key] = value
            elif isinstance(value, list) and len(value) > 0 and isinstance(value[0], (int, float)):
                # ìˆ«ì ë¦¬ìŠ¤íŠ¸ëŠ” í‰ê· ê°’ìœ¼ë¡œ ë³€í™˜
                flattened[f"{full_key}_mean"] = sum(value) / len(value)
        
        return flattened
    
    def log_axonal_heatmaps(self, axonal_data: Dict[str, Any], step: Optional[int] = None):
        """ì¶•ì‚­ ì—°ê²° í†µí•© íˆíŠ¸ë§µì„ TensorBoardì— ë¡œê¹…"""
        if not axonal_data or not self.should_log("axonal_heatmaps"):  # ìˆ˜ì •: ì ì ˆí•œ should_log ì²´í¬
            return
        
        step = step if step is not None else self.epoch
        
        try:
            for conn_data in axonal_data:
                conn_name = conn_data['connection_name']
                gates = conn_data['gates']  # [num_patches]
                transforms = conn_data['transforms']  # [num_patches, target_size, source_size]
                
                if gates.numel() > 0 and transforms.numel() > 0:
                    self._log_integrated_axonal_heatmap(gates, transforms, conn_name, step)
                    
        except Exception as e:
            warnings.warn(f"Axonal íˆíŠ¸ë§µ ë¡œê¹… ì¤‘ ì˜¤ë¥˜: {e}")
    
    def _log_integrated_axonal_heatmap(self, gates: torch.Tensor, transforms: torch.Tensor, conn_name: str, step: int):
        """í†µí•©ëœ GatesÃ—Transforms íˆíŠ¸ë§µì„ TensorBoardì— ë¡œê¹…"""
        try:
            gates_np = gates.detach().cpu().numpy()
            transforms_np = transforms.detach().cpu().numpy()
            
            num_patches, target_size, source_size = transforms_np.shape
            
            # íŒ¨ì¹˜ ê²©ì í¬ê¸° ê³„ì‚°
            patches_per_row = int(np.ceil(np.sqrt(num_patches)))
            patches_per_col = int(np.ceil(num_patches / patches_per_row))
            
            # í†µí•© íˆíŠ¸ë§µ í¬ê¸°
            cell_size = max(target_size, source_size)
            total_height = patches_per_col * cell_size
            total_width = patches_per_row * cell_size
            
            integrated_heatmap = np.zeros((total_height, total_width))
            
            for patch_idx in range(num_patches):
                row_idx = patch_idx // patches_per_row
                col_idx = patch_idx % patches_per_row
                
                start_row = row_idx * cell_size
                end_row = start_row + cell_size
                start_col = col_idx * cell_size
                end_col = start_col + cell_size
                
                # Transform í‰ê· ê°’ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©
                patch_transform_mean = transforms_np[patch_idx].mean()
                integrated_heatmap[start_row:end_row, start_col:end_col] = patch_transform_mean
                
                # Gate ê°’ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§
                gate_value = gates_np[patch_idx]
                integrated_heatmap[start_row:end_row, start_col:end_col] *= gate_value
                
                # ì‹¤ì œ transform íŒ¨í„´ ì˜¤ë²„ë ˆì´
                if target_size <= cell_size and source_size <= cell_size:
                    center_start_row = start_row + (cell_size - target_size) // 2
                    center_end_row = center_start_row + target_size
                    center_start_col = start_col + (cell_size - source_size) // 2
                    center_end_col = center_start_col + source_size
                    
                    integrated_heatmap[center_start_row:center_end_row, 
                                     center_start_col:center_end_col] = transforms_np[patch_idx] * gate_value
            
            # matplotlibìœ¼ë¡œ íˆíŠ¸ë§µ ìƒì„±
            fig, ax = plt.subplots(figsize=(10, 8))
            im = ax.imshow(integrated_heatmap, cmap='RdYlBu_r', aspect='auto')
            ax.set_title(f'{conn_name} - Integrated GatesÃ—Transforms\n({num_patches} patches)')
            ax.set_xlabel('Source Dimension')
            ax.set_ylabel('Target Dimension')
            
            # íŒ¨ì¹˜ ê²½ê³„ì„ 
            for p in range(1, patches_per_row):
                ax.axvline(x=p * cell_size - 0.5, color='black', linewidth=1, alpha=0.8)
            for p in range(1, patches_per_col):
                ax.axhline(y=p * cell_size - 0.5, color='black', linewidth=1, alpha=0.8)
            
            # ê²Œì´íŠ¸ ê°’ í…ìŠ¤íŠ¸ í‘œì‹œ
            for patch_idx in range(num_patches):
                row_idx = patch_idx // patches_per_row
                col_idx = patch_idx % patches_per_row
                
                text_row = row_idx * cell_size + cell_size // 2
                text_col = col_idx * cell_size + cell_size // 2
                
                ax.text(text_col, text_row, f'{gates_np[patch_idx]:.2f}', 
                       ha='center', va='center', fontsize=8, 
                       color='white', fontweight='bold',
                       bbox=dict(boxstyle='round,pad=0.2', facecolor='black', alpha=0.7))
            
            plt.colorbar(im, ax=ax)
            plt.tight_layout()
            
            # TensorBoardì— Figureë¡œ ì €ì¥
            self.writer.add_figure(f'Axonal_Integrated/{conn_name}', fig, step)
            plt.close(fig)
            
        except Exception as e:
            warnings.warn(f"í†µí•© íˆíŠ¸ë§µ ë¡œê¹… ì˜¤ë¥˜ ({conn_name}): {e}")

    def launch_tensorboard(self, port: int = 6006, auto_open: bool = True) -> bool:
        """TensorBoard ì„œë²„ ì‹œì‘"""
        try:
            cmd = [
                "tensorboard", 
                "--logdir", str(self.log_dir),  # ìƒìœ„ ë””ë ‰í† ë¦¬ê°€ ì•„ë‹Œ ì •í™•í•œ ë¡œê·¸ ë””ë ‰í† ë¦¬ ì§€ì •
                "--port", str(port), 
                "--host", "0.0.0.0",
                "--reload_interval", "30"  # 30ì´ˆë§ˆë‹¤ ìƒˆ ë¡œê·¸ í™•ì¸
            ]
            
            self.tb_process = subprocess.Popen(
                cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE,
                text=True
            )
            
            # ì„œë²„ ì‹œì‘ ëŒ€ê¸°
            time.sleep(3)
            
            # ë¸Œë¼ìš°ì € ìë™ ì—´ê¸°
            if auto_open:
                try:
                    webbrowser.open(f"http://localhost:{port}")
                except Exception:
                    pass  # ë¸Œë¼ìš°ì € ì—´ê¸° ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ
            
            print(f"ğŸ“Š TensorBoard ì„œë²„ ì‹œì‘ë¨: http://localhost:{port}")
            print(f"ğŸ“ ë¡œê·¸ ë””ë ‰í† ë¦¬: {self.log_dir}")
            return True
            
        except FileNotFoundError:
            print("âš ï¸ TensorBoardê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install tensorboard'ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
            return False
        except Exception as e:
            print(f"âš ï¸ TensorBoard ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")
            return False
        
    def close(self):
        """ë¡œê±° ë° TensorBoard ì„œë²„ ì¢…ë£Œ"""
        if self.writer:
            self.writer.close()
        
        if self.tb_process:
            try:
                self.tb_process.terminate()
                self.tb_process.wait(timeout=5)
            except subprocess.TimeoutExpired:
                self.tb_process.kill()
            except Exception:
                pass  # í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹¤íŒ¨í•´ë„ ë¬´ì‹œ
    
    def __enter__(self):
        """Context manager ì§„ì…"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager ì¢…ë£Œ"""
        self.close()